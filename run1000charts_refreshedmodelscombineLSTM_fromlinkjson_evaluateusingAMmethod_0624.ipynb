{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import os,boto3,sys,glob,json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1  Loading the  data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF=pd.read_csv('run1000charts_0521.csv')\n",
    "#testDF= pd.read_csv('/home/jovyan/work/Analytics_Data_training/bfAI_allinst_7502charts_061019.csv') # 7502 charts\n",
    "\n",
    "# the csv is generated in D drive D:/chartai_qa  with extract1000charts_jsontxt.py, then uploaded to here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76792"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'chart_id', 'code', 'text', 'start_offset', 'end_offset',\n",
       "       'text75'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF=testDF.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>E063</td>\n",
       "      <td>Ht</td>\n",
       "      <td>1187</td>\n",
       "      <td>1189</td>\n",
       "      <td>ocedure codes 36415 venipunct routine vital si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>E785</td>\n",
       "      <td>Hyperlipidemia</td>\n",
       "      <td>1374</td>\n",
       "      <td>1388</td>\n",
       "      <td>tion list reviewed reconciled patient past med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>I10</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>1391</td>\n",
       "      <td>1403</td>\n",
       "      <td>reconciled patient past medical history hyperl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>E785</td>\n",
       "      <td>Hyperlipidemia</td>\n",
       "      <td>2957</td>\n",
       "      <td>2971</td>\n",
       "      <td>tion list reviewed reconciled patient past med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>I10</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>2974</td>\n",
       "      <td>2986</td>\n",
       "      <td>reconciled patient past medical history hyperl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            chart_id  code            text  \\\n",
       "0  IBXRMA2018_MULT_1163297620010001_HMK_179342168...  E063              Ht   \n",
       "1  IBXRMA2018_MULT_1163297620010001_HMK_179342168...  E785  Hyperlipidemia   \n",
       "2  IBXRMA2018_MULT_1163297620010001_HMK_179342168...   I10    Hypertension   \n",
       "3  IBXRMA2018_MULT_1163297620010001_HMK_179342168...  E785  Hyperlipidemia   \n",
       "4  IBXRMA2018_MULT_1163297620010001_HMK_179342168...   I10    Hypertension   \n",
       "\n",
       "   start_offset  end_offset                                             text75  \n",
       "0          1187        1189  ocedure codes 36415 venipunct routine vital si...  \n",
       "1          1374        1388  tion list reviewed reconciled patient past med...  \n",
       "2          1391        1403  reconciled patient past medical history hyperl...  \n",
       "3          2957        2971  tion list reviewed reconciled patient past med...  \n",
       "4          2974        2986  reconciled patient past medical history hyperl...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just check if there's null text, if yes, remove them \n",
    "nulltext=testDF[~pd.notnull(testDF['text'])] \n",
    "len(nulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulltext=testDF[~pd.notnull(testDF['text75'])] \n",
    "len(nulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>IBXRMA2018_MULT_1164353980010001_HMK_160303709...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>IBXRMA2018_MULT_1176161080010001_HMK_192365603...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>IBXRMA2018_MULT_1202740400010001_HMK_153425750...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>IBXRMA2018_MULT_1202908350010001_HMK_210648786...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>IBXRMA2018_MULT_1210779380010001_HMK_184462858...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>IBXRMA2018_MULT_1212745310010001_HMK_165441851...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>IBXRMA2018_MULT_1216729130010001_HMK_196286386...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>IBXRMA2018_MULT_1216856710010001_HMK_173309591...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>IBXRMA2018_MULT_1216874020010001_HMK_143364782...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21748</th>\n",
       "      <td>IBXRMA2018_MULT_1216901800010001_HMK_201224196...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23385</th>\n",
       "      <td>IBXRMA2018_MULT_1216920010010001_HMK_166407506...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36203</th>\n",
       "      <td>IBXRMA2018_MULT_1217130710010001_HMK_180325209...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38069</th>\n",
       "      <td>IBXRMA2018_MULT_1217196230010001_HMK_147405194...</td>\n",
       "      <td>H4010X0</td>\n",
       "      <td>glaucoma</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42560</th>\n",
       "      <td>IBXRMA2018_MULT_1217427650010001_HMK_140260863...</td>\n",
       "      <td>I200</td>\n",
       "      <td>1200</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49636</th>\n",
       "      <td>IBXRMA2018_MULT_1217591910010001_HMK_168240489...</td>\n",
       "      <td>E780</td>\n",
       "      <td>cholesterol</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50776</th>\n",
       "      <td>IBXRMA2018_MULT_1217621540010001_HMK_169322472...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55924</th>\n",
       "      <td>IBXRMA2018_MULT_1217796040010001_HMK_211221367...</td>\n",
       "      <td>E785</td>\n",
       "      <td>hyperlipidemia  unspecified</td>\n",
       "      <td>52</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56125</th>\n",
       "      <td>IBXRMA2018_MULT_1217797400010001_HMK_583093637...</td>\n",
       "      <td>E1169</td>\n",
       "      <td>diabetic foot</td>\n",
       "      <td>72</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57927</th>\n",
       "      <td>IBXRMA2018_MULT_1217834870010001_HMK_192226422...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59488</th>\n",
       "      <td>IBXRMA2018_MULT_1217905040010001_HMK_174329240...</td>\n",
       "      <td>J449</td>\n",
       "      <td>cord</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61236</th>\n",
       "      <td>IBXRMA2018_MULT_1217936810010001_HMK_MA1462698...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67867</th>\n",
       "      <td>IBXRMA2018_MULT_1217996130010001_HMK_314380144...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69643</th>\n",
       "      <td>IBXRMA2018_MULT_1218012650010001_HMK_197249628...</td>\n",
       "      <td>N189</td>\n",
       "      <td>CKD</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69946</th>\n",
       "      <td>IBXRMA2018_MULT_1218015600010001_HMK_3GM6V72QA...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72670</th>\n",
       "      <td>IBXRMA2018_MULT_1218027670010001_HMK_198289883...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76646</th>\n",
       "      <td>IBXRMA2018_MULT_1231613440010001_HMK_177320615...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id     code  \\\n",
       "1336   IBXRMA2018_MULT_1164353980010001_HMK_160303709...     G129   \n",
       "2198   IBXRMA2018_MULT_1176161080010001_HMK_192365603...      N08   \n",
       "3876   IBXRMA2018_MULT_1202740400010001_HMK_153425750...     G129   \n",
       "4032   IBXRMA2018_MULT_1202908350010001_HMK_210648786...     E744   \n",
       "5591   IBXRMA2018_MULT_1210779380010001_HMK_184462858...     G129   \n",
       "6465   IBXRMA2018_MULT_1212745310010001_HMK_165441851...      N08   \n",
       "9116   IBXRMA2018_MULT_1216729130010001_HMK_196286386...      N08   \n",
       "14970  IBXRMA2018_MULT_1216856710010001_HMK_173309591...     G129   \n",
       "18950  IBXRMA2018_MULT_1216874020010001_HMK_143364782...     E744   \n",
       "21748  IBXRMA2018_MULT_1216901800010001_HMK_201224196...     G129   \n",
       "23385  IBXRMA2018_MULT_1216920010010001_HMK_166407506...      N08   \n",
       "36203  IBXRMA2018_MULT_1217130710010001_HMK_180325209...     E744   \n",
       "38069  IBXRMA2018_MULT_1217196230010001_HMK_147405194...  H4010X0   \n",
       "42560  IBXRMA2018_MULT_1217427650010001_HMK_140260863...     I200   \n",
       "49636  IBXRMA2018_MULT_1217591910010001_HMK_168240489...     E780   \n",
       "50776  IBXRMA2018_MULT_1217621540010001_HMK_169322472...     E744   \n",
       "55924  IBXRMA2018_MULT_1217796040010001_HMK_211221367...     E785   \n",
       "56125  IBXRMA2018_MULT_1217797400010001_HMK_583093637...    E1169   \n",
       "57927  IBXRMA2018_MULT_1217834870010001_HMK_192226422...     E744   \n",
       "59488  IBXRMA2018_MULT_1217905040010001_HMK_174329240...     J449   \n",
       "61236  IBXRMA2018_MULT_1217936810010001_HMK_MA1462698...     G129   \n",
       "67867  IBXRMA2018_MULT_1217996130010001_HMK_314380144...     E744   \n",
       "69643  IBXRMA2018_MULT_1218012650010001_HMK_197249628...     N189   \n",
       "69946  IBXRMA2018_MULT_1218015600010001_HMK_3GM6V72QA...      N08   \n",
       "72670  IBXRMA2018_MULT_1218027670010001_HMK_198289883...      N08   \n",
       "76646  IBXRMA2018_MULT_1231613440010001_HMK_177320615...     G129   \n",
       "\n",
       "                              text  start_offset  end_offset text75  \n",
       "1336                           SMA             4           7    NaN  \n",
       "2198                        Kidney            46          52    NaN  \n",
       "3876                           SMA             4           7    NaN  \n",
       "4032                            PC            25          27    NaN  \n",
       "5591                           SMA             4           7    NaN  \n",
       "6465                        Kidney            48          54    NaN  \n",
       "9116                        Kidney            46          52    NaN  \n",
       "14970                          SMA             4           7    NaN  \n",
       "18950                           PC            25          27    NaN  \n",
       "21748                          SMA             4           7    NaN  \n",
       "23385                       Kidney            46          52    NaN  \n",
       "36203                           PC            25          27    NaN  \n",
       "38069                     glaucoma            52          60    NaN  \n",
       "42560                         1200            33          37    NaN  \n",
       "49636                  cholesterol            60          71    NaN  \n",
       "50776                           PC            18          20    NaN  \n",
       "55924  hyperlipidemia  unspecified            52          79    NaN  \n",
       "56125                diabetic foot            72          85    NaN  \n",
       "57927                           PC            18          20    NaN  \n",
       "59488                         cord            65          69    NaN  \n",
       "61236                          SMA             4           7    NaN  \n",
       "67867                           PC            25          27    NaN  \n",
       "69643                          CKD            28          31    NaN  \n",
       "69946                       Kidney            48          54    NaN  \n",
       "72670                       Kidney            46          52    NaN  \n",
       "76646                          SMA             4           7    NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulltext   # there are some text not correctly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF=testDF[pd.notnull(testDF['text75'])] \n",
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF['chart_id'].nunique()   # only 980 charts not 1044 charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76761</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E119</td>\n",
       "      <td>dm2</td>\n",
       "      <td>5902</td>\n",
       "      <td>5905</td>\n",
       "      <td>onciled patient past medical history cholecyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>B182</td>\n",
       "      <td>hepatitis c</td>\n",
       "      <td>6819</td>\n",
       "      <td>6830</td>\n",
       "      <td>lab comp metabolic panel lab glycosolated hemo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76763</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>6951</td>\n",
       "      <td>6971</td>\n",
       "      <td>increat random colon cancer screening notes de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76764</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E782</td>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>7001</td>\n",
       "      <td>7015</td>\n",
       "      <td>declined gi referral vitamin deficiency lab vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76765</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>7144</td>\n",
       "      <td>7147</td>\n",
       "      <td>breast cancer screening imaging mammo digital ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id   code  \\\n",
       "76761  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E119   \n",
       "76762  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   B182   \n",
       "76763  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E550   \n",
       "76764  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E782   \n",
       "76765  IBXRMA2018_MULT_1231614110010001_HMK_196526763...  I2510   \n",
       "\n",
       "                       text  start_offset  end_offset  \\\n",
       "76761                   dm2          5902        5905   \n",
       "76762           hepatitis c          6819        6830   \n",
       "76763  vitamin d deficiency          6951        6971   \n",
       "76764        hyperlipidemia          7001        7015   \n",
       "76765                   cad          7144        7147   \n",
       "\n",
       "                                                  text75  \n",
       "76761  onciled patient past medical history cholecyst...  \n",
       "76762  lab comp metabolic panel lab glycosolated hemo...  \n",
       "76763  increat random colon cancer screening notes de...  \n",
       "76764  declined gi referral vitamin deficiency lab vi...  \n",
       "76765  breast cancer screening imaging mammo digital ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF=testDF.reset_index(drop=True)   # very very import, to reset the index, otherwise the below running the model will not be right, because I use the index as reference for position and matching them\n",
    "testDF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Loading all the models or locate the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.a. Load the 28 pickle files and run them on the testDF with selected chart_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files=glob.glob(\"../../picklefolder_ngrams/refreshed_models_update0531/*.pickle\") # refreshed updated models\n",
    "files=glob.glob(\"../../picklefolder_ngrams/refreshed_models/*19.pickle\")  # refreshed models\n",
    "#files=glob.glob(\"../../picklefolder_ngrams/pipeline_pickles/*.pickle\")  # pipeline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files=files[:-1]\n",
    "#len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files2=glob.glob(\"../../picklefolder_ngrams/refreshed_models_update0531/*.pickle\") # refreshed updated models\n",
    "#files2=files2[:-1]   # run 28 model\n",
    "files2=files2[28]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models_update0531/Deletion_Consolidated_LRMay2919.pickle']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.append(files2)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preventative'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[27].split('/')[-1].split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Code_Heart_LRApril0219.pickle'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[10].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Apply models to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = preprocessing.LabelEncoder()\n",
    "#test_y = encoder.fit_transform(testDF['flag'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list={}\n",
    "code_list[\"Model1\"]=['I10','E119']\n",
    "code_list[\"Model2\"]=['I2510','E785','K219','F329','I639']\n",
    "code_list[\"Model3\"]=['I739','N183','Z992','B20','I213','R569','I43','J410','I714','R579','E550','I209','J45998','I480','B182','K210','K739']\n",
    "code_list[\"Heart\"]=['I509','I482','I4891','I82401']\n",
    "code_list[\"Depression\"]=['F411','F410','F40240','F458','F409','F4000','F4001','F445','F444','F40243','F446','F4010','F442','F408','F449','F451']\n",
    "code_list[\"Kidney\"]=['N189','N181','N182','E1122','I130','E0822','E1022']\n",
    "code_list[\"Diabetes\"]=['Z794','E109','E119','E139','E089','E099']\n",
    "code_list[\"Cancer\"]=['C801','C50919','C189']\n",
    "code_list[\"COPD\"]=['J449','J45909']\n",
    "code_list[\"Cholesterol\"]=['E780','E785','E782','E789','E7800','E784','E781','E7801','E7881','E882','E783','E786','E7889','E756','E755','E7130']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "allpredict=pd.DataFrame()   # create an empty dataframe, to save the prediction result for each model\n",
    "allprob=pd.DataFrame()\n",
    "print(allprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nindexdf=pd.DataFrame() \\nmodel_pipeline = joblib.load(files)\\n  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\\n    # deletion model\\n\\ntestDF1=testDF\\nindexdf[0]= [1 for i in range(len(testDF))]\\n        \\n        \\n        #print(files[i])\\n    # how to put the prediction on the right index?\\ntest=testDF1[\\'text75\\']\\nprint(\"model loaded:\", files )\\nprint(\"length of data for the model:\", len(test))\\n    \\n   \\nproba = model_pipeline.predict_proba(test)[:,1]\\nprediction = np.where(proba > 0.4, 1, 0) # use a lower threshold\\ntestDF1[\\'key\\']=testDF1.index\\ntestDF1[\\'pred\\']=prediction\\ntestDF1[\\'prob\\']= proba\\n\\nindexdf[\\'key\\']=indexdf.index\\nmerged=pd.merge(indexdf,testDF1,on=\\'key\\',how=\\'outer\\')  # maintain the position of the perdiction, match to the right index\\nallpredict[0]=merged[\\'pred\\']    # save the prediction to corresponding dataframe\\nallprob[0]=merged[\\'prob\\']\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for one model evaluation\n",
    "'''\n",
    "indexdf=pd.DataFrame() \n",
    "model_pipeline = joblib.load(files)\n",
    "  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\n",
    "    # deletion model\n",
    "\n",
    "testDF1=testDF\n",
    "indexdf[0]= [1 for i in range(len(testDF))]\n",
    "        \n",
    "        \n",
    "        #print(files[i])\n",
    "    # how to put the prediction on the right index?\n",
    "test=testDF1['text75']\n",
    "print(\"model loaded:\", files )\n",
    "print(\"length of data for the model:\", len(test))\n",
    "    \n",
    "   \n",
    "proba = model_pipeline.predict_proba(test)[:,1]\n",
    "prediction = np.where(proba > 0.4, 1, 0) # use a lower threshold\n",
    "testDF1['key']=testDF1.index\n",
    "testDF1['pred']=prediction\n",
    "testDF1['prob']= proba\n",
    "\n",
    "indexdf['key']=indexdf.index\n",
    "merged=pd.merge(indexdf,testDF1,on='key',how='outer')  # maintain the position of the perdiction, match to the right index\n",
    "allpredict[0]=merged['pred']    # save the prediction to corresponding dataframe\n",
    "allprob[0]=merged['prob']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle\n",
      "length of data for the model: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle\n",
      "length of data for the model: 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle\n",
      "length of data for the model: 7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle\n",
      "length of data for the model: 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle\n",
      "length of data for the model: 3221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle\n",
      "length of data for the model: 1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle\n",
      "length of data for the model: 581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle\n",
      "length of data for the model: 1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle\n",
      "length of data for the model: 1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle\n",
      "length of data for the model: 6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle\n",
      "length of data for the model: 3178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle\n",
      "length of data for the model: 1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle\n",
      "length of data for the model: 16290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle\n",
      "length of data for the model: 1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle\n",
      "length of data for the model: 8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle\n",
      "length of data for the model: 11544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle\n",
      "length of data for the model: 6145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle\n",
      "length of data for the model: 764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle\n",
      "length of data for the model: 2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle\n",
      "length of data for the model: 582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle\n",
      "length of data for the model: 1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle\n",
      "length of data for the model: 5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle\n",
      "length of data for the model: 76766\n",
      "../../picklefolder_ngrams/refreshed_models_update0531/Deletion_Consolidated_LRMay2919.pickle\n",
      "length of data for the model: 76766\n"
     ]
    }
   ],
   "source": [
    "#f = open(\"allmodeltestscore_0506.txt\", \"w+\")  # save all the score to this file\n",
    "# for multiple model evaluation\n",
    "\n",
    "   # create a dataframe, otherwise can use testDF for merging to obtain the prediction matched to index\n",
    "# because for some model testing, we only select partial data, like phrase-based model, code-based model\n",
    "for i in range(len(files)):\n",
    "    indexdf=pd.DataFrame() \n",
    "    model_pipeline = joblib.load(files[i])\n",
    "  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\n",
    "    # deletion model\n",
    "    if(files[i].split('/')[-1].startswith('D')):\n",
    "        try:\n",
    "            testDF1=testDF\n",
    "            indexdf[i]= [1 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "        \n",
    "    elif(files[i].split('/')[-1].startswith('P')):\n",
    "    # if it's phrase-based model, use the following way to select data\n",
    "        \n",
    "        phrase=files[i].split('/')[4].split('_')[1]\n",
    "        try:\n",
    "            testDF1 = testDF[testDF['text'].str.contains(phrase,flags=re.IGNORECASE)]\n",
    "            temp=testDF1.index.tolist()\n",
    "            indexdf[i]=[1 if i in (temp) else 0 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "\n",
    "    elif(files[i].split('/')[-1].startswith('C')):\n",
    "    # if it's code based model, use the following way to select model\n",
    "        codereason=files[i].split('/')[4].split('_')[1]\n",
    "        try:\n",
    "            testDF1 = testDF[testDF['code'].isin(code_list[codereason])]\n",
    "            temp=testDF1.index.tolist()\n",
    "            indexdf[i]=[1 if i in (temp) else 0 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "    else:\n",
    "        print('not a valid/good model name probably...')\n",
    "\n",
    "    print(files[i])\n",
    "    # how to put the prediction on the right index?\n",
    "    test=testDF1['text75']\n",
    "    print(\"length of data for the model:\", len(test))\n",
    "    try:\n",
    "        \n",
    "        proba = model_pipeline.predict_proba(test)[:,1]\n",
    "        prediction = np.where(proba > 0.4, 1, 0) # use a lower threshold\n",
    "        #prediction = model_pipeline.predict(test)\n",
    "        \n",
    "        \n",
    "        testDF1['key']=testDF1.index\n",
    "        testDF1['pred']=prediction\n",
    "        testDF1['prob']= proba\n",
    "\n",
    "        indexdf['key']=indexdf.index\n",
    "        merged=pd.merge(indexdf,testDF1,on='key',how='outer')  # maintain the position of the perdiction, match to the right index\n",
    "        allpredict[i]=merged['pred']    # save the prediction to corresponding dataframe\n",
    "        allprob[i]=merged['prob']   # save the probability\n",
    "    except:\n",
    "         print('something is wrong')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Part 2.b. Now get the prediction and probability dataframes and merge with testDF which has all the chart_id etc info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allpredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     76599\n",
       "1     76583\n",
       "2     69367\n",
       "3     76248\n",
       "4     73545\n",
       "5     75332\n",
       "6     76185\n",
       "7     74772\n",
       "8     75576\n",
       "9     70135\n",
       "10    73588\n",
       "11    75610\n",
       "12    60476\n",
       "13    75301\n",
       "14    68037\n",
       "15    65222\n",
       "16    70621\n",
       "17    76002\n",
       "18    74736\n",
       "19    76184\n",
       "20    75238\n",
       "21    71545\n",
       "22        0\n",
       "23        0\n",
       "24        0\n",
       "25        0\n",
       "26        0\n",
       "27        0\n",
       "28        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.isnull().sum()  # a lot of nulls because not all data are run for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2   3   4   5   6   7   8   9  ...  19  20  21  22  23  24  25  \\\n",
       "0 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "1 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "2 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "3 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "4 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "\n",
       "   26  27  28  \n",
       "0   0   0   1  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.160061</td>\n",
       "      <td>0.349433</td>\n",
       "      <td>0.196206</td>\n",
       "      <td>0.026679</td>\n",
       "      <td>0.521088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.021906</td>\n",
       "      <td>0.020609</td>\n",
       "      <td>0.160427</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.197786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.221087</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>0.331177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.047251</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.108050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.101171</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.253157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1         2   3   4   5   6   7   8   9     ...     19  20  21  \\\n",
       "0 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "1 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "2 NaN NaN  0.113764 NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "3 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "4 NaN NaN  0.125394 NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "\n",
       "         22        23        24        25        26        27        28  \n",
       "0  0.014626  0.063301  0.160061  0.349433  0.196206  0.026679  0.521088  \n",
       "1  0.005715  0.021906  0.020609  0.160427  0.018062  0.008571  0.197786  \n",
       "2  0.008170  0.036722  0.046403  0.221087  0.024644  0.018220  0.331177  \n",
       "3  0.002357  0.006155  0.004079  0.047251  0.002172  0.002319  0.108050  \n",
       "4  0.003010  0.007203  0.021988  0.101171  0.002850  0.004171  0.253157  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data frame for predictions from each model\n",
    "#merge to testDF to keep the Nan, which means not omputed for that instance\n",
    "#testDF2=pd.concat([testDF,allpredict],axis=1)\n",
    "#len(testDF2)\n",
    "testDF['index']=testDF.index\n",
    "allpredict['index']=allpredict.index\n",
    "df_pred = pd.merge(testDF,allpredict, how='left', on = 'index')\n",
    "len(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>key</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>index</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76761</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E119</td>\n",
       "      <td>dm2</td>\n",
       "      <td>5902</td>\n",
       "      <td>5905</td>\n",
       "      <td>onciled patient past medical history cholecyst...</td>\n",
       "      <td>76761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693213</td>\n",
       "      <td>76761</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>B182</td>\n",
       "      <td>hepatitis c</td>\n",
       "      <td>6819</td>\n",
       "      <td>6830</td>\n",
       "      <td>lab comp metabolic panel lab glycosolated hemo...</td>\n",
       "      <td>76762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296027</td>\n",
       "      <td>76762</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76763</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>6951</td>\n",
       "      <td>6971</td>\n",
       "      <td>increat random colon cancer screening notes de...</td>\n",
       "      <td>76763</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>76763</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76764</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E782</td>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>7001</td>\n",
       "      <td>7015</td>\n",
       "      <td>declined gi referral vitamin deficiency lab vi...</td>\n",
       "      <td>76764</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>76764</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76765</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>7144</td>\n",
       "      <td>7147</td>\n",
       "      <td>breast cancer screening imaging mammo digital ...</td>\n",
       "      <td>76765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899252</td>\n",
       "      <td>76765</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id   code  \\\n",
       "76761  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E119   \n",
       "76762  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   B182   \n",
       "76763  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E550   \n",
       "76764  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E782   \n",
       "76765  IBXRMA2018_MULT_1231614110010001_HMK_196526763...  I2510   \n",
       "\n",
       "                       text  start_offset  end_offset  \\\n",
       "76761                   dm2          5902        5905   \n",
       "76762           hepatitis c          6819        6830   \n",
       "76763  vitamin d deficiency          6951        6971   \n",
       "76764        hyperlipidemia          7001        7015   \n",
       "76765                   cad          7144        7147   \n",
       "\n",
       "                                                  text75    key  pred  \\\n",
       "76761  onciled patient past medical history cholecyst...  76761     1   \n",
       "76762  lab comp metabolic panel lab glycosolated hemo...  76762     0   \n",
       "76763  increat random colon cancer screening notes de...  76763     0   \n",
       "76764  declined gi referral vitamin deficiency lab vi...  76764     0   \n",
       "76765  breast cancer screening imaging mammo digital ...  76765     1   \n",
       "\n",
       "           prob  index ...  19  20  21  22  23  24  25  26  27  28  \n",
       "76761  0.693213  76761 ... NaN NaN NaN   0   0   0   0   0   0   1  \n",
       "76762  0.296027  76762 ... NaN NaN NaN   0   0   0   0   0   0   0  \n",
       "76763  0.246400  76763 ... NaN NaN NaN   0   0   0   0   0   1   0  \n",
       "76764  0.178136  76764 ... NaN NaN NaN   0   0   0   0   0   0   0  \n",
       "76765  0.899252  76765 ... NaN NaN NaN   0   0   1   1   0   1   1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76766\n"
     ]
    }
   ],
   "source": [
    "# now the data frame with probabilities\n",
    "testDF['index']=testDF.index\n",
    "allprob['index']=allprob.index\n",
    "df_prob = pd.merge(testDF,allprob, how='left', on = 'index')\n",
    "print(len(df_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>key</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>index</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76761</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E119</td>\n",
       "      <td>dm2</td>\n",
       "      <td>5902</td>\n",
       "      <td>5905</td>\n",
       "      <td>onciled patient past medical history cholecyst...</td>\n",
       "      <td>76761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693213</td>\n",
       "      <td>76761</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.272709</td>\n",
       "      <td>0.064432</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.693213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>B182</td>\n",
       "      <td>hepatitis c</td>\n",
       "      <td>6819</td>\n",
       "      <td>6830</td>\n",
       "      <td>lab comp metabolic panel lab glycosolated hemo...</td>\n",
       "      <td>76762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296027</td>\n",
       "      <td>76762</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.072086</td>\n",
       "      <td>0.181318</td>\n",
       "      <td>0.381113</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.306477</td>\n",
       "      <td>0.296027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76763</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>6951</td>\n",
       "      <td>6971</td>\n",
       "      <td>increat random colon cancer screening notes de...</td>\n",
       "      <td>76763</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>76763</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018394</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.686125</td>\n",
       "      <td>0.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76764</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E782</td>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>7001</td>\n",
       "      <td>7015</td>\n",
       "      <td>declined gi referral vitamin deficiency lab vi...</td>\n",
       "      <td>76764</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>76764</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.183114</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.194581</td>\n",
       "      <td>0.178136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76765</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>7144</td>\n",
       "      <td>7147</td>\n",
       "      <td>breast cancer screening imaging mammo digital ...</td>\n",
       "      <td>76765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899252</td>\n",
       "      <td>76765</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154583</td>\n",
       "      <td>0.207874</td>\n",
       "      <td>0.571299</td>\n",
       "      <td>0.816210</td>\n",
       "      <td>0.020743</td>\n",
       "      <td>0.990072</td>\n",
       "      <td>0.899252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id   code  \\\n",
       "76761  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E119   \n",
       "76762  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   B182   \n",
       "76763  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E550   \n",
       "76764  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E782   \n",
       "76765  IBXRMA2018_MULT_1231614110010001_HMK_196526763...  I2510   \n",
       "\n",
       "                       text  start_offset  end_offset  \\\n",
       "76761                   dm2          5902        5905   \n",
       "76762           hepatitis c          6819        6830   \n",
       "76763  vitamin d deficiency          6951        6971   \n",
       "76764        hyperlipidemia          7001        7015   \n",
       "76765                   cad          7144        7147   \n",
       "\n",
       "                                                  text75    key  pred  \\\n",
       "76761  onciled patient past medical history cholecyst...  76761     1   \n",
       "76762  lab comp metabolic panel lab glycosolated hemo...  76762     0   \n",
       "76763  increat random colon cancer screening notes de...  76763     0   \n",
       "76764  declined gi referral vitamin deficiency lab vi...  76764     0   \n",
       "76765  breast cancer screening imaging mammo digital ...  76765     1   \n",
       "\n",
       "           prob  index    ...     19  20  21        22        23        24  \\\n",
       "76761  0.693213  76761    ...    NaN NaN NaN  0.272709  0.064432  0.027841   \n",
       "76762  0.296027  76762    ...    NaN NaN NaN  0.012492  0.072086  0.181318   \n",
       "76763  0.246400  76763    ...    NaN NaN NaN  0.018394  0.025507  0.030261   \n",
       "76764  0.178136  76764    ...    NaN NaN NaN  0.011497  0.027704  0.075676   \n",
       "76765  0.899252  76765    ...    NaN NaN NaN  0.154583  0.207874  0.571299   \n",
       "\n",
       "             25        26        27        28  \n",
       "76761  0.217822  0.013272  0.018055  0.693213  \n",
       "76762  0.381113  0.030548  0.306477  0.296027  \n",
       "76763  0.122995  0.003520  0.686125  0.246400  \n",
       "76764  0.183114  0.005224  0.194581  0.178136  \n",
       "76765  0.816210  0.020743  0.990072  0.899252  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.c. Now combine the prediction from 28 models to make one prediction,it's actually an or operation, but here using sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.160061</td>\n",
       "      <td>0.349433</td>\n",
       "      <td>0.196206</td>\n",
       "      <td>0.026679</td>\n",
       "      <td>0.521088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.021906</td>\n",
       "      <td>0.020609</td>\n",
       "      <td>0.160427</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.197786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.221087</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>0.331177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.047251</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.108050</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.101171</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.253157</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1         2   3   4   5   6   7   8   9  ...    20  21        22  \\\n",
       "0 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.014626   \n",
       "1 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.005715   \n",
       "2 NaN NaN  0.113764 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.008170   \n",
       "3 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.002357   \n",
       "4 NaN NaN  0.125394 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.003010   \n",
       "\n",
       "         23        24        25        26        27        28  index  \n",
       "0  0.063301  0.160061  0.349433  0.196206  0.026679  0.521088      0  \n",
       "1  0.021906  0.020609  0.160427  0.018062  0.008571  0.197786      1  \n",
       "2  0.036722  0.046403  0.221087  0.024644  0.018220  0.331177      2  \n",
       "3  0.006155  0.004079  0.047251  0.002172  0.002319  0.108050      3  \n",
       "4  0.007203  0.021988  0.101171  0.002850  0.004171  0.253157      4  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredictNan=allpredict   # keep the original NaN if that row is not computed for that model\n",
    "allpredict=allpredict.fillna(0) # fill the NaNs by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1    2   3   4   5   6   7   8   9  ...    20  21  22  23  24  25  26  \\\n",
       "0 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "1 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "2 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "3 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "4 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "\n",
       "   27  28  index  \n",
       "0   0   1      0  \n",
       "1   0   0      1  \n",
       "2   0   0      2  \n",
       "3   0   0      3  \n",
       "4   0   0      4  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredictNan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...     20   21  22  23  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "\n",
       "   24  25  26  27  28  index  \n",
       "0   0   0   0   0   1      0  \n",
       "1   0   0   0   0   0      1  \n",
       "2   0   0   0   0   0      2  \n",
       "3   0   0   0   0   0      3  \n",
       "4   0   0   0   0   0      4  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...   19   20   21  22  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "\n",
       "   23  24  25  26  27  28  \n",
       "0   0   0   0   0   0   1  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.drop(['index'],inplace=True, axis=1)\n",
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...   19   20   21  22  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "\n",
       "   23  24  25  26  27  28  \n",
       "0   0   0   0   0   0   1  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allpredict=allpredict[[22,23,24,25,26,27]]  # only select deletion reason columns\n",
    "#allpredict.columns\n",
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredict['Sum'] = allpredict.sum(axis = 1, skipna = True) \n",
    "df_pred['all_model_pred']=[1 if allpredict['Sum'].iloc[i]>=1 else 0 for i in range(len(allpredict))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39345\n",
      "76766\n"
     ]
    }
   ],
   "source": [
    "# check how many 1s are predicted \n",
    "allpredict1=df_pred['all_model_pred']\n",
    "print(sum(allpredict1))\n",
    "print(len(allpredict1))  # 228562 are predicted as deleted out of 418310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the key and predict prob temp columns\n",
    "df_pred.drop(['key','pred','prob','index'],inplace=True, axis=1)\n",
    "df_prob.drop(['key','pred','prob','index'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>all_model_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76761</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E119</td>\n",
       "      <td>dm2</td>\n",
       "      <td>5902</td>\n",
       "      <td>5905</td>\n",
       "      <td>onciled patient past medical history cholecyst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>B182</td>\n",
       "      <td>hepatitis c</td>\n",
       "      <td>6819</td>\n",
       "      <td>6830</td>\n",
       "      <td>lab comp metabolic panel lab glycosolated hemo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76763</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>6951</td>\n",
       "      <td>6971</td>\n",
       "      <td>increat random colon cancer screening notes de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76764</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E782</td>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>7001</td>\n",
       "      <td>7015</td>\n",
       "      <td>declined gi referral vitamin deficiency lab vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76765</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>7144</td>\n",
       "      <td>7147</td>\n",
       "      <td>breast cancer screening imaging mammo digital ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id   code  \\\n",
       "76761  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E119   \n",
       "76762  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   B182   \n",
       "76763  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E550   \n",
       "76764  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E782   \n",
       "76765  IBXRMA2018_MULT_1231614110010001_HMK_196526763...  I2510   \n",
       "\n",
       "                       text  start_offset  end_offset  \\\n",
       "76761                   dm2          5902        5905   \n",
       "76762           hepatitis c          6819        6830   \n",
       "76763  vitamin d deficiency          6951        6971   \n",
       "76764        hyperlipidemia          7001        7015   \n",
       "76765                   cad          7144        7147   \n",
       "\n",
       "                                                  text75   0   1   2   3  \\\n",
       "76761  onciled patient past medical history cholecyst... NaN NaN NaN NaN   \n",
       "76762  lab comp metabolic panel lab glycosolated hemo... NaN NaN NaN NaN   \n",
       "76763  increat random colon cancer screening notes de... NaN NaN NaN NaN   \n",
       "76764  declined gi referral vitamin deficiency lab vi... NaN NaN NaN NaN   \n",
       "76765  breast cancer screening imaging mammo digital ... NaN NaN NaN NaN   \n",
       "\n",
       "            ...        20  21  22  23  24  25  26  27  28  all_model_pred  \n",
       "76761       ...       NaN NaN   0   0   0   0   0   0   1               1  \n",
       "76762       ...       NaN NaN   0   0   0   0   0   0   0               1  \n",
       "76763       ...       NaN NaN   0   0   0   0   0   1   0               1  \n",
       "76764       ...       NaN NaN   0   0   0   0   0   0   0               0  \n",
       "76765       ...       NaN NaN   0   0   1   1   0   1   1               1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.tail()\n",
    "#all_model_pred is check any model output is 1 for that instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chart_id          IBXRMA2018_MULT_1163518440010001_HMK_188344641...\n",
       "code                                                            I10\n",
       "text                                                            i10\n",
       "start_offset                                                   1241\n",
       "end_offset                                                     1244\n",
       "text75            clerotic heart disease native coronary artery ...\n",
       "0                                                               NaN\n",
       "1                                                               NaN\n",
       "2                                                               NaN\n",
       "3                                                               NaN\n",
       "4                                                               NaN\n",
       "5                                                               NaN\n",
       "6                                                               NaN\n",
       "7                                                               NaN\n",
       "8                                                               NaN\n",
       "9                                                               NaN\n",
       "10                                                              NaN\n",
       "11                                                              NaN\n",
       "12                                                                0\n",
       "13                                                              NaN\n",
       "14                                                              NaN\n",
       "15                                                              NaN\n",
       "16                                                              NaN\n",
       "17                                                              NaN\n",
       "18                                                              NaN\n",
       "19                                                              NaN\n",
       "20                                                              NaN\n",
       "21                                                              NaN\n",
       "22                                                                0\n",
       "23                                                                0\n",
       "24                                                                0\n",
       "25                                                                0\n",
       "26                                                                0\n",
       "27                                                                0\n",
       "28                                                                0\n",
       "all_model_pred                                                    0\n",
       "Name: 135, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.iloc[135]   # just check one instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      'chart_id',           'code',           'text',   'start_offset',\n",
       "           'end_offset',         'text75',                0,                1,\n",
       "                      2,                3,                4,                5,\n",
       "                      6,                7,                8,                9,\n",
       "                     10,               11,               12,               13,\n",
       "                     14,               15,               16,               17,\n",
       "                     18,               19,               20,               21,\n",
       "                     22,               23,               24,               25,\n",
       "                     26,               27,               28, 'all_model_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    'chart_id',         'code',         'text', 'start_offset',\n",
       "         'end_offset',       'text75',              0,              1,\n",
       "                    2,              3,              4,              5,\n",
       "                    6,              7,              8,              9,\n",
       "                   10,             11,             12,             13,\n",
       "                   14,             15,             16,             17,\n",
       "                   18,             19,             20,             21,\n",
       "                   22,             23,             24,             25,\n",
       "                   26,             27,             28],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models_update0531/Deletion_Consolidated_LRMay2919.pickle']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# if running refreshed model, use this rename\\n# rename the columns names, has to be consistent with the above order\\n# since there's no 0, or 1, 17, these models didn't run because no data for them\\n\\ncol_dict = {0: 'Phrase_stroke', 1: 'Phrase_emphysema',2:'Phrase_hypertension',3:'Phrase_dementia',4:'Phrase_cholesterol',\\n           5:'Phrase_cad',6:'Phrase_aneurysm',7:'Code_COPD',8:'Code_Depression',9:'Code_Diabetes',10:'Code_Heart',\\n           11:'Code_Kidney',12:'Code_Model1',13:'Code_Cancer',14:'Code_Cholesterol',15:'Code_Model2',\\n           16:'Code_Model3',17:'Phrase_asthma',18:'Phrase_cancer',19:'Phrase_ckd',20:'Phrase_depression',21:'Phrase_diabetes',\\n            22:'DeletionReason_family_history',23:'DeletionReason_negation',24:'DeletionReason_not_doctors_note',\\n           25:'DeletionReason_not_relevant',26:'DeletionReason_phoneORaddressORother_number',27:'DeletionReason_preventative_screening',\\n           }   ## keyold name, valuenew name\\n\\ndf_pred.columns = [col_dict.get(x, x) for x in df_pred.columns]\\ndf_prob.columns = [col_dict.get(x, x) for x in df_prob.columns]\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# if running refreshed model, use this rename\n",
    "# rename the columns names, has to be consistent with the above order\n",
    "# since there's no 0, or 1, 17, these models didn't run because no data for them\n",
    "\n",
    "col_dict = {0: 'Phrase_stroke', 1: 'Phrase_emphysema',2:'Phrase_hypertension',3:'Phrase_dementia',4:'Phrase_cholesterol',\n",
    "           5:'Phrase_cad',6:'Phrase_aneurysm',7:'Code_COPD',8:'Code_Depression',9:'Code_Diabetes',10:'Code_Heart',\n",
    "           11:'Code_Kidney',12:'Code_Model1',13:'Code_Cancer',14:'Code_Cholesterol',15:'Code_Model2',\n",
    "           16:'Code_Model3',17:'Phrase_asthma',18:'Phrase_cancer',19:'Phrase_ckd',20:'Phrase_depression',21:'Phrase_diabetes',\n",
    "            22:'DeletionReason_family_history',23:'DeletionReason_negation',24:'DeletionReason_not_doctors_note',\n",
    "           25:'DeletionReason_not_relevant',26:'DeletionReason_phoneORaddressORother_number',27:'DeletionReason_preventative_screening',\n",
    "           }   ## keyold name, valuenew name\n",
    "\n",
    "df_pred.columns = [col_dict.get(x, x) for x in df_pred.columns]\n",
    "df_prob.columns = [col_dict.get(x, x) for x in df_prob.columns]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running pipeline models, use this rename\n",
    "# rename the columns names, has to be consistent with the above order  \n",
    "# since there's no 0, or 1, 17, these models didn't run because no data for them\n",
    " ## keyold name, valuenew name\n",
    "col_dict = {0:'Code_Cholesterol' , 1: 'DeletionReason_family_history',2:'DeletionReason_negation',3:'DeletionReason_not_doctors_note',4:'Code_Model2',\n",
    "           5:'DeletionReason_not_relevant',6:'Phrase_stroke',7:'Phrase_hypertension',8:'Phrase_emphysema',9:'Phrase_diabetes',10:'Phrase_depression',\n",
    "           11:'Phrase_dementia',12:'Phrase_ckd',13:'Phrase_cholesterol',14:'Phrase_cancer',15:'Phrase_cad',\n",
    "           16:'Phrase_asthma',17:'Phrase_aneurysm',18:'DeletionReason_preventative_screening',19:'DeletionReason_phoneORaddressORother_number',20:'Code_Model3',21:'Code_Model1',\n",
    "            22:'Code_Kidney',23:'Code_Heart',24:'Code_Diabetes',\n",
    "           25:'Code_Depression',26:'Code_COPD',27:'Code_Cancer', 28:'consolidated_LR'\n",
    "           }  \n",
    "\n",
    "df_pred.columns = [col_dict.get(x, x) for x in df_pred.columns]\n",
    "df_prob.columns = [col_dict.get(x, x) for x in df_prob.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                   'chart_id',\n",
       "                                              'code',\n",
       "                                              'text',\n",
       "                                      'start_offset',\n",
       "                                        'end_offset',\n",
       "                                            'text75',\n",
       "                                  'Code_Cholesterol',\n",
       "                     'DeletionReason_family_history',\n",
       "                           'DeletionReason_negation',\n",
       "                   'DeletionReason_not_doctors_note',\n",
       "                                       'Code_Model2',\n",
       "                       'DeletionReason_not_relevant',\n",
       "                                     'Phrase_stroke',\n",
       "                               'Phrase_hypertension',\n",
       "                                  'Phrase_emphysema',\n",
       "                                   'Phrase_diabetes',\n",
       "                                 'Phrase_depression',\n",
       "                                   'Phrase_dementia',\n",
       "                                        'Phrase_ckd',\n",
       "                                'Phrase_cholesterol',\n",
       "                                     'Phrase_cancer',\n",
       "                                        'Phrase_cad',\n",
       "                                     'Phrase_asthma',\n",
       "                                   'Phrase_aneurysm',\n",
       "             'DeletionReason_preventative_screening',\n",
       "       'DeletionReason_phoneORaddressORother_number',\n",
       "                                       'Code_Model3',\n",
       "                                       'Code_Model1',\n",
       "                                       'Code_Kidney',\n",
       "                                        'Code_Heart',\n",
       "                                     'Code_Diabetes',\n",
       "                                   'Code_Depression',\n",
       "                                         'Code_COPD',\n",
       "                                       'Code_Cancer',\n",
       "                                                  28,\n",
       "                                    'all_model_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred.rename(columns={'start': 'start_offset', 'end': 'end_offset'}, inplace=True)\n",
    "#df_pred[['chart_id','start_offset','end_offset','DeletionReason_family_history']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prob.rename(columns={'start': 'start_offset', 'end': 'end_offset'}, inplace=True)\n",
    "#df_prob[['chart_id','start_offset','end_offset','DeletionReason_family_history']].tail()  #ok make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred.to_csv('run1000charts_pred_0521.csv')   #  with prediction for each model and all model combined\n",
    "#df_prob.to_csv('probdataforcompwithAM_0506.csv')   #  with probability for each model\n",
    "# finally corrected a lot of errors like index not reset issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n",
      "980\n"
     ]
    }
   ],
   "source": [
    "print(len(set(df_pred['chart_id'].tolist())))\n",
    "print(len(set(df_prob['chart_id'].tolist())))   # 813 unique chart ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.d. Load LSTM model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load modules\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../picklefolder_ngrams/temp_4deletionmodels_refreshed/keras_tokenizer_embeddings_0328.pickle\", \"rb\") as f:\n",
    "   tokenizer = pickle.load(f)    # lOAD tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76766\n",
      "(76766, 70)\n"
     ]
    }
   ],
   "source": [
    "print(len(testDF))\n",
    "# tokenize the test dataset\n",
    "sequences = tokenizer.texts_to_sequences(testDF['text75'].values)\n",
    "#word_index = tokenizer.word_index\n",
    "#print('Found %s unique tokens.' % len(word_index))\n",
    "testX1 = pad_sequences(sequences, maxlen=max_len)\n",
    "#y_test1 = testdf['flag']\n",
    "print(testX1.shape)  # ,y_test1.shape)    # no flag for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0624 19:41:58.744635 139737363326784 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0624 19:41:58.758430 139737363326784 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0624 19:41:58.775067 139737363326784 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0624 19:41:58.775788 139737363326784 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0624 19:41:58.925335 139737363326784 deprecation.py:506] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0624 19:41:59.032157 139737363326784 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0624 19:41:59.054514 139737363326784 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0624 19:41:59.073861 139737363326784 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0624 19:41:59.088598 139737363326784 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0624 19:41:59.105479 139737363326784 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0624 19:41:59.322753 139737363326784 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0624 19:41:59.504624 139737363326784 deprecation_wrapper.py:119] From /opt/conda/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0624 19:41:59.512288 139737363326784 deprecation.py:323] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# load the lstm model\n",
    "model2=joblib.load('../../picklefolder_ngrams/temp_4deletionmodels_refreshed/DeleteReason_biclass_Mar2819_lstm.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictiont2 = model2.predict(testX1)\n",
    "\n",
    "finallabelt1= (predictiont2 > 0.4).astype(np.int)    # using different threshold\n",
    "#finallabelt2= (predictiont2 > 0.3).astype(np.int) \n",
    "#finallabelt3= (predictiont2 > 0.2).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 3. Load in coder feedback and  evaluate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select common chart_ids from both 1000 model run and 6000 coder annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                   'chart_id',\n",
       "                                              'code',\n",
       "                                              'text',\n",
       "                                      'start_offset',\n",
       "                                        'end_offset',\n",
       "                                            'text75',\n",
       "                                  'Code_Cholesterol',\n",
       "                     'DeletionReason_family_history',\n",
       "                           'DeletionReason_negation',\n",
       "                   'DeletionReason_not_doctors_note',\n",
       "                                       'Code_Model2',\n",
       "                       'DeletionReason_not_relevant',\n",
       "                                     'Phrase_stroke',\n",
       "                               'Phrase_hypertension',\n",
       "                                  'Phrase_emphysema',\n",
       "                                   'Phrase_diabetes',\n",
       "                                 'Phrase_depression',\n",
       "                                   'Phrase_dementia',\n",
       "                                        'Phrase_ckd',\n",
       "                                'Phrase_cholesterol',\n",
       "                                     'Phrase_cancer',\n",
       "                                        'Phrase_cad',\n",
       "                                     'Phrase_asthma',\n",
       "                                   'Phrase_aneurysm',\n",
       "             'DeletionReason_preventative_screening',\n",
       "       'DeletionReason_phoneORaddressORother_number',\n",
       "                                       'Code_Model3',\n",
       "                                       'Code_Model1',\n",
       "                                       'Code_Kidney',\n",
       "                                        'Code_Heart',\n",
       "                                     'Code_Diabetes',\n",
       "                                   'Code_Depression',\n",
       "                                         'Code_COPD',\n",
       "                                       'Code_Cancer',\n",
       "                                                  28,\n",
       "                                    'all_model_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['lstm_red']=finallabelt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9 ...    20   21  22  23  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   0   0   \n",
       "\n",
       "   24  25  26  27  28  Sum  \n",
       "0   0   0   0   0   1  1.0  \n",
       "1   0   0   0   0   0  0.0  \n",
       "2   0   0   0   0   0  0.0  \n",
       "3   0   0   0   0   0  0.0  \n",
       "4   0   0   0   0   0  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "          10,    11,    12,    13,    14,    15,    16,    17,    18,    19,\n",
       "          20,    21,    22,    23,    24,    25,    26,    27,    28, 'Sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...   19   20   21  22  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "\n",
       "   23  24  25  26  27  28  \n",
       "0   0   0   0   0   0   1  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict_28=allpredict[[0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
    "          10,    11,    12,    13,    14,    15,    16,    17,    18,    19,\n",
    "          20,    21,    22,    23,    24,    25,    26,    27, 28]]\n",
    "allpredict_28.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredict_28['lstm']=finallabelt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>lstm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...    20   21  22  23  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   0   0   \n",
       "\n",
       "   24  25  26  27  28  lstm  \n",
       "0   0   0   0   0   1     1  \n",
       "1   0   0   0   0   0     0  \n",
       "2   0   0   0   0   0     0  \n",
       "3   0   0   0   0   0     0  \n",
       "4   0   0   0   0   0     0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict_28.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredict_28['Sum'] = allpredict_28.sum(axis = 1, skipna = True) \n",
    "df_pred['all_model_pred']=[1 if allpredict_28['Sum'].iloc[i]>=1 else 0 for i in range(len(allpredict))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963\n",
      "76766\n"
     ]
    }
   ],
   "source": [
    "allpredict1=df_pred['all_model_pred']\n",
    "print(sum(allpredict1))\n",
    "print(len(allpredict1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred['all_model_pred']=df_pred['DeletionReason_not_relevant']\n",
    "#model_name='Code_Cholesterol'\n",
    "#df_pred['all_model_pred']=df_pred['DeletionReason_family_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76766\n",
      "76766\n"
     ]
    }
   ],
   "source": [
    "# model computation\n",
    "df_pred1=df_pred[['chart_id', 'code', 'text', 'start_offset', 'end_offset', 'text75','all_model_pred']]\n",
    "print(len(df_pred1))\n",
    "df_pred1 = df_pred1.drop_duplicates()\n",
    "print(len(df_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136527\n"
     ]
    }
   ],
   "source": [
    "# read in all charts with coder feedback\n",
    "df_codeall = pd.read_csv('/home/jovyan/work/Analytics_Data_training/conditions_with_chartids_29042019.csv') # 1000 charts\n",
    "#df_codeall = pd.read_csv('/home/jovyan/work/Analytics_Data_training/conditions_output_withchart_id_100619.csv') #7500 chart\n",
    "print(len(df_codeall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chart is in 1000 charts run model output: 980\n",
      "unique chart is in 6000 charts with coder feedback: 5982\n"
     ]
    }
   ],
   "source": [
    "print(\"unique chart is in 1000 charts run model output:\",df_pred1['chart_id'].nunique())\n",
    "print(\"unique chart is in 6000 charts with coder feedback:\",df_codeall['chart_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n"
     ]
    }
   ],
   "source": [
    "# now find overlap chart ids\n",
    "overlapped_charts = pd.merge(df_codeall[['chart_id']].drop_duplicates(),df_pred1[['chart_id']].drop_duplicates(), how = 'inner')\n",
    "overlapped_charts = list(overlapped_charts['chart_id'].unique())\n",
    "print(len(overlapped_charts))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60131"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the model output\n",
    "fd_prod = df_pred1[['chart_id','code','start_offset','end_offset','text75','all_model_pred']][df_pred1['chart_id'].isin(overlapped_charts)].drop_duplicates()\n",
    "len(fd_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60131\n"
     ]
    }
   ],
   "source": [
    "# select the model output, if it's individual model, need to select those not NaN instances only\n",
    "fd_prod.dropna(inplace=True)\n",
    "print(len(fd_prod))\n",
    "#fd_prod.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30057\n",
      "17974\n",
      "3232\n",
      "8851\n"
     ]
    }
   ],
   "source": [
    "# select those in the code output\n",
    "data = df_codeall[df_codeall['chart_id'].isin(overlapped_charts)]\n",
    "print(len(data))\n",
    "print(len(data[data['label'] == 'added']))\n",
    "print(len(data[data['label'] == 'deleted']))\n",
    "print(len(data[data['label'] == 'agreed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TNh: 48048\n",
      "TNh: 33306\n"
     ]
    }
   ],
   "source": [
    "# The pipeline TN can be computed as, the following is not true negative yet\n",
    "TNh= len(fd_prod)-(len(data)-len(data[data['label'] == 'added']))\n",
    "print(\"TNh:\",TNh)\n",
    "TNh= len(fd_prod)-(len(data)-len(data[data['label'] == 'deleted']))\n",
    "print(\"TNh:\",TNh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accurary number for the pipeline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16376\n",
      "770\n",
      "9168\n"
     ]
    }
   ],
   "source": [
    "# Use fuzzy logic to compute the deleted, added, agreed\n",
    "data = data[data['start'] != 0]\n",
    "data = data[data['end'] != 0]\n",
    "#data = data[data['created_at'] == date ] ##Change date to filter for datewise data\n",
    "#label_counts = data.groupby(['label']).size().reset_index(name='counts')\n",
    "instmatches = data[data['label'] == 'agreed']\n",
    "instfuzzymatches = data[data['label'] == 'deleted']\n",
    "instfuzzymatches = instfuzzymatches[instfuzzymatches['deleted_reason'].isin(['Incorrect Specification - Non-Risk Adjusted','repeated_instance','incorrect_year_of_service']) ]\n",
    "instmatches = pd.concat([instmatches, instfuzzymatches])\n",
    "instmatches = instmatches[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "instdeleted = data[data['label'] == 'deleted']\n",
    "instdeleted = instdeleted[instdeleted['deleted_reason'] != 'other']\n",
    "instdeleted = pd.merge(instdeleted, instmatches,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "instdeleted = instdeleted[instdeleted['_merge'] == 'left_only']\n",
    "instdeleted = instdeleted[['chart_id','submission_id','code_id','start','end','deleted_reason']].drop_duplicates()\n",
    "deleted_reason = instdeleted.groupby(['deleted_reason']).size().reset_index(name = 'counts')\n",
    "instdeleted = instdeleted[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "\n",
    "instadded = data[data['label'] == 'added']\n",
    "instadded = pd.merge(instadded, instmatches,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "instadded = instadded[instadded['_merge'] == 'left_only']\n",
    "instadded = instadded[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "instadded = pd.merge(instadded, instdeleted,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "instadded = instadded[instadded['_merge'] == 'left_only']\n",
    "instadded = instadded[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "added = len(instadded)\n",
    "deleted = len(instdeleted)\n",
    "agreed = len(instmatches)\n",
    "print(added)\n",
    "print(deleted)\n",
    "print(agreed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chart_id', 'submission_id', 'code_id', 'start', 'end'], dtype='object')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instmatches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my added small part\n",
    "instmatchessub=instmatches[['chart_id', 'code_id', 'submission_id','start','end']]\n",
    "instmatchessub.columns = ['chart_id', 'code_id','submission_id', 'start_offset', 'end_offset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60131"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "instadded.columns = ['chart_id', 'submission_id', 'code_id', 'start_offset', 'end_offset']\n",
    "prod_additions_models = pd.merge(instadded, fd_prod,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "prod_additions_models['abs_diff_start'] = abs(prod_additions_models['start_offset_x'] - prod_additions_models['start_offset_y'])\n",
    "prod_additions_models['abs_diff_end'] = abs(prod_additions_models['end_offset_x'] - prod_additions_models['end_offset_y'])\n",
    "prod_additions_models1 = prod_additions_models[ (\n",
    "                    (prod_additions_models['code_id'] == prod_additions_models['code']) \n",
    "                    & (prod_additions_models['abs_diff_start'] <= 75))\n",
    "          | (prod_additions_models['start_offset_x'] == prod_additions_models['start_offset_y'])\n",
    "          | (prod_additions_models['end_offset_x'] == prod_additions_models['end_offset_y'])\n",
    "          |((prod_additions_models['code_id'] == prod_additions_models['code']) \n",
    "                    & (prod_additions_models['abs_diff_end'] <= 75))\n",
    "          ]\n",
    "instadded_modeldeleted = prod_additions_models1[['chart_id','submission_id','code','start_offset_y','end_offset_y']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15514"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instadded_modeldeleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 9168\n",
      "TN: 48048\n",
      "FN: 16376\n",
      "FP: 770\n",
      "precision: 0.9225196216542564\n",
      "recall: 0.3589101158784842\n",
      "accuracy: 0.7694252440762755\n",
      "-------------------\n",
      "Agreements =  9168\n",
      "Deletions =  770\n",
      "Additions =  16376\n"
     ]
    }
   ],
   "source": [
    "# initial numbers considering all the additions data for recall\n",
    "\n",
    "total = len(instmatches) + len(instdeleted) + len(instadded)\n",
    "added = len(instadded)\n",
    "deleted = len(instdeleted)\n",
    "agreed = len(instmatches)\n",
    "\n",
    "TP = agreed\n",
    "FN = added\n",
    "FP = deleted\n",
    "TN= len(fd_prod)-(len(data)-len(data[data['label'] == 'added']))\n",
    "\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n",
    "\n",
    "print('-------------------')\n",
    "print('Agreements = ', agreed)\n",
    "print('Deletions = ', deleted)\n",
    "print('Additions = ', added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 9168\n",
      "TN: 48048\n",
      "FN: 15514\n",
      "FP: 770\n",
      "precision: 0.9225196216542564\n",
      "recall: 0.37144477757069927\n",
      "accuracy: 0.7784489795918368\n",
      "-------------------\n",
      "Agreements =  9168\n",
      "Deletions =  770\n",
      "Additions =  15514\n"
     ]
    }
   ],
   "source": [
    "# initial numbers considering model deleted additions data for recall\n",
    "\n",
    "total = len(instmatches) + len(instdeleted) + len(instadded_modeldeleted)\n",
    "added = len(instadded_modeldeleted)\n",
    "deleted = len(instdeleted)\n",
    "agreed = len(instmatches)\n",
    "\n",
    "TP = agreed\n",
    "FN = added\n",
    "FP = deleted\n",
    "TN1= len(fd_prod)-(len(data)-len(data[data['label'] == 'added']))\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN1+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n",
    "\n",
    "print('-------------------')\n",
    "print('Agreements = ', agreed)\n",
    "print('Deletions = ', deleted)\n",
    "print('Additions = ', added)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Evaluated   Model accuracy numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76766\n"
     ]
    }
   ],
   "source": [
    "print(len(df_pred1))   # model output with all the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60131\n"
     ]
    }
   ],
   "source": [
    "print(len(fd_prod))  # already selected  the 798 chart  from previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chart_id          object\n",
       "code              object\n",
       "start_offset       int64\n",
       "end_offset         int64\n",
       "text75            object\n",
       "all_model_pred     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_prod.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 32100\n"
     ]
    }
   ],
   "source": [
    "TN=len(fd_prod[fd_prod['all_model_pred']==1])  # predicted deleted instances, but not true negative\n",
    "print(\"TN:\",TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28031"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select those 708 charts and only passed the filtering not deleted, 0 is keep here\n",
    "\n",
    "dev_df_sub_1 = fd_prod[fd_prod['all_model_pred']==0]  # select the 798 chart\n",
    "len(dev_df_sub_1[['chart_id','start_offset']].drop_duplicates())  # 37085 pass through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_sub_1.rename(columns={'start_offset':'start','end_offset':'end'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_sub_1.rename(columns={'code':'code_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches = pd.merge(dev_df_sub_1[['chart_id','start']], instmatches,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "new_deleted = pd.merge(dev_df_sub_1[['chart_id','start']], instdeleted,how = 'inner', on = ['chart_id','start'], indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "instadded.columns = ['chart_id', 'submission_id', 'code_id', 'start', 'end']\n",
    "new_added = pd.merge(dev_df_sub_1, instadded,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "new_added['abs_diff_start'] = abs(new_added['start_x'] - new_added['start_y'])\n",
    "new_added['abs_diff_end'] = abs(new_added['end_x'] - new_added['end_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_added1 = new_added[ (\n",
    "                    (new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                    & (new_added['abs_diff_start'] <= 5))\n",
    "          | (new_added['start_x'] == new_added['start_y'])\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. if the start offset matches exactly\n",
    "#2. If the end offset matches exactly\n",
    "#3. If the overlap of start offset is between 75 characters and the code id matches\n",
    "#4. If the overlap of end offset is between 75 characters and the code id matches\n",
    "new_added2 = new_added[ (\n",
    "                    (new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                    & (new_added['abs_diff_start'] <= 75))\n",
    "          | (new_added['start_x'] == new_added['start_y'])\n",
    "          | (new_added['end_x'] == new_added['end_y'])\n",
    "          |((new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                    & (new_added['abs_diff_end'] <= 75))\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chart_id', 'submission_id', 'code', 'start_offset_y', 'end_offset_y'], dtype='object')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instadded_modeldeleted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11673"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just validating the additions with a different method of calculation\n",
    "instadded_modeldeleted.columns = ['chart_id', 'submission_id', 'code_id', 'start', 'end']\n",
    "x = pd.merge(dev_df_sub_1[['chart_id','start']].drop_duplicates()\n",
    "             , instadded_modeldeleted[['chart_id','start']].drop_duplicates()\n",
    "             ,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8519\n",
      "572\n",
      "8434\n",
      "11673\n"
     ]
    }
   ],
   "source": [
    "print(len(new_matches))\n",
    "print(len(new_deleted))\n",
    "print(len(new_added1[['chart_id','start_x']].drop_duplicates()))\n",
    "print(len(new_added2[['chart_id','start_x']].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16953\n",
      "11078\n",
      "7080\n",
      "--------\n",
      "20192\n",
      "7839\n",
      "3841\n"
     ]
    }
   ],
   "source": [
    "#type 1 - older number of additions considering only start offset\n",
    "refreshed_agreements1 = int(len(new_matches)) + int(len(new_added1[['chart_id','start_x']].drop_duplicates()))\n",
    "refreshed_deletions1 = int(len(dev_df_sub_1[['chart_id','start']].drop_duplicates())) - (int(len(new_matches)) + int(len(new_added1[['chart_id','start_x']].drop_duplicates()))) \n",
    "refreshed_additions1 = added - int(len(new_added1[['chart_id','start_x']].drop_duplicates()))\n",
    "\n",
    "#type 2 - new number of additions considering start offset and end offset\n",
    "refreshed_agreements2 = int(len(new_matches)) + int(len(new_added2[['chart_id','start_x']].drop_duplicates()))\n",
    "refreshed_deletions2 = int(len(dev_df_sub_1[['chart_id','start']].drop_duplicates())) - (int(len(new_matches)) + int(len(new_added2[['chart_id','start_x']].drop_duplicates()))) \n",
    "refreshed_additions2 = added - int(len(new_added2[['chart_id','start_x']].drop_duplicates()))\n",
    "\n",
    "print(refreshed_agreements1)\n",
    "print(refreshed_deletions1)\n",
    "print(refreshed_additions1)\n",
    "print(\"--------\")\n",
    "print(refreshed_agreements2)\n",
    "print(refreshed_deletions2)\n",
    "print(refreshed_additions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35111\n",
      "31872\n"
     ]
    }
   ],
   "source": [
    "refreshed_total1 = refreshed_agreements1 + refreshed_deletions1 + refreshed_additions1\n",
    "refreshed_total2 = refreshed_agreements2 + refreshed_deletions2 + refreshed_additions2\n",
    "print(refreshed_total1)\n",
    "print(refreshed_total2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32100\n",
      "28031\n"
     ]
    }
   ],
   "source": [
    "# my added part of calculating TN\n",
    "fd_prodsub=fd_prod[fd_prod['all_model_pred']==1]\n",
    "fd_prodsub2=fd_prod[fd_prod['all_model_pred']==0]\n",
    "print(len(fd_prodsub))   # predicted as delete\n",
    "print(len(fd_prodsub2))  # not deleted, presented to coder\n",
    "fd_prodsub.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "       'all_model_pred']   # model predicted as deleted\n",
    "fd_prodsub2.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "       'all_model_pred']   # model predicted as passing through or agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "instaddedsub=instadded[['chart_id', 'submission_id','code_id', 'start','end']]\n",
    "instaddedsub.columns = ['chart_id', 'submission_id', 'code_id', 'start_offset', 'end_offset']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_prodsub.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "       'all_model_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4112"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instmatchedaddedsub = pd.concat([instaddedsub,instmatchessub])\n",
    "#instmatchedaddedsub=instmatchedaddedsub[['chart_id', 'code_id', 'submission_id','start','end']]\n",
    "#instmatchedaddedsub.columns = ['chart_id', 'code_id','submission_id', 'start_offset', 'end_offset']\n",
    "#print(len(instmatchedaddedsub))  # 25273\n",
    "prod_agree_models = pd.merge(instmatchedaddedsub, fd_prodsub,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "len(prod_agree_models)\n",
    "\n",
    "prod_agree_models['abs_diff_start'] = abs(prod_agree_models['start_offset_x'] - prod_agree_models['start_offset_y'])\n",
    "prod_agree_models['abs_diff_end'] = abs(prod_agree_models['end_offset_x'] - prod_agree_models['end_offset_y'])\n",
    "\n",
    "prod_agree_models1 = prod_agree_models[ (\n",
    "                    (prod_agree_models['code_id_x'] == prod_agree_models['code_id_y']) \n",
    "                    & (prod_agree_models['abs_diff_start'] <= 5))\n",
    "          | (prod_agree_models['start_offset_x'] == prod_agree_models['start_offset_y'])\n",
    "          | (prod_agree_models['end_offset_x'] == prod_agree_models['end_offset_y'])\n",
    "          |((prod_agree_models['code_id_x'] == prod_agree_models['code_id_y']) \n",
    "                    & (prod_agree_models['abs_diff_end'] <= 5))\n",
    "          ]\n",
    "\n",
    "instaddagreed_modeldeleted = prod_agree_models1[['chart_id','submission_id','code_id_x','code_id_y','start_offset_x','end_offset_x']].drop_duplicates()\n",
    "len(instaddagreed_modeldeleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance level New Models:\n",
      "Agreements =  48.284013557004926 %\n",
      "Deletions =  31.5513656688787 %\n",
      "Additions =  20.164620774116372 %\n",
      "Precision =  60.47946915914523 %\n",
      "Recall =  70.54050680314568 %\n",
      "-------------------\n",
      "Agreements =  16953\n",
      "Deletions =  11078\n",
      "Additions =  7080\n",
      "TP: 16953\n",
      "TN: 27988\n",
      "FN: 7080\n",
      "FP: 11078\n",
      "precision: 0.6047946915914523\n",
      "recall: 0.7054050680314568\n",
      "accuracy: 0.712229987796954\n"
     ]
    }
   ],
   "source": [
    "#type 1 calculation\n",
    "\n",
    "print('Instance level New Models:')\n",
    "print('Agreements = ', refreshed_agreements1*100/refreshed_total1,'%')\n",
    "print('Deletions = ', refreshed_deletions1*100/refreshed_total1,'%')\n",
    "print('Additions = ', refreshed_additions1*100/refreshed_total1,'%')\n",
    "print('Precision = ', refreshed_agreements1*100/(refreshed_agreements1+refreshed_deletions1),'%')\n",
    "print('Recall = ', refreshed_agreements1*100/(refreshed_agreements1+refreshed_additions1),'%')\n",
    "print('-------------------')\n",
    "print('Agreements = ', refreshed_agreements1)\n",
    "print('Deletions = ', refreshed_deletions1)\n",
    "print('Additions = ', refreshed_additions1)\n",
    "\n",
    "TP = refreshed_agreements1\n",
    "FP = refreshed_deletions1\n",
    "FN = refreshed_additions1\n",
    "\n",
    "TN=len(fd_prod[fd_prod['all_model_pred']==1])-len(instaddagreed_modeldeleted)  # deleted instances\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance level New Models:\n",
      "Agreements =  63.35341365461847 %\n",
      "Deletions =  24.595256024096386 %\n",
      "Additions =  12.05133032128514 %\n",
      "Precision =  72.03453319539082 %\n",
      "Recall =  84.01780884616986 %\n",
      "-------------------\n",
      "Agreements =  20192\n",
      "Deletions =  7839\n",
      "Additions =  3841\n",
      "TP: 20192\n",
      "TN: 27988\n",
      "FN: 3841\n",
      "FP: 7839\n",
      "precision: 0.7203453319539082\n",
      "recall: 0.8401780884616985\n",
      "accuracy: 0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "#type 2 calculation\n",
    "\n",
    "print('Instance level New Models:')\n",
    "print('Agreements = ', refreshed_agreements2*100/refreshed_total2,'%')\n",
    "print('Deletions = ', refreshed_deletions2*100/refreshed_total2,'%')\n",
    "print('Additions = ', refreshed_additions2*100/refreshed_total2,'%')\n",
    "print('Precision = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_deletions2),'%')\n",
    "print('Recall = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_additions2),'%')\n",
    "print('-------------------')\n",
    "print('Agreements = ', refreshed_agreements2)\n",
    "print('Deletions = ', refreshed_deletions2)\n",
    "print('Additions = ', refreshed_additions2)\n",
    "\n",
    "\n",
    "\n",
    "TP = refreshed_agreements2\n",
    "FP = refreshed_deletions2\n",
    "FN = refreshed_additions2\n",
    "\n",
    "TN=len(fd_prod[fd_prod['all_model_pred']==1])-len(instaddagreed_modeldeleted)  # deleted instances\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a html copy\n",
    "#!jupyter nbconvert --to html all28refreshedmodels_comptoAMresult_050819-deleteinstances.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
