{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import os,boto3,sys,glob,json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1  Loading the  data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testDF=pd.read_csv('run1000charts_0521.csv')\n",
    "testDF= pd.read_csv('/home/jovyan/work/Analytics_Data_training/bfAI_allinst_7502charts_061019.csv') # 7502 charts\n",
    "# the csv is generated in D drive D:/chartai_qa  with extract1000charts_jsontxt.py, then uploaded to here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418518"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'chart_id', 'code', 'text', 'start_offset', 'end_offset',\n",
       "       'text75'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF=testDF.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBXRMA2018_MULT_1218010190010001_HMK_188263480...</td>\n",
       "      <td>E785</td>\n",
       "      <td>Hyperlipidemia</td>\n",
       "      <td>2526</td>\n",
       "      <td>2540</td>\n",
       "      <td>b12 deficiency vitamin deficiency intertrigo b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBXRMA2018_MULT_1218010190010001_HMK_188263480...</td>\n",
       "      <td>I10</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>2543</td>\n",
       "      <td>2555</td>\n",
       "      <td>vitamin deficiency intertrigo bmi 350359adult ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBXRMA2018_MULT_1218010190010001_HMK_188263480...</td>\n",
       "      <td>G20</td>\n",
       "      <td>Parkinson's Disease</td>\n",
       "      <td>3258</td>\n",
       "      <td>3277</td>\n",
       "      <td>parkinsons fu history present illness 82 yo wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBXRMA2018_MULT_1218010190010001_HMK_188263480...</td>\n",
       "      <td>E46</td>\n",
       "      <td>deficiency</td>\n",
       "      <td>3972</td>\n",
       "      <td>3982</td>\n",
       "      <td>elchair bound minimal transfer bradykinesis ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBXRMA2018_MULT_1218010190010001_HMK_188263480...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>2468</td>\n",
       "      <td>2488</td>\n",
       "      <td>er quadrant abdominal pelvic swelling mass lum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            chart_id  code  \\\n",
       "0  IBXRMA2018_MULT_1218010190010001_HMK_188263480...  E785   \n",
       "1  IBXRMA2018_MULT_1218010190010001_HMK_188263480...   I10   \n",
       "2  IBXRMA2018_MULT_1218010190010001_HMK_188263480...   G20   \n",
       "3  IBXRMA2018_MULT_1218010190010001_HMK_188263480...   E46   \n",
       "4  IBXRMA2018_MULT_1218010190010001_HMK_188263480...  E550   \n",
       "\n",
       "                   text  start_offset  end_offset  \\\n",
       "0        Hyperlipidemia          2526        2540   \n",
       "1          Hypertension          2543        2555   \n",
       "2   Parkinson's Disease          3258        3277   \n",
       "3            deficiency          3972        3982   \n",
       "4  vitamin d deficiency          2468        2488   \n",
       "\n",
       "                                              text75  \n",
       "0  b12 deficiency vitamin deficiency intertrigo b...  \n",
       "1  vitamin deficiency intertrigo bmi 350359adult ...  \n",
       "2  parkinsons fu history present illness 82 yo wh...  \n",
       "3  elchair bound minimal transfer bradykinesis ac...  \n",
       "4  er quadrant abdominal pelvic swelling mass lum...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just check if there's null text, if yes, remove them \n",
    "nulltext=testDF[~pd.notnull(testDF['text'])] \n",
    "len(nulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulltext=testDF[~pd.notnull(testDF['text75'])] \n",
    "len(nulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>IBXRMA2018_MULT_1216944220010001_HMK_195147709...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>IBXRMA2018_MULT_1217060910010001_HMK_097164250...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>IBXRMA2018_MULT_1216129800010001_HMK_239481844...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>IBXRMA2018_MULT_1218015600010001_HMK_3GM6V72QA...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8082</th>\n",
       "      <td>IBXRMA2018_MULT_1216901800010001_HMK_201224196...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>IBXRMA2018_MULT_1217591910010001_HMK_168240489...</td>\n",
       "      <td>E780</td>\n",
       "      <td>cholesterol</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14436</th>\n",
       "      <td>IBXRMA2018_MULT_1216874020010001_HMK_143364782...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18295</th>\n",
       "      <td>IBXRMA2018_MULT_1217464990010001_HMK_175243784...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21856</th>\n",
       "      <td>IBXRMA2018_MULT_1216920010010001_HMK_166407506...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21988</th>\n",
       "      <td>IBXRMA2018_MULT_1217403970010001_HMK_166200321...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22788</th>\n",
       "      <td>IBXRMA2018_MULT_1176161080010001_HMK_192365603...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25667</th>\n",
       "      <td>IBXRMA2018_MULT_1217431580010001_HMK_179344559...</td>\n",
       "      <td>E785</td>\n",
       "      <td>hld</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25668</th>\n",
       "      <td>IBXRMA2018_MULT_1217431580010001_HMK_179344559...</td>\n",
       "      <td>E785</td>\n",
       "      <td>hyperlipidemia) - e78.5</td>\n",
       "      <td>61</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25936</th>\n",
       "      <td>IBXRMA2018_MULT_1217803860010001_HMK_186321021...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27169</th>\n",
       "      <td>IBXRMA2018_MULT_1217772170010001_HMK_184300163...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27748</th>\n",
       "      <td>IBXRMA2018_MULT_1216861210010001_HMK_187281953...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28226</th>\n",
       "      <td>IBXRMA2018_MULT_1217130710010001_HMK_180325209...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29600</th>\n",
       "      <td>IBXRMA2018_MULT_1217575240010001_HMK_177346661...</td>\n",
       "      <td>K900</td>\n",
       "      <td>Celiac Disease</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30906</th>\n",
       "      <td>IBXRMA2018_MULT_1216927960010001_HMK_208360965...</td>\n",
       "      <td>K739</td>\n",
       "      <td>hep c</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33725</th>\n",
       "      <td>IBXRMA2018_MULT_1218022030010001_HMK_580346816...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34457</th>\n",
       "      <td>IBXRMA2018_MULT_1196754330010001_HMK_542609557...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35706</th>\n",
       "      <td>IBXRMA2018_MULT_1218114250010001_HMK_187461632...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37911</th>\n",
       "      <td>IBXRMA2018_MULT_1217083610010001_HMK_197300381...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42171</th>\n",
       "      <td>IBXRMA2018_MULT_1218027670010001_HMK_198289883...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44694</th>\n",
       "      <td>IBXRMA2018_MULT_1212745310010001_HMK_165441851...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48735</th>\n",
       "      <td>IBXRMA2018_MULT_1217905040010001_HMK_174329240...</td>\n",
       "      <td>J449</td>\n",
       "      <td>cord</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50500</th>\n",
       "      <td>IBXRMA2018_MULT_1216864060010001_HMK_187285265...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51579</th>\n",
       "      <td>IBXRMA2018_MULT_1217797400010001_HMK_583093637...</td>\n",
       "      <td>E1169</td>\n",
       "      <td>diabetic foot</td>\n",
       "      <td>72</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52298</th>\n",
       "      <td>IBXRMA2018_MULT_1164353980010001_HMK_160303709...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52530</th>\n",
       "      <td>IBXRMA2018_MULT_1210311960010001_HMK_203426044...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345326</th>\n",
       "      <td>IBXRMA2018_MULT_1217961720010001_HMK_204361741...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346867</th>\n",
       "      <td>IBXRMA2018_MULT_1216973310010001_HMK_156346803...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349357</th>\n",
       "      <td>IBXRMA2018_MULT_1217945710010001_HMK_206267939...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351899</th>\n",
       "      <td>IBXRMA2018_MULT_1217850770010001_HMK_266645788...</td>\n",
       "      <td>I158</td>\n",
       "      <td>1158</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355384</th>\n",
       "      <td>IBXRMA2018_MULT_1217377970010001_HMK_157249307...</td>\n",
       "      <td>F411</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355385</th>\n",
       "      <td>IBXRMA2018_MULT_1216733710010001_HMK_164400715...</td>\n",
       "      <td>K219</td>\n",
       "      <td>GERD</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357348</th>\n",
       "      <td>IBXRMA2018_MULT_1216927260010001_HMK_200320821...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364569</th>\n",
       "      <td>IBXRMA2018_MULT_1216729130010001_HMK_196286386...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374648</th>\n",
       "      <td>IBXRMA2018_MULT_1217087530010001_HMK_347363306...</td>\n",
       "      <td>E744</td>\n",
       "      <td>Pc</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374839</th>\n",
       "      <td>IBXRMA2018_MULT_1216934370010001_HMK_197308403...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375120</th>\n",
       "      <td>IBXRMA2018_MULT_1217361600010001_HMK_168326736...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381758</th>\n",
       "      <td>IBXRMA2018_MULT_1216905660010001_HMK_141364882...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387179</th>\n",
       "      <td>IBXRMA2018_MULT_1217113290010001_HMK_197187744...</td>\n",
       "      <td>I775</td>\n",
       "      <td>1775</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390832</th>\n",
       "      <td>IBXRMA2018_MULT_1216951190010001_HMK_9FH8F63RR...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394400</th>\n",
       "      <td>IBXRMA2018_MULT_1217115110010001_HMK_552848638...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399573</th>\n",
       "      <td>IBXRMA2018_MULT_1218089270010001_HMK_4HJ2UK2NJ...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409752</th>\n",
       "      <td>IBXRMA2018_MULT_1201693350010001_HMK_175400775...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411334</th>\n",
       "      <td>IBXRMA2018_MULT_1163872250010001_HMK_186345030...</td>\n",
       "      <td>I10</td>\n",
       "      <td>HTN</td>\n",
       "      <td>1768</td>\n",
       "      <td>1771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411335</th>\n",
       "      <td>IBXRMA2018_MULT_1163872250010001_HMK_186345030...</td>\n",
       "      <td>F339</td>\n",
       "      <td>Depression</td>\n",
       "      <td>2794</td>\n",
       "      <td>2804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411336</th>\n",
       "      <td>IBXRMA2018_MULT_1163872250010001_HMK_186345030...</td>\n",
       "      <td>E063</td>\n",
       "      <td>Ht</td>\n",
       "      <td>3060</td>\n",
       "      <td>3062</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411342</th>\n",
       "      <td>IBXRMA2018_MULT_1163872250010001_HMK_186345030...</td>\n",
       "      <td>I10</td>\n",
       "      <td>htn</td>\n",
       "      <td>2029</td>\n",
       "      <td>2032</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411343</th>\n",
       "      <td>IBXRMA2018_MULT_1163872250010001_HMK_186345030...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>2033</td>\n",
       "      <td>2036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411344</th>\n",
       "      <td>IBXRMA2018_MULT_1163872250010001_HMK_186345030...</td>\n",
       "      <td>I10</td>\n",
       "      <td>htn</td>\n",
       "      <td>2070</td>\n",
       "      <td>2073</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411345</th>\n",
       "      <td>IBXRMA2018_MULT_1163872250010001_HMK_186345030...</td>\n",
       "      <td>F329</td>\n",
       "      <td>depressed</td>\n",
       "      <td>2929</td>\n",
       "      <td>2938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411698</th>\n",
       "      <td>IBXRMA2018_MULT_1217424900010001_HMK_168302018...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411880</th>\n",
       "      <td>IBXRMA2018_MULT_1202740400010001_HMK_153425750...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412237</th>\n",
       "      <td>IBXRMA2018_MULT_1205719370010001_HMK_191505555...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412642</th>\n",
       "      <td>IBXRMA2018_MULT_1213490230010001_HMK_205425988...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414042</th>\n",
       "      <td>IBXRMA2018_MULT_1217421400010001_HMK_172260104...</td>\n",
       "      <td>E039</td>\n",
       "      <td>hypothyroidism - e03.9</td>\n",
       "      <td>51</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414925</th>\n",
       "      <td>IBXRMA2018_MULT_1175896150010001_HMK_135288952...</td>\n",
       "      <td>G309</td>\n",
       "      <td>Alzheimers disease</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 chart_id   code  \\\n",
       "93      IBXRMA2018_MULT_1216944220010001_HMK_195147709...   E744   \n",
       "2812    IBXRMA2018_MULT_1217060910010001_HMK_097164250...   E744   \n",
       "5677    IBXRMA2018_MULT_1216129800010001_HMK_239481844...   G129   \n",
       "7858    IBXRMA2018_MULT_1218015600010001_HMK_3GM6V72QA...    N08   \n",
       "8082    IBXRMA2018_MULT_1216901800010001_HMK_201224196...   G129   \n",
       "10147   IBXRMA2018_MULT_1217591910010001_HMK_168240489...   E780   \n",
       "14436   IBXRMA2018_MULT_1216874020010001_HMK_143364782...   E744   \n",
       "18295   IBXRMA2018_MULT_1217464990010001_HMK_175243784...    N08   \n",
       "21856   IBXRMA2018_MULT_1216920010010001_HMK_166407506...    N08   \n",
       "21988   IBXRMA2018_MULT_1217403970010001_HMK_166200321...   E744   \n",
       "22788   IBXRMA2018_MULT_1176161080010001_HMK_192365603...    N08   \n",
       "25667   IBXRMA2018_MULT_1217431580010001_HMK_179344559...   E785   \n",
       "25668   IBXRMA2018_MULT_1217431580010001_HMK_179344559...   E785   \n",
       "25936   IBXRMA2018_MULT_1217803860010001_HMK_186321021...   G129   \n",
       "27169   IBXRMA2018_MULT_1217772170010001_HMK_184300163...   E744   \n",
       "27748   IBXRMA2018_MULT_1216861210010001_HMK_187281953...    N08   \n",
       "28226   IBXRMA2018_MULT_1217130710010001_HMK_180325209...   E744   \n",
       "29600   IBXRMA2018_MULT_1217575240010001_HMK_177346661...   K900   \n",
       "30906   IBXRMA2018_MULT_1216927960010001_HMK_208360965...   K739   \n",
       "33725   IBXRMA2018_MULT_1218022030010001_HMK_580346816...   E744   \n",
       "34457   IBXRMA2018_MULT_1196754330010001_HMK_542609557...    N08   \n",
       "35706   IBXRMA2018_MULT_1218114250010001_HMK_187461632...   E744   \n",
       "37911   IBXRMA2018_MULT_1217083610010001_HMK_197300381...   E744   \n",
       "42171   IBXRMA2018_MULT_1218027670010001_HMK_198289883...    N08   \n",
       "44694   IBXRMA2018_MULT_1212745310010001_HMK_165441851...    N08   \n",
       "48735   IBXRMA2018_MULT_1217905040010001_HMK_174329240...   J449   \n",
       "50500   IBXRMA2018_MULT_1216864060010001_HMK_187285265...    N08   \n",
       "51579   IBXRMA2018_MULT_1217797400010001_HMK_583093637...  E1169   \n",
       "52298   IBXRMA2018_MULT_1164353980010001_HMK_160303709...   G129   \n",
       "52530   IBXRMA2018_MULT_1210311960010001_HMK_203426044...   G129   \n",
       "...                                                   ...    ...   \n",
       "345326  IBXRMA2018_MULT_1217961720010001_HMK_204361741...   G129   \n",
       "346867  IBXRMA2018_MULT_1216973310010001_HMK_156346803...    N08   \n",
       "349357  IBXRMA2018_MULT_1217945710010001_HMK_206267939...    N08   \n",
       "351899  IBXRMA2018_MULT_1217850770010001_HMK_266645788...   I158   \n",
       "355384  IBXRMA2018_MULT_1217377970010001_HMK_157249307...   F411   \n",
       "355385  IBXRMA2018_MULT_1216733710010001_HMK_164400715...   K219   \n",
       "357348  IBXRMA2018_MULT_1216927260010001_HMK_200320821...  I2510   \n",
       "364569  IBXRMA2018_MULT_1216729130010001_HMK_196286386...    N08   \n",
       "374648  IBXRMA2018_MULT_1217087530010001_HMK_347363306...   E744   \n",
       "374839  IBXRMA2018_MULT_1216934370010001_HMK_197308403...    N08   \n",
       "375120  IBXRMA2018_MULT_1217361600010001_HMK_168326736...    N08   \n",
       "381758  IBXRMA2018_MULT_1216905660010001_HMK_141364882...    N08   \n",
       "387179  IBXRMA2018_MULT_1217113290010001_HMK_197187744...   I775   \n",
       "390832  IBXRMA2018_MULT_1216951190010001_HMK_9FH8F63RR...    N08   \n",
       "394400  IBXRMA2018_MULT_1217115110010001_HMK_552848638...    N08   \n",
       "399573  IBXRMA2018_MULT_1218089270010001_HMK_4HJ2UK2NJ...    N08   \n",
       "409752  IBXRMA2018_MULT_1201693350010001_HMK_175400775...    N08   \n",
       "411334  IBXRMA2018_MULT_1163872250010001_HMK_186345030...    I10   \n",
       "411335  IBXRMA2018_MULT_1163872250010001_HMK_186345030...   F339   \n",
       "411336  IBXRMA2018_MULT_1163872250010001_HMK_186345030...   E063   \n",
       "411342  IBXRMA2018_MULT_1163872250010001_HMK_186345030...    I10   \n",
       "411343  IBXRMA2018_MULT_1163872250010001_HMK_186345030...  I2510   \n",
       "411344  IBXRMA2018_MULT_1163872250010001_HMK_186345030...    I10   \n",
       "411345  IBXRMA2018_MULT_1163872250010001_HMK_186345030...   F329   \n",
       "411698  IBXRMA2018_MULT_1217424900010001_HMK_168302018...   G129   \n",
       "411880  IBXRMA2018_MULT_1202740400010001_HMK_153425750...   G129   \n",
       "412237  IBXRMA2018_MULT_1205719370010001_HMK_191505555...    N08   \n",
       "412642  IBXRMA2018_MULT_1213490230010001_HMK_205425988...    N08   \n",
       "414042  IBXRMA2018_MULT_1217421400010001_HMK_172260104...   E039   \n",
       "414925  IBXRMA2018_MULT_1175896150010001_HMK_135288952...   G309   \n",
       "\n",
       "                           text  start_offset  end_offset text75  \n",
       "93                           PC            25          27    NaN  \n",
       "2812                         PC            25          27    NaN  \n",
       "5677                        SMA             4           7    NaN  \n",
       "7858                     Kidney            48          54    NaN  \n",
       "8082                        SMA             4           7    NaN  \n",
       "10147               cholesterol            60          71    NaN  \n",
       "14436                        PC            25          27    NaN  \n",
       "18295                    Kidney            46          52    NaN  \n",
       "21856                    Kidney            46          52    NaN  \n",
       "21988                        PC            25          27    NaN  \n",
       "22788                    Kidney            46          52    NaN  \n",
       "25667                       hld            56          59    NaN  \n",
       "25668   hyperlipidemia) - e78.5            61          84    NaN  \n",
       "25936                       SMA             4           7    NaN  \n",
       "27169                        PC            18          20    NaN  \n",
       "27748                    Kidney            48          54    NaN  \n",
       "28226                        PC            25          27    NaN  \n",
       "29600            Celiac Disease            18          32    NaN  \n",
       "30906                     hep c            18          23    NaN  \n",
       "33725                        PC            18          20    NaN  \n",
       "34457                    Kidney            46          52    NaN  \n",
       "35706                        PC            61          63    NaN  \n",
       "37911                        PC            49          51    NaN  \n",
       "42171                    Kidney            46          52    NaN  \n",
       "44694                    Kidney            48          54    NaN  \n",
       "48735                      cord            65          69    NaN  \n",
       "50500                    Kidney            46          52    NaN  \n",
       "51579             diabetic foot            72          85    NaN  \n",
       "52298                       SMA             4           7    NaN  \n",
       "52530                       SMA             4           7    NaN  \n",
       "...                         ...           ...         ...    ...  \n",
       "345326                      SMA             4           7    NaN  \n",
       "346867                   Kidney            48          54    NaN  \n",
       "349357                   Kidney            48          54    NaN  \n",
       "351899                     1158            19          23    NaN  \n",
       "355384                  anxiety             8          15    NaN  \n",
       "355385                     GERD            16          20    NaN  \n",
       "357348                      cad            28          31    NaN  \n",
       "364569                   Kidney            46          52    NaN  \n",
       "374648                       Pc            40          42    NaN  \n",
       "374839                   Kidney            48          54    NaN  \n",
       "375120                   Kidney            46          52    NaN  \n",
       "381758                   Kidney            46          52    NaN  \n",
       "387179                     1775             8          12    NaN  \n",
       "390832                   Kidney            48          54    NaN  \n",
       "394400                   Kidney            48          54    NaN  \n",
       "399573                   Kidney            48          54    NaN  \n",
       "409752                   Kidney            45          51    NaN  \n",
       "411334                      HTN          1768        1771    NaN  \n",
       "411335               Depression          2794        2804    NaN  \n",
       "411336                       Ht          3060        3062    NaN  \n",
       "411342                      htn          2029        2032    NaN  \n",
       "411343                      cad          2033        2036    NaN  \n",
       "411344                      htn          2070        2073    NaN  \n",
       "411345                depressed          2929        2938    NaN  \n",
       "411698                      SMA             4           7    NaN  \n",
       "411880                      SMA             4           7    NaN  \n",
       "412237                   Kidney            48          54    NaN  \n",
       "412642                   Kidney            48          54    NaN  \n",
       "414042   hypothyroidism - e03.9            51          73    NaN  \n",
       "414925       Alzheimers disease            54          72    NaN  \n",
       "\n",
       "[208 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulltext   # there are some text not correctly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418310"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF=testDF[pd.notnull(testDF['text75'])] \n",
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF['chart_id'].nunique()   # only 980 charts not 1044 charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418305</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I482</td>\n",
       "      <td>atrial</td>\n",
       "      <td>367638</td>\n",
       "      <td>367644</td>\n",
       "      <td>left atrium mildly dilated left atrium right a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418306</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I482</td>\n",
       "      <td>atrial</td>\n",
       "      <td>367668</td>\n",
       "      <td>367674</td>\n",
       "      <td>ed left atrium right atrium normal right atria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418307</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>E041</td>\n",
       "      <td>thyroid nodule</td>\n",
       "      <td>371470</td>\n",
       "      <td>371484</td>\n",
       "      <td>nable raise left arm 13 cm hypodense left lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418308</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>E041</td>\n",
       "      <td>thyroid nodule</td>\n",
       "      <td>372201</td>\n",
       "      <td>372215</td>\n",
       "      <td>icant lytic blastic bone lesions impression 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418309</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I509</td>\n",
       "      <td>congestive heart failure</td>\n",
       "      <td>374108</td>\n",
       "      <td>374132</td>\n",
       "      <td>robably gross acute pathology examination siza...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 chart_id  code  \\\n",
       "418305  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I482   \n",
       "418306  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I482   \n",
       "418307  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  E041   \n",
       "418308  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  E041   \n",
       "418309  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I509   \n",
       "\n",
       "                            text  start_offset  end_offset  \\\n",
       "418305                    atrial        367638      367644   \n",
       "418306                    atrial        367668      367674   \n",
       "418307            thyroid nodule        371470      371484   \n",
       "418308            thyroid nodule        372201      372215   \n",
       "418309  congestive heart failure        374108      374132   \n",
       "\n",
       "                                                   text75  \n",
       "418305  left atrium mildly dilated left atrium right a...  \n",
       "418306  ed left atrium right atrium normal right atria...  \n",
       "418307  nable raise left arm 13 cm hypodense left lowe...  \n",
       "418308  icant lytic blastic bone lesions impression 13...  \n",
       "418309  robably gross acute pathology examination siza...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF=testDF.reset_index(drop=True)   # very very import, to reset the index, otherwise the below running the model will not be right, because I use the index as reference for position and matching them\n",
    "testDF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Loading all the models or locate the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.a. Load the 28 pickle files and run them on the testDF with selected chart_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files=glob.glob(\"../../picklefolder_ngrams/refreshed_models_update0531/*.pickle\") # refreshed updated models\n",
    "files=glob.glob(\"../../picklefolder_ngrams/refreshed_models/*19.pickle\")  # refreshed models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files2=glob.glob(\"../../picklefolder_ngrams/refreshed_models_update0531/*.pickle\") # refreshed updated models\n",
    "#files2=files2[:-1]   # run 28 model\n",
    "files2=files2[28]   # run consolidated only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.append(files2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models_update0531/Deletion_Consolidated_LRMay2919.pickle']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preventative'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[27].split('/')[4].split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phrase_stroke_LRApril0219.pickle'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0].split('/')[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Apply models to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = preprocessing.LabelEncoder()\n",
    "#test_y = encoder.fit_transform(testDF['flag'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list={}\n",
    "code_list[\"Model1\"]=['I10','E119']\n",
    "code_list[\"Model2\"]=['I2510','E785','K219','F329','I639']\n",
    "code_list[\"Model3\"]=['I739','N183','Z992','B20','I213','R569','I43','J410','I714','R579','E550','I209','J45998','I480','B182','K210','K739']\n",
    "code_list[\"Heart\"]=['I509','I482','I4891','I82401']\n",
    "code_list[\"Depression\"]=['F411','F410','F40240','F458','F409','F4000','F4001','F445','F444','F40243','F446','F4010','F442','F408','F449','F451']\n",
    "code_list[\"Kidney\"]=['N189','N181','N182','E1122','I130','E0822','E1022']\n",
    "code_list[\"Diabetes\"]=['Z794','E109','E119','E139','E089','E099']\n",
    "code_list[\"Cancer\"]=['C801','C50919','C189']\n",
    "code_list[\"COPD\"]=['J449','J45909']\n",
    "code_list[\"Cholesterol\"]=['E780','E785','E782','E789','E7800','E784','E781','E7801','E7881','E882','E783','E786','E7889','E756','E755','E7130']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "allpredict=pd.DataFrame()   # create an empty dataframe, to save the prediction result for each model\n",
    "allprob=pd.DataFrame()\n",
    "print(allprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nindexdf=pd.DataFrame() \\nmodel_pipeline = joblib.load(files)\\n  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\\n    # deletion model\\n\\ntestDF1=testDF\\nindexdf[0]= [1 for i in range(len(testDF))]\\n        \\n        \\n        #print(files[i])\\n    # how to put the prediction on the right index?\\ntest=testDF1[\\'text75\\']\\nprint(\"model loaded:\", files )\\nprint(\"length of data for the model:\", len(test))\\n    \\n   \\nproba = model_pipeline.predict_proba(test)[:,1]\\nprediction = np.where(proba > 0.3, 1, 0) # use a lower threshold\\ntestDF1[\\'key\\']=testDF1.index\\ntestDF1[\\'pred\\']=prediction\\ntestDF1[\\'prob\\']= proba\\n\\nindexdf[\\'key\\']=indexdf.index\\nmerged=pd.merge(indexdf,testDF1,on=\\'key\\',how=\\'outer\\')  # maintain the position of the perdiction, match to the right index\\nallpredict[0]=merged[\\'pred\\']    # save the prediction to corresponding dataframe\\nallprob[0]=merged[\\'prob\\']\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for one model evaluation\n",
    "'''\n",
    "indexdf=pd.DataFrame() \n",
    "model_pipeline = joblib.load(files)\n",
    "  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\n",
    "    # deletion model\n",
    "\n",
    "testDF1=testDF\n",
    "indexdf[0]= [1 for i in range(len(testDF))]\n",
    "        \n",
    "        \n",
    "        #print(files[i])\n",
    "    # how to put the prediction on the right index?\n",
    "test=testDF1['text75']\n",
    "print(\"model loaded:\", files )\n",
    "print(\"length of data for the model:\", len(test))\n",
    "    \n",
    "   \n",
    "proba = model_pipeline.predict_proba(test)[:,1]\n",
    "prediction = np.where(proba > 0.3, 1, 0) # use a lower threshold\n",
    "testDF1['key']=testDF1.index\n",
    "testDF1['pred']=prediction\n",
    "testDF1['prob']= proba\n",
    "\n",
    "indexdf['key']=indexdf.index\n",
    "merged=pd.merge(indexdf,testDF1,on='key',how='outer')  # maintain the position of the perdiction, match to the right index\n",
    "allpredict[0]=merged['pred']    # save the prediction to corresponding dataframe\n",
    "allprob[0]=merged['prob']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 1623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 39272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 2729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 17738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 10658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 6963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 34509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 17493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 87297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 10217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 46150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 60510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 31229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 3979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 14764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 9162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 27075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 418310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 418310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 418310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 418310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 418310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data for the model: 418310\n",
      "length of data for the model: 418310\n"
     ]
    }
   ],
   "source": [
    "#f = open(\"allmodeltestscore_0506.txt\", \"w+\")  # save all the score to this file\n",
    "# for multiple model evaluation\n",
    "\n",
    "   # create a dataframe, otherwise can use testDF for merging to obtain the prediction matched to index\n",
    "# because for some model testing, we only select partial data, like phrase-based model, code-based model\n",
    "for i in range(len(files)):\n",
    "    indexdf=pd.DataFrame() \n",
    "    model_pipeline = joblib.load(files[i])\n",
    "  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\n",
    "    # deletion model\n",
    "    if(files[i].split('/')[4].startswith('D')):\n",
    "        try:\n",
    "            testDF1=testDF\n",
    "            indexdf[i]= [1 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "        \n",
    "    elif(files[i].split('/')[4].startswith('P')):\n",
    "    # if it's phrase-based model, use the following way to select data\n",
    "        \n",
    "        phrase=files[i].split('/')[4].split('_')[1]\n",
    "        try:\n",
    "            testDF1 = testDF[testDF['text'].str.contains(phrase,flags=re.IGNORECASE)]\n",
    "            temp=testDF1.index.tolist()\n",
    "            indexdf[i]=[1 if i in (temp) else 0 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "\n",
    "    elif(files[i].split('/')[4].startswith('C')):\n",
    "    # if it's code based model, use the following way to select model\n",
    "        codereason=files[i].split('/')[4].split('_')[1]\n",
    "        try:\n",
    "            testDF1 = testDF[testDF['code'].isin(code_list[codereason])]\n",
    "            temp=testDF1.index.tolist()\n",
    "            indexdf[i]=[1 if i in (temp) else 0 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "    else:\n",
    "        print('not a valid/good model name probably...')\n",
    "\n",
    "    #print(files[i])\n",
    "    # how to put the prediction on the right index?\n",
    "    test=testDF1['text75']\n",
    "    print(\"length of data for the model:\", len(test))\n",
    "    try:\n",
    "        \n",
    "        proba = model_pipeline.predict_proba(test)[:,1]\n",
    "        prediction = np.where(proba > 0.4, 1, 0) # use a lower threshold\n",
    "        #prediction = model_pipeline.predict(test)\n",
    "        \n",
    "        \n",
    "        testDF1['key']=testDF1.index\n",
    "        testDF1['pred']=prediction\n",
    "        testDF1['prob']= proba\n",
    "\n",
    "        indexdf['key']=indexdf.index\n",
    "        merged=pd.merge(indexdf,testDF1,on='key',how='outer')  # maintain the position of the perdiction, match to the right index\n",
    "        allpredict[i]=merged['pred']    # save the prediction to corresponding dataframe\n",
    "        allprob[i]=merged['prob']   # save the probability\n",
    "    except:\n",
    "         print('something is wrong')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Part 2.b. Now get the prediction and probability dataframes and merge with testDF which has all the chart_id etc info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418310"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allpredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     416687\n",
       "1     417346\n",
       "2     379038\n",
       "3     415581\n",
       "4     400572\n",
       "5     411683\n",
       "6     415678\n",
       "7     407652\n",
       "8     411347\n",
       "9     383801\n",
       "10    400817\n",
       "11    411935\n",
       "12    331013\n",
       "13    408093\n",
       "14    372160\n",
       "15    357800\n",
       "16    387081\n",
       "17    414331\n",
       "18    403546\n",
       "19    415178\n",
       "20    409148\n",
       "21    391235\n",
       "22         0\n",
       "23         0\n",
       "24         0\n",
       "25         0\n",
       "26         0\n",
       "27         0\n",
       "28         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.isnull().sum()  # a lot of nulls because not all data are run for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2   3   4   5   6   7   8   9  ...  19  20  21  22  23  24  25  \\\n",
       "0 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "1 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "2 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "3 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "4 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN   0   0   0   0   \n",
       "\n",
       "   26  27  28  \n",
       "0   0   0   0  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.014130</td>\n",
       "      <td>0.034596</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.067671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.018645</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.074822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115857</td>\n",
       "      <td>0.033108</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.067311</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.025832</td>\n",
       "      <td>0.129453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.071882</td>\n",
       "      <td>0.167899</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>0.013970</td>\n",
       "      <td>0.203773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.049663</td>\n",
       "      <td>0.043583</td>\n",
       "      <td>0.169887</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>0.135165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1         2   3   4   5   6   7   8   9     ...     19  20  21  \\\n",
       "0 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "1 NaN NaN  0.094929 NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "2 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "3 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "4 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN   \n",
       "\n",
       "         22        23        24        25        26        27        28  \n",
       "0  0.001588  0.009432  0.014130  0.034596  0.001052  0.002447  0.067671  \n",
       "1  0.003035  0.007828  0.018645  0.027765  0.001430  0.002414  0.074822  \n",
       "2  0.115857  0.033108  0.007716  0.067311  0.001899  0.025832  0.129453  \n",
       "3  0.003465  0.032156  0.071882  0.167899  0.009440  0.013970  0.203773  \n",
       "4  0.003773  0.049663  0.043583  0.169887  0.003179  0.019628  0.135165  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418310"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418310"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418310"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data frame for predictions from each model\n",
    "#merge to testDF to keep the Nan, which means not omputed for that instance\n",
    "#testDF2=pd.concat([testDF,allpredict],axis=1)\n",
    "#len(testDF2)\n",
    "testDF['index']=testDF.index\n",
    "allpredict['index']=allpredict.index\n",
    "df_pred = pd.merge(testDF,allpredict, how='left', on = 'index')\n",
    "len(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>key</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>index</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418305</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I482</td>\n",
       "      <td>atrial</td>\n",
       "      <td>367638</td>\n",
       "      <td>367644</td>\n",
       "      <td>left atrium mildly dilated left atrium right a...</td>\n",
       "      <td>418305</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932658</td>\n",
       "      <td>418305</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418306</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I482</td>\n",
       "      <td>atrial</td>\n",
       "      <td>367668</td>\n",
       "      <td>367674</td>\n",
       "      <td>ed left atrium right atrium normal right atria...</td>\n",
       "      <td>418306</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936481</td>\n",
       "      <td>418306</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418307</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>E041</td>\n",
       "      <td>thyroid nodule</td>\n",
       "      <td>371470</td>\n",
       "      <td>371484</td>\n",
       "      <td>nable raise left arm 13 cm hypodense left lowe...</td>\n",
       "      <td>418307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768912</td>\n",
       "      <td>418307</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418308</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>E041</td>\n",
       "      <td>thyroid nodule</td>\n",
       "      <td>372201</td>\n",
       "      <td>372215</td>\n",
       "      <td>icant lytic blastic bone lesions impression 13...</td>\n",
       "      <td>418308</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678415</td>\n",
       "      <td>418308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418309</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I509</td>\n",
       "      <td>congestive heart failure</td>\n",
       "      <td>374108</td>\n",
       "      <td>374132</td>\n",
       "      <td>robably gross acute pathology examination siza...</td>\n",
       "      <td>418309</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817968</td>\n",
       "      <td>418309</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 chart_id  code  \\\n",
       "418305  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I482   \n",
       "418306  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I482   \n",
       "418307  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  E041   \n",
       "418308  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  E041   \n",
       "418309  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I509   \n",
       "\n",
       "                            text  start_offset  end_offset  \\\n",
       "418305                    atrial        367638      367644   \n",
       "418306                    atrial        367668      367674   \n",
       "418307            thyroid nodule        371470      371484   \n",
       "418308            thyroid nodule        372201      372215   \n",
       "418309  congestive heart failure        374108      374132   \n",
       "\n",
       "                                                   text75     key  pred  \\\n",
       "418305  left atrium mildly dilated left atrium right a...  418305     1   \n",
       "418306  ed left atrium right atrium normal right atria...  418306     1   \n",
       "418307  nable raise left arm 13 cm hypodense left lowe...  418307     1   \n",
       "418308  icant lytic blastic bone lesions impression 13...  418308     1   \n",
       "418309  robably gross acute pathology examination siza...  418309     1   \n",
       "\n",
       "            prob   index ...  19  20  21  22  23  24  25  26  27  28  \n",
       "418305  0.932658  418305 ... NaN NaN NaN   0   0   1   1   0   0   1  \n",
       "418306  0.936481  418306 ... NaN NaN NaN   0   0   1   1   0   0   1  \n",
       "418307  0.768912  418307 ... NaN NaN NaN   0   0   1   1   0   0   1  \n",
       "418308  0.678415  418308 ... NaN NaN NaN   0   1   1   0   0   0   1  \n",
       "418309  0.817968  418309 ... NaN NaN NaN   0   1   1   0   0   0   1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418310\n"
     ]
    }
   ],
   "source": [
    "# now the data frame with probabilities\n",
    "testDF['index']=testDF.index\n",
    "allprob['index']=allprob.index\n",
    "df_prob = pd.merge(testDF,allprob, how='left', on = 'index')\n",
    "print(len(df_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>key</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>index</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418305</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I482</td>\n",
       "      <td>atrial</td>\n",
       "      <td>367638</td>\n",
       "      <td>367644</td>\n",
       "      <td>left atrium mildly dilated left atrium right a...</td>\n",
       "      <td>418305</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932658</td>\n",
       "      <td>418305</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.279688</td>\n",
       "      <td>0.846352</td>\n",
       "      <td>0.804261</td>\n",
       "      <td>0.027458</td>\n",
       "      <td>0.051732</td>\n",
       "      <td>0.932658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418306</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I482</td>\n",
       "      <td>atrial</td>\n",
       "      <td>367668</td>\n",
       "      <td>367674</td>\n",
       "      <td>ed left atrium right atrium normal right atria...</td>\n",
       "      <td>418306</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936481</td>\n",
       "      <td>418306</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.298900</td>\n",
       "      <td>0.850264</td>\n",
       "      <td>0.837606</td>\n",
       "      <td>0.022916</td>\n",
       "      <td>0.043327</td>\n",
       "      <td>0.936481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418307</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>E041</td>\n",
       "      <td>thyroid nodule</td>\n",
       "      <td>371470</td>\n",
       "      <td>371484</td>\n",
       "      <td>nable raise left arm 13 cm hypodense left lowe...</td>\n",
       "      <td>418307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768912</td>\n",
       "      <td>418307</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>0.121493</td>\n",
       "      <td>0.715362</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.056095</td>\n",
       "      <td>0.020721</td>\n",
       "      <td>0.768912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418308</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>E041</td>\n",
       "      <td>thyroid nodule</td>\n",
       "      <td>372201</td>\n",
       "      <td>372215</td>\n",
       "      <td>icant lytic blastic bone lesions impression 13...</td>\n",
       "      <td>418308</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678415</td>\n",
       "      <td>418308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.668864</td>\n",
       "      <td>0.720203</td>\n",
       "      <td>0.318181</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.026901</td>\n",
       "      <td>0.678415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418309</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I509</td>\n",
       "      <td>congestive heart failure</td>\n",
       "      <td>374108</td>\n",
       "      <td>374132</td>\n",
       "      <td>robably gross acute pathology examination siza...</td>\n",
       "      <td>418309</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817968</td>\n",
       "      <td>418309</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>0.435160</td>\n",
       "      <td>0.438354</td>\n",
       "      <td>0.325368</td>\n",
       "      <td>0.015158</td>\n",
       "      <td>0.021450</td>\n",
       "      <td>0.817968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 chart_id  code  \\\n",
       "418305  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I482   \n",
       "418306  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I482   \n",
       "418307  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  E041   \n",
       "418308  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  E041   \n",
       "418309  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I509   \n",
       "\n",
       "                            text  start_offset  end_offset  \\\n",
       "418305                    atrial        367638      367644   \n",
       "418306                    atrial        367668      367674   \n",
       "418307            thyroid nodule        371470      371484   \n",
       "418308            thyroid nodule        372201      372215   \n",
       "418309  congestive heart failure        374108      374132   \n",
       "\n",
       "                                                   text75     key  pred  \\\n",
       "418305  left atrium mildly dilated left atrium right a...  418305     1   \n",
       "418306  ed left atrium right atrium normal right atria...  418306     1   \n",
       "418307  nable raise left arm 13 cm hypodense left lowe...  418307     1   \n",
       "418308  icant lytic blastic bone lesions impression 13...  418308     1   \n",
       "418309  robably gross acute pathology examination siza...  418309     1   \n",
       "\n",
       "            prob   index    ...     19  20  21        22        23        24  \\\n",
       "418305  0.932658  418305    ...    NaN NaN NaN  0.008212  0.279688  0.846352   \n",
       "418306  0.936481  418306    ...    NaN NaN NaN  0.005806  0.298900  0.850264   \n",
       "418307  0.768912  418307    ...    NaN NaN NaN  0.008633  0.121493  0.715362   \n",
       "418308  0.678415  418308    ...    NaN NaN NaN  0.007722  0.668864  0.720203   \n",
       "418309  0.817968  418309    ...    NaN NaN NaN  0.008685  0.435160  0.438354   \n",
       "\n",
       "              25        26        27        28  \n",
       "418305  0.804261  0.027458  0.051732  0.932658  \n",
       "418306  0.837606  0.022916  0.043327  0.936481  \n",
       "418307  0.547000  0.056095  0.020721  0.768912  \n",
       "418308  0.318181  0.008026  0.026901  0.678415  \n",
       "418309  0.325368  0.015158  0.021450  0.817968  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.c. Now combine the prediction from 28 models to make one prediction,it's actually an or operation, but here using sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.014130</td>\n",
       "      <td>0.034596</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.067671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.018645</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.074822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115857</td>\n",
       "      <td>0.033108</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.067311</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.025832</td>\n",
       "      <td>0.129453</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.071882</td>\n",
       "      <td>0.167899</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>0.013970</td>\n",
       "      <td>0.203773</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.049663</td>\n",
       "      <td>0.043583</td>\n",
       "      <td>0.169887</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>0.135165</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1         2   3   4   5   6   7   8   9  ...    20  21        22  \\\n",
       "0 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.001588   \n",
       "1 NaN NaN  0.094929 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.003035   \n",
       "2 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.115857   \n",
       "3 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.003465   \n",
       "4 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN  0.003773   \n",
       "\n",
       "         23        24        25        26        27        28  index  \n",
       "0  0.009432  0.014130  0.034596  0.001052  0.002447  0.067671      0  \n",
       "1  0.007828  0.018645  0.027765  0.001430  0.002414  0.074822      1  \n",
       "2  0.033108  0.007716  0.067311  0.001899  0.025832  0.129453      2  \n",
       "3  0.032156  0.071882  0.167899  0.009440  0.013970  0.203773      3  \n",
       "4  0.049663  0.043583  0.169887  0.003179  0.019628  0.135165      4  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredictNan=allpredict   # keep the original NaN if that row is not computed for that model\n",
    "allpredict=allpredict.fillna(0) # fill the NaNs by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1    2   3   4   5   6   7   8   9  ...    20  21  22  23  24  25  26  \\\n",
       "0 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "1 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "2 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "3 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "4 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN   0   0   0   0   0   \n",
       "\n",
       "   27  28  index  \n",
       "0   0   0      0  \n",
       "1   0   0      1  \n",
       "2   0   0      2  \n",
       "3   0   0      3  \n",
       "4   0   0      4  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredictNan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...     20   21  22  23  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   0   0   \n",
       "\n",
       "   24  25  26  27  28  index  \n",
       "0   0   0   0   0   0      0  \n",
       "1   0   0   0   0   0      1  \n",
       "2   0   0   0   0   0      2  \n",
       "3   0   0   0   0   0      3  \n",
       "4   0   0   0   0   0      4  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...   19   20   21  22  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0   0   \n",
       "\n",
       "   23  24  25  26  27  28  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.drop(['index'],inplace=True, axis=1)\n",
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredict['Sum'] = allpredict.sum(axis = 1, skipna = True) \n",
    "df_pred['all_model_pred']=[1 if allpredict['Sum'].iloc[i]>=1 else 0 for i in range(len(allpredict))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225651\n",
      "418310\n"
     ]
    }
   ],
   "source": [
    "# check how many 1s are predicted \n",
    "allpredict1=df_pred['all_model_pred']\n",
    "print(sum(allpredict1))\n",
    "print(len(allpredict1))  # 228562 are predicted as deleted out of 418310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the key and predict prob temp columns\n",
    "df_pred.drop(['key','pred','prob','index'],inplace=True, axis=1)\n",
    "df_prob.drop(['key','pred','prob','index'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>all_model_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418305</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I482</td>\n",
       "      <td>atrial</td>\n",
       "      <td>367638</td>\n",
       "      <td>367644</td>\n",
       "      <td>left atrium mildly dilated left atrium right a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418306</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I482</td>\n",
       "      <td>atrial</td>\n",
       "      <td>367668</td>\n",
       "      <td>367674</td>\n",
       "      <td>ed left atrium right atrium normal right atria...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418307</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>E041</td>\n",
       "      <td>thyroid nodule</td>\n",
       "      <td>371470</td>\n",
       "      <td>371484</td>\n",
       "      <td>nable raise left arm 13 cm hypodense left lowe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418308</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>E041</td>\n",
       "      <td>thyroid nodule</td>\n",
       "      <td>372201</td>\n",
       "      <td>372215</td>\n",
       "      <td>icant lytic blastic bone lesions impression 13...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418309</th>\n",
       "      <td>IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...</td>\n",
       "      <td>I509</td>\n",
       "      <td>congestive heart failure</td>\n",
       "      <td>374108</td>\n",
       "      <td>374132</td>\n",
       "      <td>robably gross acute pathology examination siza...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 chart_id  code  \\\n",
       "418305  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I482   \n",
       "418306  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I482   \n",
       "418307  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  E041   \n",
       "418308  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  E041   \n",
       "418309  IBXRMA2018_MULT_1217052600010001_HMK_1UH0MM2YA...  I509   \n",
       "\n",
       "                            text  start_offset  end_offset  \\\n",
       "418305                    atrial        367638      367644   \n",
       "418306                    atrial        367668      367674   \n",
       "418307            thyroid nodule        371470      371484   \n",
       "418308            thyroid nodule        372201      372215   \n",
       "418309  congestive heart failure        374108      374132   \n",
       "\n",
       "                                                   text75   0   1   2   3  \\\n",
       "418305  left atrium mildly dilated left atrium right a... NaN NaN NaN NaN   \n",
       "418306  ed left atrium right atrium normal right atria... NaN NaN NaN NaN   \n",
       "418307  nable raise left arm 13 cm hypodense left lowe... NaN NaN NaN NaN   \n",
       "418308  icant lytic blastic bone lesions impression 13... NaN NaN NaN NaN   \n",
       "418309  robably gross acute pathology examination siza... NaN NaN NaN NaN   \n",
       "\n",
       "             ...        20  21  22  23  24  25  26  27  28  all_model_pred  \n",
       "418305       ...       NaN NaN   0   0   1   1   0   0   1               1  \n",
       "418306       ...       NaN NaN   0   0   1   1   0   0   1               1  \n",
       "418307       ...       NaN NaN   0   0   1   1   0   0   1               1  \n",
       "418308       ...       NaN NaN   0   1   1   0   0   0   1               1  \n",
       "418309       ...       NaN NaN   0   1   1   0   0   0   1               1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.tail()\n",
    "#all_model_pred is check any model output is 1 for that instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chart_id          IBXRMA2018_MULT_1217111440010001_HMK_159289263...\n",
       "code                                                           I509\n",
       "text                                                  Heart Failure\n",
       "start_offset                                                  81201\n",
       "end_offset                                                    81214\n",
       "text75            healthcare provider discharge instructions pat...\n",
       "0                                                               NaN\n",
       "1                                                               NaN\n",
       "2                                                               NaN\n",
       "3                                                               NaN\n",
       "4                                                               NaN\n",
       "5                                                               NaN\n",
       "6                                                               NaN\n",
       "7                                                               NaN\n",
       "8                                                               NaN\n",
       "9                                                               NaN\n",
       "10                                                                1\n",
       "11                                                              NaN\n",
       "12                                                              NaN\n",
       "13                                                              NaN\n",
       "14                                                              NaN\n",
       "15                                                              NaN\n",
       "16                                                              NaN\n",
       "17                                                              NaN\n",
       "18                                                              NaN\n",
       "19                                                              NaN\n",
       "20                                                              NaN\n",
       "21                                                              NaN\n",
       "22                                                                0\n",
       "23                                                                1\n",
       "24                                                                1\n",
       "25                                                                1\n",
       "26                                                                0\n",
       "27                                                                0\n",
       "28                                                                1\n",
       "all_model_pred                                                    1\n",
       "Name: 76761, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.iloc[76761]   # just check one instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      'chart_id',           'code',           'text',   'start_offset',\n",
       "           'end_offset',         'text75',                0,                1,\n",
       "                      2,                3,                4,                5,\n",
       "                      6,                7,                8,                9,\n",
       "                     10,               11,               12,               13,\n",
       "                     14,               15,               16,               17,\n",
       "                     18,               19,               20,               21,\n",
       "                     22,               23,               24,               25,\n",
       "                     26,               27,               28, 'all_model_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    'chart_id',         'code',         'text', 'start_offset',\n",
       "         'end_offset',       'text75',              0,              1,\n",
       "                    2,              3,              4,              5,\n",
       "                    6,              7,              8,              9,\n",
       "                   10,             11,             12,             13,\n",
       "                   14,             15,             16,             17,\n",
       "                   18,             19,             20,             21,\n",
       "                   22,             23,             24,             25,\n",
       "                   26,             27,             28],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models_update0531/Deletion_Consolidated_LRMay2919.pickle']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns names, has to be consistent with the above order\n",
    "# since there's no 0, or 1, 17, these models didn't run because no data for them\n",
    "\n",
    "col_dict = {0: 'Phrase_stroke', 1: 'Phrase_emphysema',2:'Phrase_hypertension',3:'Phrase_dementia',4:'Phrase_cholesterol',\n",
    "           5:'Phrase_cad',6:'Phrase_aneurysm',7:'Code_COPD',8:'Code_Depression',9:'Code_Diabetes',10:'Code_Heart',\n",
    "           11:'Code_Kidney',12:'Code_Model1',13:'Code_Cancer',14:'Code_Cholesterol',15:'Code_Model2',\n",
    "           16:'Code_Model3',17:'Phrase_asthma',18:'Phrase_cancer',19:'Phrase_ckd',20:'Phrase_depression',21:'Phrase_diabetes',\n",
    "            22:'DeletionReason_family_history',23:'DeletionReason_negation',24:'DeletionReason_not_doctors_note',\n",
    "           25:'DeletionReason_not_relevant',26:'DeletionReason_phoneORaddressORother_number',27:'DeletionReason_preventative_screening',\n",
    "           }   ## key→old name, value→new name\n",
    "\n",
    "df_pred.columns = [col_dict.get(x, x) for x in df_pred.columns]\n",
    "df_prob.columns = [col_dict.get(x, x) for x in df_prob.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                   'chart_id',\n",
       "                                              'code',\n",
       "                                              'text',\n",
       "                                      'start_offset',\n",
       "                                        'end_offset',\n",
       "                                            'text75',\n",
       "                                     'Phrase_stroke',\n",
       "                                  'Phrase_emphysema',\n",
       "                               'Phrase_hypertension',\n",
       "                                   'Phrase_dementia',\n",
       "                                'Phrase_cholesterol',\n",
       "                                        'Phrase_cad',\n",
       "                                   'Phrase_aneurysm',\n",
       "                                         'Code_COPD',\n",
       "                                   'Code_Depression',\n",
       "                                     'Code_Diabetes',\n",
       "                                        'Code_Heart',\n",
       "                                       'Code_Kidney',\n",
       "                                       'Code_Model1',\n",
       "                                       'Code_Cancer',\n",
       "                                  'Code_Cholesterol',\n",
       "                                       'Code_Model2',\n",
       "                                       'Code_Model3',\n",
       "                                     'Phrase_asthma',\n",
       "                                     'Phrase_cancer',\n",
       "                                        'Phrase_ckd',\n",
       "                                 'Phrase_depression',\n",
       "                                   'Phrase_diabetes',\n",
       "                     'DeletionReason_family_history',\n",
       "                           'DeletionReason_negation',\n",
       "                   'DeletionReason_not_doctors_note',\n",
       "                       'DeletionReason_not_relevant',\n",
       "       'DeletionReason_phoneORaddressORother_number',\n",
       "             'DeletionReason_preventative_screening',\n",
       "                                                  28,\n",
       "                                    'all_model_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                   'chart_id',\n",
       "                                              'code',\n",
       "                                              'text',\n",
       "                                      'start_offset',\n",
       "                                        'end_offset',\n",
       "                                            'text75',\n",
       "                                     'Phrase_stroke',\n",
       "                                  'Phrase_emphysema',\n",
       "                               'Phrase_hypertension',\n",
       "                                   'Phrase_dementia',\n",
       "                                'Phrase_cholesterol',\n",
       "                                        'Phrase_cad',\n",
       "                                   'Phrase_aneurysm',\n",
       "                                         'Code_COPD',\n",
       "                                   'Code_Depression',\n",
       "                                     'Code_Diabetes',\n",
       "                                        'Code_Heart',\n",
       "                                       'Code_Kidney',\n",
       "                                       'Code_Model1',\n",
       "                                       'Code_Cancer',\n",
       "                                  'Code_Cholesterol',\n",
       "                                       'Code_Model2',\n",
       "                                       'Code_Model3',\n",
       "                                     'Phrase_asthma',\n",
       "                                     'Phrase_cancer',\n",
       "                                        'Phrase_ckd',\n",
       "                                 'Phrase_depression',\n",
       "                                   'Phrase_diabetes',\n",
       "                     'DeletionReason_family_history',\n",
       "                           'DeletionReason_negation',\n",
       "                   'DeletionReason_not_doctors_note',\n",
       "                       'DeletionReason_not_relevant',\n",
       "       'DeletionReason_phoneORaddressORother_number',\n",
       "             'DeletionReason_preventative_screening',\n",
       "                                                  28],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred.rename(columns={'start': 'start_offset', 'end': 'end_offset'}, inplace=True)\n",
    "#df_pred[['chart_id','start_offset','end_offset','DeletionReason_family_history']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prob.rename(columns={'start': 'start_offset', 'end': 'end_offset'}, inplace=True)\n",
    "#df_prob[['chart_id','start_offset','end_offset','DeletionReason_family_history']].tail()  #ok make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred.to_csv('run1000charts_pred_0521.csv')   #  with prediction for each model and all model combined\n",
    "#df_prob.to_csv('probdataforcompwithAM_0506.csv')   #  with probability for each model\n",
    "# finally corrected a lot of errors like index not reset issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n",
      "7500\n"
     ]
    }
   ],
   "source": [
    "print(len(set(df_pred['chart_id'].tolist())))\n",
    "print(len(set(df_prob['chart_id'].tolist())))   # 813 unique chart ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 3. Load in coder feedback and  evaluate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select common chart_ids from both 1000 model run and 6000 coder annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418310\n",
      "418310\n"
     ]
    }
   ],
   "source": [
    "# model computation\n",
    "df_pred1=df_pred[['chart_id', 'code', 'text', 'start_offset', 'end_offset', 'text75','all_model_pred']]\n",
    "print(len(df_pred1))\n",
    "df_pred1 = df_pred1.drop_duplicates()\n",
    "print(len(df_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188444\n"
     ]
    }
   ],
   "source": [
    "# read in all charts with coder feedback\n",
    "#df_codeall = pd.read_csv('/home/jovyan/work/Analytics_Data_training/conditions_with_chartids_29042019.csv')\n",
    "df_codeall = pd.read_csv('/home/jovyan/work/Analytics_Data_training/conditions_output_withchart_id_100619.csv')\n",
    "print(len(df_codeall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chart is in 1000 charts run model output: 7500\n",
      "unique chart is in 6000 charts with coder feedback: 7654\n"
     ]
    }
   ],
   "source": [
    "print(\"unique chart is in 1000 charts run model output:\",df_pred1['chart_id'].nunique())\n",
    "print(\"unique chart is in 6000 charts with coder feedback:\",df_codeall['chart_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    }
   ],
   "source": [
    "# now find overlap chart ids\n",
    "overlapped_charts = pd.merge(df_codeall[['chart_id']].drop_duplicates(),df_pred1[['chart_id']].drop_duplicates(), how = 'inner')\n",
    "overlapped_charts = list(overlapped_charts['chart_id'].unique())\n",
    "print(len(overlapped_charts))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418310"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the model output\n",
    "fd_prod = df_pred1[['chart_id','code','start_offset','end_offset','text75','all_model_pred']][df_pred1['chart_id'].isin(overlapped_charts)].drop_duplicates()\n",
    "len(fd_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187681\n",
      "109958\n",
      "25331\n",
      "52392\n"
     ]
    }
   ],
   "source": [
    "# select those in the code output\n",
    "data = df_codeall[df_codeall['chart_id'].isin(overlapped_charts)]\n",
    "print(len(data))\n",
    "print(len(data[data['label'] == 'added']))\n",
    "print(len(data[data['label'] == 'deleted']))\n",
    "print(len(data[data['label'] == 'agreed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TNh: 340587\n",
      "TNh: 255960\n"
     ]
    }
   ],
   "source": [
    "# The pipeline TN can be computed as, the following is not true negative yet\n",
    "TNh= len(fd_prod)-(len(data)-len(data[data['label'] == 'added']))\n",
    "print(\"TNh:\",TNh)\n",
    "TNh= len(fd_prod)-(len(data)-len(data[data['label'] == 'deleted']))\n",
    "print(\"TNh:\",TNh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accurary number for the pipeline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98442\n",
      "4930\n",
      "55232\n"
     ]
    }
   ],
   "source": [
    "# Use fuzzy logic to compute the deleted, added, agreed\n",
    "data = data[data['start'] != 0]\n",
    "data = data[data['end'] != 0]\n",
    "#data = data[data['created_at'] == date ] ##Change date to filter for datewise data\n",
    "#label_counts = data.groupby(['label']).size().reset_index(name='counts')\n",
    "instmatches = data[data['label'] == 'agreed']\n",
    "instfuzzymatches = data[data['label'] == 'deleted']\n",
    "instfuzzymatches = instfuzzymatches[instfuzzymatches['deleted_reason'].isin(['Incorrect Specification - Non-Risk Adjusted','repeated_instance','incorrect_year_of_service']) ]\n",
    "instmatches = pd.concat([instmatches, instfuzzymatches])\n",
    "instmatches = instmatches[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "instdeleted = data[data['label'] == 'deleted']\n",
    "instdeleted = instdeleted[instdeleted['deleted_reason'] != 'other']\n",
    "instdeleted = pd.merge(instdeleted, instmatches,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "instdeleted = instdeleted[instdeleted['_merge'] == 'left_only']\n",
    "instdeleted = instdeleted[['chart_id','submission_id','code_id','start','end','deleted_reason']].drop_duplicates()\n",
    "deleted_reason = instdeleted.groupby(['deleted_reason']).size().reset_index(name = 'counts')\n",
    "instdeleted = instdeleted[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "\n",
    "instadded = data[data['label'] == 'added']\n",
    "instadded = pd.merge(instadded, instmatches,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "instadded = instadded[instadded['_merge'] == 'left_only']\n",
    "instadded = instadded[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "instadded = pd.merge(instadded, instdeleted,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "instadded = instadded[instadded['_merge'] == 'left_only']\n",
    "instadded = instadded[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "added = len(instadded)\n",
    "deleted = len(instdeleted)\n",
    "agreed = len(instmatches)\n",
    "print(added)\n",
    "print(deleted)\n",
    "print(agreed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chart_id', 'submission_id', 'code_id', 'start', 'end'], dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instmatches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my added small part\n",
    "instmatchessub=instmatches[['chart_id', 'code_id', 'submission_id','start','end']]\n",
    "instmatchessub.columns = ['chart_id', 'code_id','submission_id', 'start_offset', 'end_offset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    225651\n",
       "0    192659\n",
       "Name: all_model_pred, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_prod['all_model_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should use fd_prod[fd_prod['all_model_pred']==1]  if it want to find instadded_modeldeleted\n",
    "instadded.columns = ['chart_id', 'submission_id', 'code_id', 'start_offset', 'end_offset']\n",
    "prod_additions_models = pd.merge(instadded, fd_prod,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "prod_additions_models['abs_diff_start'] = abs(prod_additions_models['start_offset_x'] - prod_additions_models['start_offset_y'])\n",
    "prod_additions_models['abs_diff_end'] = abs(prod_additions_models['end_offset_x'] - prod_additions_models['end_offset_y'])\n",
    "prod_additions_models1 = prod_additions_models[ (\n",
    "                    (prod_additions_models['code_id'] == prod_additions_models['code']) \n",
    "                    & (prod_additions_models['abs_diff_start'] <= 75))\n",
    "          | (prod_additions_models['start_offset_x'] == prod_additions_models['start_offset_y'])\n",
    "          | (prod_additions_models['end_offset_x'] == prod_additions_models['end_offset_y'])\n",
    "          |((prod_additions_models['code_id'] == prod_additions_models['code']) \n",
    "                    & (prod_additions_models['abs_diff_end'] <= 75))\n",
    "          ]\n",
    "instadded_modeldeleted = prod_additions_models1[['chart_id','submission_id','code','start_offset_y','end_offset_y']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93889"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instadded_modeldeleted)  # should it be called instadded_modelpassed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18730\n"
     ]
    }
   ],
   "source": [
    "# my correction here\n",
    "instadded.columns = ['chart_id', 'submission_id', 'code_id', 'start_offset', 'end_offset']\n",
    "fd_prod1=fd_prod[fd_prod['all_model_pred']==1] # if it want to find instadded_modeldeleted\n",
    "\n",
    "prod_additions_models = pd.merge(instadded, fd_prod1,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "prod_additions_models['abs_diff_start'] = abs(prod_additions_models['start_offset_x'] - prod_additions_models['start_offset_y'])\n",
    "prod_additions_models['abs_diff_end'] = abs(prod_additions_models['end_offset_x'] - prod_additions_models['end_offset_y'])\n",
    "prod_additions_models1 = prod_additions_models[ (\n",
    "                    (prod_additions_models['code_id'] == prod_additions_models['code']) \n",
    "                    & (prod_additions_models['abs_diff_start'] <= 75))\n",
    "          | (prod_additions_models['start_offset_x'] == prod_additions_models['start_offset_y'])\n",
    "          | (prod_additions_models['end_offset_x'] == prod_additions_models['end_offset_y'])\n",
    "          |((prod_additions_models['code_id'] == prod_additions_models['code']) \n",
    "                    & (prod_additions_models['abs_diff_end'] <= 75))\n",
    "          ]\n",
    "instadded_modeldeleted2 = prod_additions_models1[['chart_id','submission_id','code','start_offset_y','end_offset_y']].drop_duplicates()\n",
    "print(len(instadded_modeldeleted2))\n",
    "# it differs dramatically from istadded_modeldeleted, because istadded_modeldeleted is taking the whole instances before AI\n",
    "# overlap with the added. If that's the purpose, shouldn't be called the misleading istadded_modeldeleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 55232\n",
      "TN: 340587\n",
      "FN: 98442\n",
      "FP: 4930\n",
      "precision: 0.9180545859512649\n",
      "recall: 0.3594101799914104\n",
      "accuracy: 0.7929209460907749\n",
      "-------------------\n",
      "Agreements =  55232\n",
      "Deletions =  4930\n",
      "Additions =  98442\n"
     ]
    }
   ],
   "source": [
    "# initial numbers considering all the additions data for recall\n",
    "\n",
    "total = len(instmatches) + len(instdeleted) + len(instadded)\n",
    "added = len(instadded)\n",
    "deleted = len(instdeleted)\n",
    "agreed = len(instmatches)\n",
    "\n",
    "TP = agreed\n",
    "FN = added\n",
    "FP = deleted\n",
    "TN= len(fd_prod)-(len(data)-len(data[data['label'] == 'added']))\n",
    "\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n",
    "\n",
    "print('-------------------')\n",
    "print('Agreements = ', agreed)\n",
    "print('Deletions = ', deleted)\n",
    "print('Additions = ', added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 55232\n",
      "TN: 340587\n",
      "FN: 93889\n",
      "FP: 4930\n",
      "precision: 0.9180545859512649\n",
      "recall: 0.3703837822975973\n",
      "accuracy: 0.8002195545024846\n",
      "-------------------\n",
      "Agreements =  55232\n",
      "Deletions =  4930\n",
      "Additions =  93889\n"
     ]
    }
   ],
   "source": [
    "# initial numbers considering model deleted additions data for recall\n",
    "'''\n",
    "\n",
    "total = len(instmatches) + len(instdeleted) + len(instadded_modeldeleted)\n",
    "added = len(instadded_modeldeleted)  # shouldn't use here, because this model is not the orginal model, \n",
    "                                    \n",
    "deleted = len(instdeleted)\n",
    "agreed = len(instmatches)\n",
    "\n",
    "TP = agreed\n",
    "FN = added\n",
    "FP = deleted\n",
    "TN1= len(fd_prod)-(len(data)-len(data[data['label'] == 'added']))\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN1+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n",
    "\n",
    "print('-------------------')\n",
    "print('Agreements = ', agreed)\n",
    "print('Deletions = ', deleted)\n",
    "print('Additions = ', added)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Refreshed  Model accuracy numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418310\n"
     ]
    }
   ],
   "source": [
    "print(len(df_pred1))   # model output with all the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418310\n"
     ]
    }
   ],
   "source": [
    "print(len(fd_prod))  # already selected  the 7500 chart  from previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_prod['chart_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chart_id          object\n",
       "code              object\n",
       "start_offset       int64\n",
       "end_offset         int64\n",
       "text75            object\n",
       "all_model_pred     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_prod.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 225651\n"
     ]
    }
   ],
   "source": [
    "TN=len(fd_prod[fd_prod['all_model_pred']==1])  # predicted deleted instances, but not true negative yet\n",
    "print(\"TN:\",TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192659"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select those 7500 charts and only passed the filtering not deleted, 0 is keep here\n",
    "dev_df_sub_1 = fd_prod[fd_prod['all_model_pred']==0]  # select the predicted as pass instances\n",
    "len(dev_df_sub_1[['chart_id','start_offset']].drop_duplicates())  # 192659 instances pass through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "dev_df_sub_1.rename(columns={'start_offset':'start','end_offset':'end'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_sub_1.rename(columns={'code':'code_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225651\n"
     ]
    }
   ],
   "source": [
    "# selected the model predicted as deleted instances\n",
    "# 1 is delete here\n",
    "dev_df_sub_2 = fd_prod[fd_prod['all_model_pred']==1]  # select the predicted as model delete instances\n",
    "print(len(dev_df_sub_2[['chart_id','start_offset']].drop_duplicates()))  # 225651 instances didn't pass through\n",
    "dev_df_sub_2.rename(columns={'start_offset':'start','end_offset':'end'},inplace=True)\n",
    "dev_df_sub_2.rename(columns={'code':'code_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3187\n"
     ]
    }
   ],
   "source": [
    "modeldelete_coderagreed=pd.merge(dev_df_sub_2[['chart_id','start']], instmatches,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "print(len(modeldelete_coderagreed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14297\n"
     ]
    }
   ],
   "source": [
    "modeldelete_coderadded=pd.merge(dev_df_sub_2[['chart_id','start']], instadded,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "print(len(modeldelete_coderadded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches = pd.merge(dev_df_sub_1[['chart_id','start']], instmatches,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "new_deleted = pd.merge(dev_df_sub_1[['chart_id','start']], instdeleted,how = 'inner', on = ['chart_id','start'], indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "instadded.columns = ['chart_id', 'submission_id', 'code_id', 'start', 'end']\n",
    "new_added = pd.merge(dev_df_sub_1, instadded,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "new_added['abs_diff_start'] = abs(new_added['start_x'] - new_added['start_y'])\n",
    "new_added['abs_diff_end'] = abs(new_added['end_x'] - new_added['end_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55113\n"
     ]
    }
   ],
   "source": [
    "new_added1 = new_added[ (\n",
    "                    (new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                    & (new_added['abs_diff_start'] <= 5))\n",
    "          | (new_added['start_x'] == new_added['start_y'])\n",
    "          ]\n",
    "print(len(new_added1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27737\n"
     ]
    }
   ],
   "source": [
    "# or use fuzzy match\n",
    "newmodeldeleted_added = pd.merge(dev_df_sub_2, instadded,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "newmodeldeleted_added['abs_diff_start'] = abs(new_added['start_x'] - new_added['start_y'])\n",
    "newmodeldeleted_added['abs_diff_end'] = abs(new_added['end_x'] - new_added['end_y'])\n",
    "newmodeldeleted_added1 = newmodeldeleted_added[ (\n",
    "                    (newmodeldeleted_added['code_id_x'] == newmodeldeleted_added['code_id_y']) \n",
    "                    & (newmodeldeleted_added['abs_diff_start'] <= 75))\n",
    "          | (newmodeldeleted_added['start_x'] == newmodeldeleted_added['start_y'])\n",
    "          | (newmodeldeleted_added['end_x'] == newmodeldeleted_added['end_y'])\n",
    "          |((newmodeldeleted_added['code_id_x'] == newmodeldeleted_added['code_id_y']) \n",
    "                    & (newmodeldeleted_added['abs_diff_end'] <= 75))\n",
    "          ]\n",
    "print(len(newmodeldeleted_added1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27737\n"
     ]
    }
   ],
   "source": [
    "# use fuzzy match there are more instances for model-deleted but coder added, from 14297 to 27737\n",
    "modeldelete_coderadded2=newmodeldeleted_added1\n",
    "print(len(modeldelete_coderadded2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90795\n"
     ]
    }
   ],
   "source": [
    "#1. if the start offset matches exactly\n",
    "#2. If the end offset matches exactly\n",
    "#3. If the overlap of start offset is between 75 characters and the code id matches\n",
    "#4. If the overlap of end offset is between 75 characters and the code id matches\n",
    "new_added2 = new_added[ (\n",
    "                    (new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                    & (new_added['abs_diff_start'] <= 75))\n",
    "          | (new_added['start_x'] == new_added['start_y'])\n",
    "          | (new_added['end_x'] == new_added['end_y'])\n",
    "          |((new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                    & (new_added['abs_diff_end'] <= 75))\n",
    "          ]\n",
    "print(len(new_added2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chart_id', 'submission_id', 'code_id', 'start', 'end'], dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instadded_modeldeleted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74464"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just validating the additions with a different method of calculation\n",
    "instadded_modeldeleted.columns = ['chart_id', 'submission_id', 'code_id', 'start', 'end']\n",
    "x = pd.merge(dev_df_sub_1[['chart_id','start']].drop_duplicates()\n",
    "             , instadded_modeldeleted[['chart_id','start']].drop_duplicates()\n",
    "             ,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chart_id', 'submission_id', 'code_id', 'start', 'end'], dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instadded_modeldeleted2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just validating the additions with a different method of calculation\n",
    "instadded_modeldeleted2.columns = ['chart_id', 'submission_id', 'code_id', 'start', 'end']\n",
    "x2 = pd.merge(dev_df_sub_1[['chart_id','start']].drop_duplicates()\n",
    "             , instadded_modeldeleted2[['chart_id','start']].drop_duplicates()\n",
    "             ,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "len(x2)    # overlap model deleted, instance added, with the model agreed instances, should be zero? Added by my check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52043\n",
      "3692\n",
      "54188\n",
      "74464\n"
     ]
    }
   ],
   "source": [
    "print(len(new_matches))\n",
    "print(len(new_deleted))\n",
    "print(len(new_added1[['chart_id','start_x']].drop_duplicates()))\n",
    "print(len(new_added2[['chart_id','start_x']].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106231\n",
      "86428\n",
      "44254\n",
      "--------\n",
      "126507\n",
      "66152\n",
      "23978\n",
      "30924\n",
      "17484\n"
     ]
    }
   ],
   "source": [
    "#type 1 - older number of additions considering only start offset\n",
    "refreshed_agreements1 = int(len(new_matches)) + int(len(new_added1[['chart_id','start_x']].drop_duplicates()))\n",
    "refreshed_deletions1 = int(len(dev_df_sub_1[['chart_id','start']].drop_duplicates())) - (int(len(new_matches)) + int(len(new_added1[['chart_id','start_x']].drop_duplicates()))) \n",
    "refreshed_additions1 = added - int(len(new_added1[['chart_id','start_x']].drop_duplicates()))\n",
    "\n",
    "#type 2 - new number of additions considering start offset and end offset\n",
    "refreshed_agreements2 = int(len(new_matches)) + int(len(new_added2[['chart_id','start_x']].drop_duplicates()))\n",
    "refreshed_deletions2 = int(len(dev_df_sub_1[['chart_id','start']].drop_duplicates())) - (int(len(new_matches)) + int(len(new_added2[['chart_id','start_x']].drop_duplicates()))) \n",
    "refreshed_additions2 = added - int(len(new_added2[['chart_id','start_x']].drop_duplicates()))\n",
    "\n",
    "# have second thought on addition, should we use model predicted as deletion, but coder feedback is agreed or added\n",
    "# as deletion? I'm adding it here as refreshed_additions3\n",
    "\n",
    "refreshed_additions3= int(len(modeldelete_coderagreed))+ int(len(modeldelete_coderadded2))\n",
    "refreshed_additions4= int(len(modeldelete_coderagreed))+ int(len(modeldelete_coderadded))\n",
    "\n",
    "print(refreshed_agreements1)\n",
    "print(refreshed_deletions1)\n",
    "print(refreshed_additions1)\n",
    "print(\"--------\")\n",
    "print(refreshed_agreements2)\n",
    "print(refreshed_deletions2)\n",
    "print(refreshed_additions2)\n",
    "print(refreshed_additions3)  # this one defintely make the number worse, because it's the FN\n",
    "print(refreshed_additions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236913\n",
      "216637\n",
      "223583\n",
      "210143\n"
     ]
    }
   ],
   "source": [
    "refreshed_total1 = refreshed_agreements1 + refreshed_deletions1 + refreshed_additions1\n",
    "refreshed_total2 = refreshed_agreements2 + refreshed_deletions2 + refreshed_additions2\n",
    "refreshed_total3 = refreshed_agreements2 + refreshed_deletions2 + refreshed_additions3\n",
    "refreshed_total4 = refreshed_agreements2 + refreshed_deletions2 + refreshed_additions4\n",
    "print(refreshed_total1)\n",
    "print(refreshed_total2)\n",
    "print(refreshed_total3)\n",
    "print(refreshed_total4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225651\n",
      "192659\n"
     ]
    }
   ],
   "source": [
    "# my added part of calculating TN\n",
    "fd_prodsub=fd_prod[fd_prod['all_model_pred']==1]\n",
    "fd_prodsub2=fd_prod[fd_prod['all_model_pred']==0]\n",
    "print(len(fd_prodsub))   # predicted as delete\n",
    "print(len(fd_prodsub2))  # not deleted, presented to coder\n",
    "fd_prodsub.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "       'all_model_pred']   # model predicted as deleted\n",
    "fd_prodsub2.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "       'all_model_pred']   # model predicted as passing through or agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "instaddedsub=instadded[['chart_id', 'submission_id','code_id', 'start','end']]\n",
    "instaddedsub.columns = ['chart_id', 'submission_id', 'code_id', 'start_offset', 'end_offset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_prodsub.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "       'all_model_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20220"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instmatchedaddedsub = pd.concat([instaddedsub,instmatchessub])\n",
    "#instmatchedaddedsub=instmatchedaddedsub[['chart_id', 'code_id', 'submission_id','start','end']]\n",
    "#instmatchedaddedsub.columns = ['chart_id', 'code_id','submission_id', 'start_offset', 'end_offset']\n",
    "#print(len(instmatchedaddedsub))  # 25273\n",
    "prod_agree_models = pd.merge(instmatchedaddedsub, fd_prodsub,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "len(prod_agree_models)\n",
    "\n",
    "prod_agree_models['abs_diff_start'] = abs(prod_agree_models['start_offset_x'] - prod_agree_models['start_offset_y'])\n",
    "prod_agree_models['abs_diff_end'] = abs(prod_agree_models['end_offset_x'] - prod_agree_models['end_offset_y'])\n",
    "\n",
    "prod_agree_models1 = prod_agree_models[ (\n",
    "                    (prod_agree_models['code_id_x'] == prod_agree_models['code_id_y']) \n",
    "                    & (prod_agree_models['abs_diff_start'] <= 5))\n",
    "          | (prod_agree_models['start_offset_x'] == prod_agree_models['start_offset_y'])\n",
    "          | (prod_agree_models['end_offset_x'] == prod_agree_models['end_offset_y'])\n",
    "          |((prod_agree_models['code_id_x'] == prod_agree_models['code_id_y']) \n",
    "                    & (prod_agree_models['abs_diff_end'] <= 5))\n",
    "          ]\n",
    "\n",
    "instaddagreed_modeldeleted = prod_agree_models1[['chart_id','submission_id','code_id_x','code_id_y','start_offset_x','end_offset_x']].drop_duplicates()\n",
    "print(len(instaddagreed_modeldeleted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance level New Models:\n",
      "Agreements =  44.839666881935564 %\n",
      "Deletions =  36.480902272142096 %\n",
      "Additions =  18.679430845922344 %\n",
      "Precision =  55.1393913598638 %\n",
      "Recall =  70.59241784895505 %\n",
      "-------------------\n",
      "Agreements =  106231\n",
      "Deletions =  86428\n",
      "Additions =  44254\n",
      "TP: 106231\n",
      "TN: 205431\n",
      "FN: 44254\n",
      "FP: 86428\n",
      "precision: 0.551393913598638\n",
      "recall: 0.7059241784895505\n",
      "accuracy: 0.7045692944857396\n"
     ]
    }
   ],
   "source": [
    "#type 1 calculation\n",
    "\n",
    "print('Instance level New Models:')\n",
    "print('Agreements = ', refreshed_agreements1*100/refreshed_total1,'%')\n",
    "print('Deletions = ', refreshed_deletions1*100/refreshed_total1,'%')\n",
    "print('Additions = ', refreshed_additions1*100/refreshed_total1,'%')\n",
    "print('Precision = ', refreshed_agreements1*100/(refreshed_agreements1+refreshed_deletions1),'%')\n",
    "print('Recall = ', refreshed_agreements1*100/(refreshed_agreements1+refreshed_additions1),'%')\n",
    "print('-------------------')\n",
    "print('Agreements = ', refreshed_agreements1)\n",
    "print('Deletions = ', refreshed_deletions1)\n",
    "print('Additions = ', refreshed_additions1)\n",
    "\n",
    "TP = refreshed_agreements1\n",
    "FP = refreshed_deletions1\n",
    "FN = refreshed_additions1\n",
    "\n",
    "TN=len(fd_prod[fd_prod['all_model_pred']==1])-len(instaddagreed_modeldeleted)  # deleted instances\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance level New Models:\n",
      "Agreements =  58.395841892197545 %\n",
      "Deletions =  30.53587337343113 %\n",
      "Additions =  11.068284734371321 %\n",
      "Precision =  65.66368557918395 %\n",
      "Recall =  84.06618599860451 %\n",
      "-------------------\n",
      "Agreements =  126507\n",
      "Deletions =  66152\n",
      "Additions =  23978\n",
      "TP: 126507\n",
      "TN: 205431\n",
      "FN: 23978\n",
      "FP: 66152\n",
      "precision: 0.6566368557918395\n",
      "recall: 0.8406618599860451\n",
      "accuracy: 0.7864562108475411\n"
     ]
    }
   ],
   "source": [
    "#type 2 calculation\n",
    "\n",
    "print('Instance level New Models:')\n",
    "print('Agreements = ', refreshed_agreements2*100/refreshed_total2,'%')\n",
    "print('Deletions = ', refreshed_deletions2*100/refreshed_total2,'%')\n",
    "print('Additions = ', refreshed_additions2*100/refreshed_total2,'%')\n",
    "print('Precision = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_deletions2),'%')\n",
    "print('Recall = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_additions2),'%')\n",
    "print('-------------------')\n",
    "print('Agreements = ', refreshed_agreements2)\n",
    "print('Deletions = ', refreshed_deletions2)\n",
    "print('Additions = ', refreshed_additions2)\n",
    "\n",
    "\n",
    "\n",
    "TP = refreshed_agreements2\n",
    "FP = refreshed_deletions2\n",
    "FN = refreshed_additions2\n",
    "\n",
    "TN=len(fd_prod[fd_prod['all_model_pred']==1])-len(instaddagreed_modeldeleted)  # deleted instances\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance level New Models:\n",
      "Agreements =  56.58167213070761 %\n",
      "Deletions =  29.58722264215079 %\n",
      "Additions =  13.831105227141599 %\n",
      "Precision =  65.66368557918395 %\n",
      "Recall =  80.35710882862969 %\n",
      "-------------------\n",
      "Agreements =  126507\n",
      "Deletions =  66152\n",
      "Additions =  30924\n",
      "TP: 126507\n",
      "TN: 205431\n",
      "FN: 30924\n",
      "FP: 66152\n",
      "precision: 0.6566368557918395\n",
      "recall: 0.8035710882862969\n",
      "accuracy: 0.7737230020465533\n"
     ]
    }
   ],
   "source": [
    "#type 3 calculation\n",
    "\n",
    "print('Instance level New Models:')\n",
    "print('Agreements = ', refreshed_agreements2*100/refreshed_total3,'%')\n",
    "print('Deletions = ', refreshed_deletions2*100/refreshed_total3,'%')\n",
    "print('Additions = ', refreshed_additions3*100/refreshed_total3,'%')\n",
    "print('Precision = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_deletions2),'%')\n",
    "print('Recall = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_additions3),'%')\n",
    "print('-------------------')\n",
    "print('Agreements = ', refreshed_agreements2)\n",
    "print('Deletions = ', refreshed_deletions2)\n",
    "print('Additions = ', refreshed_additions3)\n",
    "\n",
    "\n",
    "\n",
    "TP = refreshed_agreements2\n",
    "FP = refreshed_deletions2\n",
    "FN = refreshed_additions3\n",
    "\n",
    "TN=len(fd_prod[fd_prod['all_model_pred']==1])-len(instaddagreed_modeldeleted)  # deleted instances\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance level New Models:\n",
      "Agreements =  60.2004349419205 %\n",
      "Deletions =  31.479516329356677 %\n",
      "Additions =  14.715693599120598 %\n",
      "Precision =  65.66368557918395 %\n",
      "Recall =  87.85757443173532 %\n",
      "-------------------\n",
      "Agreements =  126507\n",
      "Deletions =  66152\n",
      "Additions =  17484\n",
      "TP: 126507\n",
      "TN: 205431\n",
      "FN: 17484\n",
      "FP: 66152\n",
      "precision: 0.6566368557918395\n",
      "recall: 0.8785757443173532\n",
      "accuracy: 0.7987458310673912\n"
     ]
    }
   ],
   "source": [
    "#type 4 calculation\n",
    "\n",
    "print('Instance level New Models:')\n",
    "print('Agreements = ', refreshed_agreements2*100/refreshed_total4,'%')\n",
    "print('Deletions = ', refreshed_deletions2*100/refreshed_total4,'%')\n",
    "print('Additions = ', refreshed_additions3*100/refreshed_total4,'%')\n",
    "print('Precision = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_deletions2),'%')\n",
    "print('Recall = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_additions4),'%')\n",
    "print('-------------------')\n",
    "print('Agreements = ', refreshed_agreements2)\n",
    "print('Deletions = ', refreshed_deletions2)\n",
    "print('Additions = ', refreshed_additions4)\n",
    "\n",
    "\n",
    "\n",
    "TP = refreshed_agreements2\n",
    "FP = refreshed_deletions2\n",
    "FN = refreshed_additions4\n",
    "\n",
    "TN=len(fd_prod[fd_prod['all_model_pred']==1])-len(instaddagreed_modeldeleted)  # deleted instances\n",
    "\n",
    "precision=TP/(FP+TP)\n",
    "recall=TP/(FN+TP)\n",
    "accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a html copy\n",
    "#!jupyter nbconvert --to html all28refreshedmodels_comptoAMresult_050819-deleteinstances.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
