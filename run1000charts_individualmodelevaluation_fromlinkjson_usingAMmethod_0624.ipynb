{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import os,boto3,sys,glob,json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1  Loading the  data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF=pd.read_csv('run1000charts_0521.csv')\n",
    "#testDF= pd.read_csv('/home/jovyan/work/Analytics_Data_training/bfAI_allinst_7502charts_061019.csv') # 7502 charts\n",
    "\n",
    "# the csv is generated in D drive D:/chartai_qa  with extract1000charts_jsontxt.py, then uploaded to here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76792"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'chart_id', 'code', 'text', 'start_offset', 'end_offset',\n",
       "       'text75'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF=testDF.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>E063</td>\n",
       "      <td>Ht</td>\n",
       "      <td>1187</td>\n",
       "      <td>1189</td>\n",
       "      <td>ocedure codes 36415 venipunct routine vital si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>E785</td>\n",
       "      <td>Hyperlipidemia</td>\n",
       "      <td>1374</td>\n",
       "      <td>1388</td>\n",
       "      <td>tion list reviewed reconciled patient past med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>I10</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>1391</td>\n",
       "      <td>1403</td>\n",
       "      <td>reconciled patient past medical history hyperl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>E785</td>\n",
       "      <td>Hyperlipidemia</td>\n",
       "      <td>2957</td>\n",
       "      <td>2971</td>\n",
       "      <td>tion list reviewed reconciled patient past med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBXRMA2018_MULT_1163297620010001_HMK_179342168...</td>\n",
       "      <td>I10</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>2974</td>\n",
       "      <td>2986</td>\n",
       "      <td>reconciled patient past medical history hyperl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            chart_id  code            text  \\\n",
       "0  IBXRMA2018_MULT_1163297620010001_HMK_179342168...  E063              Ht   \n",
       "1  IBXRMA2018_MULT_1163297620010001_HMK_179342168...  E785  Hyperlipidemia   \n",
       "2  IBXRMA2018_MULT_1163297620010001_HMK_179342168...   I10    Hypertension   \n",
       "3  IBXRMA2018_MULT_1163297620010001_HMK_179342168...  E785  Hyperlipidemia   \n",
       "4  IBXRMA2018_MULT_1163297620010001_HMK_179342168...   I10    Hypertension   \n",
       "\n",
       "   start_offset  end_offset                                             text75  \n",
       "0          1187        1189  ocedure codes 36415 venipunct routine vital si...  \n",
       "1          1374        1388  tion list reviewed reconciled patient past med...  \n",
       "2          1391        1403  reconciled patient past medical history hyperl...  \n",
       "3          2957        2971  tion list reviewed reconciled patient past med...  \n",
       "4          2974        2986  reconciled patient past medical history hyperl...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just check if there's null text, if yes, remove them \n",
    "nulltext=testDF[~pd.notnull(testDF['text'])] \n",
    "len(nulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulltext=testDF[~pd.notnull(testDF['text75'])] \n",
    "len(nulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>IBXRMA2018_MULT_1164353980010001_HMK_160303709...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>IBXRMA2018_MULT_1176161080010001_HMK_192365603...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>IBXRMA2018_MULT_1202740400010001_HMK_153425750...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>IBXRMA2018_MULT_1202908350010001_HMK_210648786...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>IBXRMA2018_MULT_1210779380010001_HMK_184462858...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>IBXRMA2018_MULT_1212745310010001_HMK_165441851...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>IBXRMA2018_MULT_1216729130010001_HMK_196286386...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>IBXRMA2018_MULT_1216856710010001_HMK_173309591...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>IBXRMA2018_MULT_1216874020010001_HMK_143364782...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21748</th>\n",
       "      <td>IBXRMA2018_MULT_1216901800010001_HMK_201224196...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23385</th>\n",
       "      <td>IBXRMA2018_MULT_1216920010010001_HMK_166407506...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36203</th>\n",
       "      <td>IBXRMA2018_MULT_1217130710010001_HMK_180325209...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38069</th>\n",
       "      <td>IBXRMA2018_MULT_1217196230010001_HMK_147405194...</td>\n",
       "      <td>H4010X0</td>\n",
       "      <td>glaucoma</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42560</th>\n",
       "      <td>IBXRMA2018_MULT_1217427650010001_HMK_140260863...</td>\n",
       "      <td>I200</td>\n",
       "      <td>1200</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49636</th>\n",
       "      <td>IBXRMA2018_MULT_1217591910010001_HMK_168240489...</td>\n",
       "      <td>E780</td>\n",
       "      <td>cholesterol</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50776</th>\n",
       "      <td>IBXRMA2018_MULT_1217621540010001_HMK_169322472...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55924</th>\n",
       "      <td>IBXRMA2018_MULT_1217796040010001_HMK_211221367...</td>\n",
       "      <td>E785</td>\n",
       "      <td>hyperlipidemia  unspecified</td>\n",
       "      <td>52</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56125</th>\n",
       "      <td>IBXRMA2018_MULT_1217797400010001_HMK_583093637...</td>\n",
       "      <td>E1169</td>\n",
       "      <td>diabetic foot</td>\n",
       "      <td>72</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57927</th>\n",
       "      <td>IBXRMA2018_MULT_1217834870010001_HMK_192226422...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59488</th>\n",
       "      <td>IBXRMA2018_MULT_1217905040010001_HMK_174329240...</td>\n",
       "      <td>J449</td>\n",
       "      <td>cord</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61236</th>\n",
       "      <td>IBXRMA2018_MULT_1217936810010001_HMK_MA1462698...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67867</th>\n",
       "      <td>IBXRMA2018_MULT_1217996130010001_HMK_314380144...</td>\n",
       "      <td>E744</td>\n",
       "      <td>PC</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69643</th>\n",
       "      <td>IBXRMA2018_MULT_1218012650010001_HMK_197249628...</td>\n",
       "      <td>N189</td>\n",
       "      <td>CKD</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69946</th>\n",
       "      <td>IBXRMA2018_MULT_1218015600010001_HMK_3GM6V72QA...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72670</th>\n",
       "      <td>IBXRMA2018_MULT_1218027670010001_HMK_198289883...</td>\n",
       "      <td>N08</td>\n",
       "      <td>Kidney</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76646</th>\n",
       "      <td>IBXRMA2018_MULT_1231613440010001_HMK_177320615...</td>\n",
       "      <td>G129</td>\n",
       "      <td>SMA</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id     code  \\\n",
       "1336   IBXRMA2018_MULT_1164353980010001_HMK_160303709...     G129   \n",
       "2198   IBXRMA2018_MULT_1176161080010001_HMK_192365603...      N08   \n",
       "3876   IBXRMA2018_MULT_1202740400010001_HMK_153425750...     G129   \n",
       "4032   IBXRMA2018_MULT_1202908350010001_HMK_210648786...     E744   \n",
       "5591   IBXRMA2018_MULT_1210779380010001_HMK_184462858...     G129   \n",
       "6465   IBXRMA2018_MULT_1212745310010001_HMK_165441851...      N08   \n",
       "9116   IBXRMA2018_MULT_1216729130010001_HMK_196286386...      N08   \n",
       "14970  IBXRMA2018_MULT_1216856710010001_HMK_173309591...     G129   \n",
       "18950  IBXRMA2018_MULT_1216874020010001_HMK_143364782...     E744   \n",
       "21748  IBXRMA2018_MULT_1216901800010001_HMK_201224196...     G129   \n",
       "23385  IBXRMA2018_MULT_1216920010010001_HMK_166407506...      N08   \n",
       "36203  IBXRMA2018_MULT_1217130710010001_HMK_180325209...     E744   \n",
       "38069  IBXRMA2018_MULT_1217196230010001_HMK_147405194...  H4010X0   \n",
       "42560  IBXRMA2018_MULT_1217427650010001_HMK_140260863...     I200   \n",
       "49636  IBXRMA2018_MULT_1217591910010001_HMK_168240489...     E780   \n",
       "50776  IBXRMA2018_MULT_1217621540010001_HMK_169322472...     E744   \n",
       "55924  IBXRMA2018_MULT_1217796040010001_HMK_211221367...     E785   \n",
       "56125  IBXRMA2018_MULT_1217797400010001_HMK_583093637...    E1169   \n",
       "57927  IBXRMA2018_MULT_1217834870010001_HMK_192226422...     E744   \n",
       "59488  IBXRMA2018_MULT_1217905040010001_HMK_174329240...     J449   \n",
       "61236  IBXRMA2018_MULT_1217936810010001_HMK_MA1462698...     G129   \n",
       "67867  IBXRMA2018_MULT_1217996130010001_HMK_314380144...     E744   \n",
       "69643  IBXRMA2018_MULT_1218012650010001_HMK_197249628...     N189   \n",
       "69946  IBXRMA2018_MULT_1218015600010001_HMK_3GM6V72QA...      N08   \n",
       "72670  IBXRMA2018_MULT_1218027670010001_HMK_198289883...      N08   \n",
       "76646  IBXRMA2018_MULT_1231613440010001_HMK_177320615...     G129   \n",
       "\n",
       "                              text  start_offset  end_offset text75  \n",
       "1336                           SMA             4           7    NaN  \n",
       "2198                        Kidney            46          52    NaN  \n",
       "3876                           SMA             4           7    NaN  \n",
       "4032                            PC            25          27    NaN  \n",
       "5591                           SMA             4           7    NaN  \n",
       "6465                        Kidney            48          54    NaN  \n",
       "9116                        Kidney            46          52    NaN  \n",
       "14970                          SMA             4           7    NaN  \n",
       "18950                           PC            25          27    NaN  \n",
       "21748                          SMA             4           7    NaN  \n",
       "23385                       Kidney            46          52    NaN  \n",
       "36203                           PC            25          27    NaN  \n",
       "38069                     glaucoma            52          60    NaN  \n",
       "42560                         1200            33          37    NaN  \n",
       "49636                  cholesterol            60          71    NaN  \n",
       "50776                           PC            18          20    NaN  \n",
       "55924  hyperlipidemia  unspecified            52          79    NaN  \n",
       "56125                diabetic foot            72          85    NaN  \n",
       "57927                           PC            18          20    NaN  \n",
       "59488                         cord            65          69    NaN  \n",
       "61236                          SMA             4           7    NaN  \n",
       "67867                           PC            25          27    NaN  \n",
       "69643                          CKD            28          31    NaN  \n",
       "69946                       Kidney            48          54    NaN  \n",
       "72670                       Kidney            46          52    NaN  \n",
       "76646                          SMA             4           7    NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulltext   # there are some text not correctly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF=testDF[pd.notnull(testDF['text75'])] \n",
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF['chart_id'].nunique()   # only 980 charts not 1044 charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76761</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E119</td>\n",
       "      <td>dm2</td>\n",
       "      <td>5902</td>\n",
       "      <td>5905</td>\n",
       "      <td>onciled patient past medical history cholecyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>B182</td>\n",
       "      <td>hepatitis c</td>\n",
       "      <td>6819</td>\n",
       "      <td>6830</td>\n",
       "      <td>lab comp metabolic panel lab glycosolated hemo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76763</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>6951</td>\n",
       "      <td>6971</td>\n",
       "      <td>increat random colon cancer screening notes de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76764</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E782</td>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>7001</td>\n",
       "      <td>7015</td>\n",
       "      <td>declined gi referral vitamin deficiency lab vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76765</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>7144</td>\n",
       "      <td>7147</td>\n",
       "      <td>breast cancer screening imaging mammo digital ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id   code  \\\n",
       "76761  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E119   \n",
       "76762  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   B182   \n",
       "76763  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E550   \n",
       "76764  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E782   \n",
       "76765  IBXRMA2018_MULT_1231614110010001_HMK_196526763...  I2510   \n",
       "\n",
       "                       text  start_offset  end_offset  \\\n",
       "76761                   dm2          5902        5905   \n",
       "76762           hepatitis c          6819        6830   \n",
       "76763  vitamin d deficiency          6951        6971   \n",
       "76764        hyperlipidemia          7001        7015   \n",
       "76765                   cad          7144        7147   \n",
       "\n",
       "                                                  text75  \n",
       "76761  onciled patient past medical history cholecyst...  \n",
       "76762  lab comp metabolic panel lab glycosolated hemo...  \n",
       "76763  increat random colon cancer screening notes de...  \n",
       "76764  declined gi referral vitamin deficiency lab vi...  \n",
       "76765  breast cancer screening imaging mammo digital ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF=testDF.reset_index(drop=True)   # very very import, to reset the index, otherwise the below running the model will not be right, because I use the index as reference for position and matching them\n",
    "testDF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Loading all the models or locate the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.a. Load the 28 pickle files and run them on the testDF with selected chart_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files=glob.glob(\"../../picklefolder_ngrams/refreshed_models_update0531/*.pickle\") # refreshed updated models\n",
    "files=glob.glob(\"../../picklefolder_ngrams/refreshed_models/*19.pickle\")  # refreshed models\n",
    "#files=glob.glob(\"../../picklefolder_ngrams/pipeline_pickles/*.pickle\")  # pipeline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle']"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files=files[:-1]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cancer'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[27].split('/')[-1].split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phrase_Depression_Mar5.pickle'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[10].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../picklefolder_ngrams/pipeline_pickles/Code_Diabetes_Mar5.pickle'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Apply models to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = preprocessing.LabelEncoder()\n",
    "#test_y = encoder.fit_transform(testDF['flag'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list={}\n",
    "code_list[\"Model1\"]=['I10','E119']\n",
    "code_list[\"Model2\"]=['I2510','E785','K219','F329','I639']\n",
    "code_list[\"Model3\"]=['I739','N183','Z992','B20','I213','R569','I43','J410','I714','R579','E550','I209','J45998','I480','B182','K210','K739']\n",
    "code_list[\"Heart\"]=['I509','I482','I4891','I82401']\n",
    "code_list[\"Depression\"]=['F411','F410','F40240','F458','F409','F4000','F4001','F445','F444','F40243','F446','F4010','F442','F408','F449','F451']\n",
    "code_list[\"Kidney\"]=['N189','N181','N182','E1122','I130','E0822','E1022']\n",
    "code_list[\"Diabetes\"]=['Z794','E109','E119','E139','E089','E099']\n",
    "code_list[\"Cancer\"]=['C801','C50919','C189']\n",
    "code_list[\"COPD\"]=['J449','J45909']\n",
    "code_list[\"Cholesterol\"]=['E780','E785','E782','E789','E7800','E784','E781','E7801','E7881','E882','E783','E786','E7889','E756','E755','E7130']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "allpredict=pd.DataFrame()   # create an empty dataframe, to save the prediction result for each model\n",
    "allprob=pd.DataFrame()\n",
    "print(allprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nindexdf=pd.DataFrame() \\nmodel_pipeline = joblib.load(files)\\n  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\\n    # deletion model\\n\\ntestDF1=testDF\\nindexdf[0]= [1 for i in range(len(testDF))]\\n        \\n        \\n        #print(files[i])\\n    # how to put the prediction on the right index?\\ntest=testDF1[\\'text75\\']\\nprint(\"model loaded:\", files )\\nprint(\"length of data for the model:\", len(test))\\n    \\n   \\nproba = model_pipeline.predict_proba(test)[:,1]\\nprediction = np.where(proba > 0.3, 1, 0) # use a lower threshold\\ntestDF1[\\'key\\']=testDF1.index\\ntestDF1[\\'pred\\']=prediction\\ntestDF1[\\'prob\\']= proba\\n\\nindexdf[\\'key\\']=indexdf.index\\nmerged=pd.merge(indexdf,testDF1,on=\\'key\\',how=\\'outer\\')  # maintain the position of the perdiction, match to the right index\\nallpredict[0]=merged[\\'pred\\']    # save the prediction to corresponding dataframe\\nallprob[0]=merged[\\'prob\\']\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for one model evaluation\n",
    "'''\n",
    "indexdf=pd.DataFrame() \n",
    "model_pipeline = joblib.load(files)\n",
    "  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\n",
    "    # deletion model\n",
    "\n",
    "testDF1=testDF\n",
    "indexdf[0]= [1 for i in range(len(testDF))]\n",
    "        \n",
    "        \n",
    "        #print(files[i])\n",
    "    # how to put the prediction on the right index?\n",
    "test=testDF1['text75']\n",
    "print(\"model loaded:\", files )\n",
    "print(\"length of data for the model:\", len(test))\n",
    "    \n",
    "   \n",
    "proba = model_pipeline.predict_proba(test)[:,1]\n",
    "prediction = np.where(proba > 0.3, 1, 0) # use a lower threshold\n",
    "testDF1['key']=testDF1.index\n",
    "testDF1['pred']=prediction\n",
    "testDF1['prob']= proba\n",
    "\n",
    "indexdf['key']=indexdf.index\n",
    "merged=pd.merge(indexdf,testDF1,on='key',how='outer')  # maintain the position of the perdiction, match to the right index\n",
    "allpredict[0]=merged['pred']    # save the prediction to corresponding dataframe\n",
    "allprob[0]=merged['prob']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle\n",
      "length of data for the model: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle\n",
      "length of data for the model: 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle\n",
      "length of data for the model: 7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle\n",
      "length of data for the model: 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle\n",
      "length of data for the model: 3221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle\n",
      "length of data for the model: 1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle\n",
      "length of data for the model: 581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle\n",
      "length of data for the model: 1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle\n",
      "length of data for the model: 1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle\n",
      "length of data for the model: 6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle\n",
      "length of data for the model: 3178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle\n",
      "length of data for the model: 1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle\n",
      "length of data for the model: 16290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle\n",
      "length of data for the model: 1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle\n",
      "length of data for the model: 8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle\n",
      "length of data for the model: 11544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle\n",
      "length of data for the model: 6145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle\n",
      "length of data for the model: 764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle\n",
      "length of data for the model: 2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle\n",
      "length of data for the model: 582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle\n",
      "length of data for the model: 1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle\n",
      "length of data for the model: 5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle\n",
      "length of data for the model: 76766\n"
     ]
    }
   ],
   "source": [
    "#f = open(\"allmodeltestscore_0506.txt\", \"w+\")  # save all the score to this file\n",
    "# for multiple model evaluation\n",
    "\n",
    "   # create a dataframe, otherwise can use testDF for merging to obtain the prediction matched to index\n",
    "# because for some model testing, we only select partial data, like phrase-based model, code-based model\n",
    "for i in range(len(files)):\n",
    "    indexdf=pd.DataFrame() \n",
    "    model_pipeline = joblib.load(files[i])\n",
    "  #  f = open(\"allmodeltestscore_0506.txt\", \"a+\")\n",
    "    # deletion model\n",
    "    if(files[i].split('/')[-1].startswith('D')):\n",
    "        try:\n",
    "            testDF1=testDF\n",
    "            indexdf[i]= [1 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "        \n",
    "    elif(files[i].split('/')[-1].startswith('P')):\n",
    "    # if it's phrase-based model, use the following way to select data\n",
    "        \n",
    "        phrase=files[i].split('/')[4].split('_')[1]\n",
    "        try:\n",
    "            testDF1 = testDF[testDF['text'].str.contains(phrase,flags=re.IGNORECASE)]\n",
    "            temp=testDF1.index.tolist()\n",
    "            indexdf[i]=[1 if i in (temp) else 0 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "\n",
    "    elif(files[i].split('/')[-1].startswith('C')):\n",
    "    # if it's code based model, use the following way to select model\n",
    "        codereason=files[i].split('/')[4].split('_')[1]\n",
    "        try:\n",
    "            testDF1 = testDF[testDF['code'].isin(code_list[codereason])]\n",
    "            temp=testDF1.index.tolist()\n",
    "            indexdf[i]=[1 if i in (temp) else 0 for i in range(len(testDF))]\n",
    "        except:\n",
    "            print('no data for this model')\n",
    "    else:\n",
    "        print('not a valid/good model name probably...')\n",
    "\n",
    "    print(files[i])\n",
    "    # how to put the prediction on the right index?\n",
    "    test=testDF1['text75']\n",
    "    print(\"length of data for the model:\", len(test))\n",
    "    try:\n",
    "        \n",
    "        proba = model_pipeline.predict_proba(test)[:,1]\n",
    "        prediction = np.where(proba > 0.4, 1, 0) # use a lower threshold\n",
    "        #prediction = model_pipeline.predict(test)\n",
    "        \n",
    "        \n",
    "        testDF1['key']=testDF1.index\n",
    "        testDF1['pred']=prediction\n",
    "        testDF1['prob']= proba\n",
    "\n",
    "        indexdf['key']=indexdf.index\n",
    "        merged=pd.merge(indexdf,testDF1,on='key',how='outer')  # maintain the position of the perdiction, match to the right index\n",
    "        allpredict[i]=merged['pred']    # save the prediction to corresponding dataframe\n",
    "        allprob[i]=merged['prob']   # save the probability\n",
    "    except:\n",
    "         print('something is wrong')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Part 2.b. Now get the prediction and probability dataframes and merge with testDF which has all the chart_id etc info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allpredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     76599\n",
       "1     76583\n",
       "2     69367\n",
       "3     76248\n",
       "4     73545\n",
       "5     75332\n",
       "6     76185\n",
       "7     74772\n",
       "8     75576\n",
       "9     70135\n",
       "10    73588\n",
       "11    75610\n",
       "12    60476\n",
       "13    75301\n",
       "14    68037\n",
       "15    65222\n",
       "16    70621\n",
       "17    76002\n",
       "18    74736\n",
       "19    76184\n",
       "20    75238\n",
       "21    71545\n",
       "22        0\n",
       "23        0\n",
       "24        0\n",
       "25        0\n",
       "26        0\n",
       "27        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.isnull().sum()  # a lot of nulls because not all data are run for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2   3   4   5   6   7   8   9  ...  18  19  20  21  22  23  24  \\\n",
       "0 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN   0   0   0   \n",
       "1 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN   0   0   0   \n",
       "2 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN   0   0   0   \n",
       "3 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN   0   0   0   \n",
       "4 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN   0   0   0   \n",
       "\n",
       "   25  26  27  \n",
       "0   0   0   0  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.160061</td>\n",
       "      <td>0.349433</td>\n",
       "      <td>0.196206</td>\n",
       "      <td>0.026679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.021906</td>\n",
       "      <td>0.020609</td>\n",
       "      <td>0.160427</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.008571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.221087</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.018220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.047251</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.101171</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.004171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1         2   3   4   5   6   7   8   9     ...     18  19  20  21  \\\n",
       "0 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN NaN   \n",
       "1 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN NaN   \n",
       "2 NaN NaN  0.113764 NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN NaN   \n",
       "3 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN NaN   \n",
       "4 NaN NaN  0.125394 NaN NaN NaN NaN NaN NaN NaN    ...    NaN NaN NaN NaN   \n",
       "\n",
       "         22        23        24        25        26        27  \n",
       "0  0.014626  0.063301  0.160061  0.349433  0.196206  0.026679  \n",
       "1  0.005715  0.021906  0.020609  0.160427  0.018062  0.008571  \n",
       "2  0.008170  0.036722  0.046403  0.221087  0.024644  0.018220  \n",
       "3  0.002357  0.006155  0.004079  0.047251  0.002172  0.002319  \n",
       "4  0.003010  0.007203  0.021988  0.101171  0.002850  0.004171  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76766"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data frame for predictions from each model\n",
    "#merge to testDF to keep the Nan, which means not omputed for that instance\n",
    "#testDF2=pd.concat([testDF,allpredict],axis=1)\n",
    "#len(testDF2)\n",
    "testDF['index']=testDF.index\n",
    "allpredict['index']=allpredict.index\n",
    "df_pred = pd.merge(testDF,allpredict, how='left', on = 'index')\n",
    "len(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>key</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>index</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76761</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E119</td>\n",
       "      <td>dm2</td>\n",
       "      <td>5902</td>\n",
       "      <td>5905</td>\n",
       "      <td>onciled patient past medical history cholecyst...</td>\n",
       "      <td>76761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>76761</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>B182</td>\n",
       "      <td>hepatitis c</td>\n",
       "      <td>6819</td>\n",
       "      <td>6830</td>\n",
       "      <td>lab comp metabolic panel lab glycosolated hemo...</td>\n",
       "      <td>76762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306477</td>\n",
       "      <td>76762</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76763</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>6951</td>\n",
       "      <td>6971</td>\n",
       "      <td>increat random colon cancer screening notes de...</td>\n",
       "      <td>76763</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686125</td>\n",
       "      <td>76763</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76764</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E782</td>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>7001</td>\n",
       "      <td>7015</td>\n",
       "      <td>declined gi referral vitamin deficiency lab vi...</td>\n",
       "      <td>76764</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194581</td>\n",
       "      <td>76764</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76765</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>7144</td>\n",
       "      <td>7147</td>\n",
       "      <td>breast cancer screening imaging mammo digital ...</td>\n",
       "      <td>76765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990072</td>\n",
       "      <td>76765</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id   code  \\\n",
       "76761  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E119   \n",
       "76762  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   B182   \n",
       "76763  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E550   \n",
       "76764  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E782   \n",
       "76765  IBXRMA2018_MULT_1231614110010001_HMK_196526763...  I2510   \n",
       "\n",
       "                       text  start_offset  end_offset  \\\n",
       "76761                   dm2          5902        5905   \n",
       "76762           hepatitis c          6819        6830   \n",
       "76763  vitamin d deficiency          6951        6971   \n",
       "76764        hyperlipidemia          7001        7015   \n",
       "76765                   cad          7144        7147   \n",
       "\n",
       "                                                  text75    key  pred  \\\n",
       "76761  onciled patient past medical history cholecyst...  76761     0   \n",
       "76762  lab comp metabolic panel lab glycosolated hemo...  76762     0   \n",
       "76763  increat random colon cancer screening notes de...  76763     1   \n",
       "76764  declined gi referral vitamin deficiency lab vi...  76764     0   \n",
       "76765  breast cancer screening imaging mammo digital ...  76765     1   \n",
       "\n",
       "           prob  index ...  18  19  20  21  22  23  24  25  26  27  \n",
       "76761  0.018055  76761 ... NaN NaN NaN NaN   0   0   0   0   0   0  \n",
       "76762  0.306477  76762 ... NaN NaN NaN NaN   0   0   0   0   0   0  \n",
       "76763  0.686125  76763 ... NaN NaN NaN NaN   0   0   0   0   0   1  \n",
       "76764  0.194581  76764 ... NaN NaN NaN NaN   0   0   0   0   0   0  \n",
       "76765  0.990072  76765 ... NaN NaN NaN NaN   0   0   1   1   0   1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76766\n"
     ]
    }
   ],
   "source": [
    "# now the data frame with probabilities\n",
    "testDF['index']=testDF.index\n",
    "allprob['index']=allprob.index\n",
    "df_prob = pd.merge(testDF,allprob, how='left', on = 'index')\n",
    "print(len(df_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>key</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>index</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76761</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E119</td>\n",
       "      <td>dm2</td>\n",
       "      <td>5902</td>\n",
       "      <td>5905</td>\n",
       "      <td>onciled patient past medical history cholecyst...</td>\n",
       "      <td>76761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>76761</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.272709</td>\n",
       "      <td>0.064432</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.018055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>B182</td>\n",
       "      <td>hepatitis c</td>\n",
       "      <td>6819</td>\n",
       "      <td>6830</td>\n",
       "      <td>lab comp metabolic panel lab glycosolated hemo...</td>\n",
       "      <td>76762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306477</td>\n",
       "      <td>76762</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.072086</td>\n",
       "      <td>0.181318</td>\n",
       "      <td>0.381113</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.306477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76763</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>6951</td>\n",
       "      <td>6971</td>\n",
       "      <td>increat random colon cancer screening notes de...</td>\n",
       "      <td>76763</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686125</td>\n",
       "      <td>76763</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018394</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.686125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76764</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E782</td>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>7001</td>\n",
       "      <td>7015</td>\n",
       "      <td>declined gi referral vitamin deficiency lab vi...</td>\n",
       "      <td>76764</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194581</td>\n",
       "      <td>76764</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.183114</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.194581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76765</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>7144</td>\n",
       "      <td>7147</td>\n",
       "      <td>breast cancer screening imaging mammo digital ...</td>\n",
       "      <td>76765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990072</td>\n",
       "      <td>76765</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154583</td>\n",
       "      <td>0.207874</td>\n",
       "      <td>0.571299</td>\n",
       "      <td>0.816210</td>\n",
       "      <td>0.020743</td>\n",
       "      <td>0.990072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id   code  \\\n",
       "76761  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E119   \n",
       "76762  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   B182   \n",
       "76763  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E550   \n",
       "76764  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E782   \n",
       "76765  IBXRMA2018_MULT_1231614110010001_HMK_196526763...  I2510   \n",
       "\n",
       "                       text  start_offset  end_offset  \\\n",
       "76761                   dm2          5902        5905   \n",
       "76762           hepatitis c          6819        6830   \n",
       "76763  vitamin d deficiency          6951        6971   \n",
       "76764        hyperlipidemia          7001        7015   \n",
       "76765                   cad          7144        7147   \n",
       "\n",
       "                                                  text75    key  pred  \\\n",
       "76761  onciled patient past medical history cholecyst...  76761     0   \n",
       "76762  lab comp metabolic panel lab glycosolated hemo...  76762     0   \n",
       "76763  increat random colon cancer screening notes de...  76763     1   \n",
       "76764  declined gi referral vitamin deficiency lab vi...  76764     0   \n",
       "76765  breast cancer screening imaging mammo digital ...  76765     1   \n",
       "\n",
       "           prob  index    ...     18  19  20  21        22        23  \\\n",
       "76761  0.018055  76761    ...    NaN NaN NaN NaN  0.272709  0.064432   \n",
       "76762  0.306477  76762    ...    NaN NaN NaN NaN  0.012492  0.072086   \n",
       "76763  0.686125  76763    ...    NaN NaN NaN NaN  0.018394  0.025507   \n",
       "76764  0.194581  76764    ...    NaN NaN NaN NaN  0.011497  0.027704   \n",
       "76765  0.990072  76765    ...    NaN NaN NaN NaN  0.154583  0.207874   \n",
       "\n",
       "             24        25        26        27  \n",
       "76761  0.027841  0.217822  0.013272  0.018055  \n",
       "76762  0.181318  0.381113  0.030548  0.306477  \n",
       "76763  0.030261  0.122995  0.003520  0.686125  \n",
       "76764  0.075676  0.183114  0.005224  0.194581  \n",
       "76765  0.571299  0.816210  0.020743  0.990072  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.c. Now combine the prediction from 28 models to make one prediction,it's actually an or operation, but here using sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.160061</td>\n",
       "      <td>0.349433</td>\n",
       "      <td>0.196206</td>\n",
       "      <td>0.026679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.021906</td>\n",
       "      <td>0.020609</td>\n",
       "      <td>0.160427</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.221087</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.047251</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.101171</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1         2   3   4   5   6   7   8   9  ...    19  20  21        22  \\\n",
       "0 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN  0.014626   \n",
       "1 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN  0.005715   \n",
       "2 NaN NaN  0.113764 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN  0.008170   \n",
       "3 NaN NaN       NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN  0.002357   \n",
       "4 NaN NaN  0.125394 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN  0.003010   \n",
       "\n",
       "         23        24        25        26        27  index  \n",
       "0  0.063301  0.160061  0.349433  0.196206  0.026679      0  \n",
       "1  0.021906  0.020609  0.160427  0.018062  0.008571      1  \n",
       "2  0.036722  0.046403  0.221087  0.024644  0.018220      2  \n",
       "3  0.006155  0.004079  0.047251  0.002172  0.002319      3  \n",
       "4  0.007203  0.021988  0.101171  0.002850  0.004171      4  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredictNan=allpredict   # keep the original NaN if that row is not computed for that model\n",
    "allpredict=allpredict.fillna(0) # fill the NaNs by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1    2   3   4   5   6   7   8   9  ...    19  20  21  22  23  24  25  \\\n",
       "0 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN   0   0   0   0   \n",
       "1 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN   0   0   0   0   \n",
       "2 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN   0   0   0   0   \n",
       "3 NaN NaN  NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN   0   0   0   0   \n",
       "4 NaN NaN  0.0 NaN NaN NaN NaN NaN NaN NaN  ...   NaN NaN NaN   0   0   0   0   \n",
       "\n",
       "   26  27  index  \n",
       "0   0   0      0  \n",
       "1   0   0      1  \n",
       "2   0   0      2  \n",
       "3   0   0      3  \n",
       "4   0   0      4  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredictNan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...     19   20   21  22  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   0   \n",
       "\n",
       "   23  24  25  26  27  index  \n",
       "0   0   0   0   0   0      0  \n",
       "1   0   0   0   0   0      1  \n",
       "2   0   0   0   0   0      2  \n",
       "3   0   0   0   0   0      3  \n",
       "4   0   0   0   0   0      4  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...   18   19   20   21  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   22  23  24  25  26  27  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpredict.drop(['index'],inplace=True, axis=1)\n",
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...   18   19   20   21  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   22  23  24  25  26  27  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allpredict=allpredict[[22,23,24,25,26,27]]  # only select deletion reason columns\n",
    "#allpredict.columns\n",
    "allpredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredict['Sum'] = allpredict.sum(axis = 1, skipna = True) \n",
    "df_pred['all_model_pred']=[1 if allpredict['Sum'].iloc[i]>=1 else 0 for i in range(len(allpredict))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34493\n",
      "76766\n"
     ]
    }
   ],
   "source": [
    "# check how many 1s are predicted \n",
    "allpredict1=df_pred['all_model_pred']\n",
    "print(sum(allpredict1))\n",
    "print(len(allpredict1))  # 228562 are predicted as deleted out of 418310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the key and predict prob temp columns\n",
    "df_pred.drop(['key','pred','prob','index'],inplace=True, axis=1)\n",
    "df_prob.drop(['key','pred','prob','index'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>text75</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>all_model_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76761</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E119</td>\n",
       "      <td>dm2</td>\n",
       "      <td>5902</td>\n",
       "      <td>5905</td>\n",
       "      <td>onciled patient past medical history cholecyst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>B182</td>\n",
       "      <td>hepatitis c</td>\n",
       "      <td>6819</td>\n",
       "      <td>6830</td>\n",
       "      <td>lab comp metabolic panel lab glycosolated hemo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76763</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E550</td>\n",
       "      <td>vitamin d deficiency</td>\n",
       "      <td>6951</td>\n",
       "      <td>6971</td>\n",
       "      <td>increat random colon cancer screening notes de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76764</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>E782</td>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>7001</td>\n",
       "      <td>7015</td>\n",
       "      <td>declined gi referral vitamin deficiency lab vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76765</th>\n",
       "      <td>IBXRMA2018_MULT_1231614110010001_HMK_196526763...</td>\n",
       "      <td>I2510</td>\n",
       "      <td>cad</td>\n",
       "      <td>7144</td>\n",
       "      <td>7147</td>\n",
       "      <td>breast cancer screening imaging mammo digital ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chart_id   code  \\\n",
       "76761  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E119   \n",
       "76762  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   B182   \n",
       "76763  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E550   \n",
       "76764  IBXRMA2018_MULT_1231614110010001_HMK_196526763...   E782   \n",
       "76765  IBXRMA2018_MULT_1231614110010001_HMK_196526763...  I2510   \n",
       "\n",
       "                       text  start_offset  end_offset  \\\n",
       "76761                   dm2          5902        5905   \n",
       "76762           hepatitis c          6819        6830   \n",
       "76763  vitamin d deficiency          6951        6971   \n",
       "76764        hyperlipidemia          7001        7015   \n",
       "76765                   cad          7144        7147   \n",
       "\n",
       "                                                  text75   0   1   2   3  \\\n",
       "76761  onciled patient past medical history cholecyst... NaN NaN NaN NaN   \n",
       "76762  lab comp metabolic panel lab glycosolated hemo... NaN NaN NaN NaN   \n",
       "76763  increat random colon cancer screening notes de... NaN NaN NaN NaN   \n",
       "76764  declined gi referral vitamin deficiency lab vi... NaN NaN NaN NaN   \n",
       "76765  breast cancer screening imaging mammo digital ... NaN NaN NaN NaN   \n",
       "\n",
       "            ...        19  20  21  22  23  24  25  26  27  all_model_pred  \n",
       "76761       ...       NaN NaN NaN   0   0   0   0   0   0               1  \n",
       "76762       ...       NaN NaN NaN   0   0   0   0   0   0               1  \n",
       "76763       ...       NaN NaN NaN   0   0   0   0   0   1               1  \n",
       "76764       ...       NaN NaN NaN   0   0   0   0   0   0               0  \n",
       "76765       ...       NaN NaN NaN   0   0   1   1   0   1               1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.tail()\n",
    "#all_model_pred is check any model output is 1 for that instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chart_id          IBXRMA2018_MULT_1163518440010001_HMK_188344641...\n",
       "code                                                            I10\n",
       "text                                                            i10\n",
       "start_offset                                                   1241\n",
       "end_offset                                                     1244\n",
       "text75            clerotic heart disease native coronary artery ...\n",
       "0                                                               NaN\n",
       "1                                                               NaN\n",
       "2                                                               NaN\n",
       "3                                                               NaN\n",
       "4                                                               NaN\n",
       "5                                                               NaN\n",
       "6                                                               NaN\n",
       "7                                                               NaN\n",
       "8                                                               NaN\n",
       "9                                                               NaN\n",
       "10                                                              NaN\n",
       "11                                                              NaN\n",
       "12                                                                0\n",
       "13                                                              NaN\n",
       "14                                                              NaN\n",
       "15                                                              NaN\n",
       "16                                                              NaN\n",
       "17                                                              NaN\n",
       "18                                                              NaN\n",
       "19                                                              NaN\n",
       "20                                                              NaN\n",
       "21                                                              NaN\n",
       "22                                                                0\n",
       "23                                                                0\n",
       "24                                                                0\n",
       "25                                                                0\n",
       "26                                                                0\n",
       "27                                                                0\n",
       "all_model_pred                                                    0\n",
       "Name: 135, dtype: object"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.iloc[135]   # just check one instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      'chart_id',           'code',           'text',   'start_offset',\n",
       "           'end_offset',         'text75',                0,                1,\n",
       "                      2,                3,                4,                5,\n",
       "                      6,                7,                8,                9,\n",
       "                     10,               11,               12,               13,\n",
       "                     14,               15,               16,               17,\n",
       "                     18,               19,               20,               21,\n",
       "                     22,               23,               24,               25,\n",
       "                     26,               27, 'all_model_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    'chart_id',         'code',         'text', 'start_offset',\n",
       "         'end_offset',       'text75',              0,              1,\n",
       "                    2,              3,              4,              5,\n",
       "                    6,              7,              8,              9,\n",
       "                   10,             11,             12,             13,\n",
       "                   14,             15,             16,             17,\n",
       "                   18,             19,             20,             21,\n",
       "                   22,             23,             24,             25,\n",
       "                   26,             27],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../picklefolder_ngrams/refreshed_models/Phrase_stroke_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_emphysema_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_hypertension_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_dementia_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cad_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_aneurysm_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_COPD_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Heart_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Kidney_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model1_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Cholesterol_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model2_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Code_Model3_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_asthma_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_cancer_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_ckd_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_depression_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/Phrase_diabetes_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_family_history_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_negation_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_doctors_note_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_not_relevant_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_phoneORaddressORother_number_LRApril0219.pickle',\n",
       " '../../picklefolder_ngrams/refreshed_models/DeletionReason_preventative_screening_LRApril0219.pickle']"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if running refreshed model, use this rename\n",
    "# rename the columns names, has to be consistent with the above order\n",
    "# since there's no 0, or 1, 17, these models didn't run because no data for them\n",
    "\n",
    "col_dict = {0: 'Phrase_stroke', 1: 'Phrase_emphysema',2:'Phrase_hypertension',3:'Phrase_dementia',4:'Phrase_cholesterol',\n",
    "           5:'Phrase_cad',6:'Phrase_aneurysm',7:'Code_COPD',8:'Code_Depression',9:'Code_Diabetes',10:'Code_Heart',\n",
    "           11:'Code_Kidney',12:'Code_Model1',13:'Code_Cancer',14:'Code_Cholesterol',15:'Code_Model2',\n",
    "           16:'Code_Model3',17:'Phrase_asthma',18:'Phrase_cancer',19:'Phrase_ckd',20:'Phrase_depression',21:'Phrase_diabetes',\n",
    "            22:'DeletionReason_family_history',23:'DeletionReason_negation',24:'DeletionReason_not_doctors_note',\n",
    "           25:'DeletionReason_not_relevant',26:'DeletionReason_phoneORaddressORother_number',27:'DeletionReason_preventative_screening',\n",
    "           }   ## keyold name, valuenew name\n",
    "\n",
    "df_pred.columns = [col_dict.get(x, x) for x in df_pred.columns]\n",
    "df_prob.columns = [col_dict.get(x, x) for x in df_prob.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# if running pipeline models, use this rename\\n# rename the columns names, has to be consistent with the above order  \\n# since there's no 0, or 1, 17, these models didn't run because no data for them\\n ## keyold name, valuenew name\\ncol_dict = {0:'Code_Cholesterol' , 1: 'DeletionReason_family_history',2:'DeletionReason_negation',3:'DeletionReason_not_doctors_note',4:'Code_Model2',\\n           5:'DeletionReason_not_relevant',6:'Phrase_stroke',7:'Phrase_hypertension',8:'Phrase_emphysema',9:'Phrase_diabetes',10:'Phrase_depression',\\n           11:'Phrase_dementia',12:'Phrase_ckd',13:'Phrase_cholesterol',14:'Phrase_cancer',15:'Phrase_cad',\\n           16:'Phrase_asthma',17:'Phrase_aneurysm',18:'DeletionReason_preventative_screening',19:'DeletionReason_phoneORaddressORother_number',20:'Code_Model3',21:'Code_Model1',\\n            22:'Code_Kidney',23:'Code_Heart',24:'Code_Diabetes',\\n           25:'Code_Depression',26:'Code_COPD',27:'Code_Cancer',\\n           }  \\n\\ndf_pred.columns = [col_dict.get(x, x) for x in df_pred.columns]\\ndf_prob.columns = [col_dict.get(x, x) for x in df_prob.columns]\\n\""
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# if running pipeline models, use this rename\n",
    "# rename the columns names, has to be consistent with the above order  \n",
    "# since there's no 0, or 1, 17, these models didn't run because no data for them\n",
    " ## keyold name, valuenew name\n",
    "col_dict = {0:'Code_Cholesterol' , 1: 'DeletionReason_family_history',2:'DeletionReason_negation',3:'DeletionReason_not_doctors_note',4:'Code_Model2',\n",
    "           5:'DeletionReason_not_relevant',6:'Phrase_stroke',7:'Phrase_hypertension',8:'Phrase_emphysema',9:'Phrase_diabetes',10:'Phrase_depression',\n",
    "           11:'Phrase_dementia',12:'Phrase_ckd',13:'Phrase_cholesterol',14:'Phrase_cancer',15:'Phrase_cad',\n",
    "           16:'Phrase_asthma',17:'Phrase_aneurysm',18:'DeletionReason_preventative_screening',19:'DeletionReason_phoneORaddressORother_number',20:'Code_Model3',21:'Code_Model1',\n",
    "            22:'Code_Kidney',23:'Code_Heart',24:'Code_Diabetes',\n",
    "           25:'Code_Depression',26:'Code_COPD',27:'Code_Cancer',\n",
    "           }  \n",
    "\n",
    "df_pred.columns = [col_dict.get(x, x) for x in df_pred.columns]\n",
    "df_prob.columns = [col_dict.get(x, x) for x in df_prob.columns]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chart_id', 'code', 'text', 'start_offset', 'end_offset', 'text75',\n",
       "       'Phrase_stroke', 'Phrase_emphysema', 'Phrase_hypertension',\n",
       "       'Phrase_dementia', 'Phrase_cholesterol', 'Phrase_cad',\n",
       "       'Phrase_aneurysm', 'Code_COPD', 'Code_Depression', 'Code_Diabetes',\n",
       "       'Code_Heart', 'Code_Kidney', 'Code_Model1', 'Code_Cancer',\n",
       "       'Code_Cholesterol', 'Code_Model2', 'Code_Model3', 'Phrase_asthma',\n",
       "       'Phrase_cancer', 'Phrase_ckd', 'Phrase_depression', 'Phrase_diabetes',\n",
       "       'DeletionReason_family_history', 'DeletionReason_negation',\n",
       "       'DeletionReason_not_doctors_note', 'DeletionReason_not_relevant',\n",
       "       'DeletionReason_phoneORaddressORother_number',\n",
       "       'DeletionReason_preventative_screening', 'all_model_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chart_id', 'code', 'text', 'start_offset', 'end_offset', 'text75',\n",
       "       'Phrase_stroke', 'Phrase_emphysema', 'Phrase_hypertension',\n",
       "       'Phrase_dementia', 'Phrase_cholesterol', 'Phrase_cad',\n",
       "       'Phrase_aneurysm', 'Code_COPD', 'Code_Depression', 'Code_Diabetes',\n",
       "       'Code_Heart', 'Code_Kidney', 'Code_Model1', 'Code_Cancer',\n",
       "       'Code_Cholesterol', 'Code_Model2', 'Code_Model3', 'Phrase_asthma',\n",
       "       'Phrase_cancer', 'Phrase_ckd', 'Phrase_depression', 'Phrase_diabetes',\n",
       "       'DeletionReason_family_history', 'DeletionReason_negation',\n",
       "       'DeletionReason_not_doctors_note', 'DeletionReason_not_relevant',\n",
       "       'DeletionReason_phoneORaddressORother_number',\n",
       "       'DeletionReason_preventative_screening'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred.rename(columns={'start': 'start_offset', 'end': 'end_offset'}, inplace=True)\n",
    "#df_pred[['chart_id','start_offset','end_offset','DeletionReason_family_history']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prob.rename(columns={'start': 'start_offset', 'end': 'end_offset'}, inplace=True)\n",
    "#df_prob[['chart_id','start_offset','end_offset','DeletionReason_family_history']].tail()  #ok make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred.to_csv('run1000charts_pred_0521.csv')   #  with prediction for each model and all model combined\n",
    "#df_prob.to_csv('probdataforcompwithAM_0506.csv')   #  with probability for each model\n",
    "# finally corrected a lot of errors like index not reset issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n",
      "980\n"
     ]
    }
   ],
   "source": [
    "print(len(set(df_pred['chart_id'].tolist())))\n",
    "print(len(set(df_prob['chart_id'].tolist())))   # 813 unique chart ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 3. Load in coder feedback and  evaluate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select common chart_ids from both 1000 model run and 6000 coder annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chart_id', 'code', 'text', 'start_offset', 'end_offset', 'text75',\n",
       "       'Phrase_stroke', 'Phrase_emphysema', 'Phrase_hypertension',\n",
       "       'Phrase_dementia', 'Phrase_cholesterol', 'Phrase_cad',\n",
       "       'Phrase_aneurysm', 'Code_COPD', 'Code_Depression', 'Code_Diabetes',\n",
       "       'Code_Heart', 'Code_Kidney', 'Code_Model1', 'Code_Cancer',\n",
       "       'Code_Cholesterol', 'Code_Model2', 'Code_Model3', 'Phrase_asthma',\n",
       "       'Phrase_cancer', 'Phrase_ckd', 'Phrase_depression', 'Phrase_diabetes',\n",
       "       'DeletionReason_family_history', 'DeletionReason_negation',\n",
       "       'DeletionReason_not_doctors_note', 'DeletionReason_not_relevant',\n",
       "       'DeletionReason_phoneORaddressORother_number',\n",
       "       'DeletionReason_preventative_screening', 'all_model_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pipeline model name list\n",
    "'''\n",
    "model_list=['Code_Cholesterol', 'DeletionReason_family_history',\n",
    "       'DeletionReason_negation', 'DeletionReason_not_doctors_note',\n",
    "       'Code_Model2', 'DeletionReason_not_relevant', 'Phrase_stroke',\n",
    "       'Phrase_hypertension', 'Phrase_emphysema', 'Phrase_diabetes',\n",
    "       'Phrase_depression', 'Phrase_dementia', 'Phrase_ckd',\n",
    "       'Phrase_cholesterol', 'Phrase_cancer', 'Phrase_cad', 'Phrase_asthma',\n",
    "       'Phrase_aneurysm', 'DeletionReason_preventative_screening',\n",
    "       'DeletionReason_phoneORaddressORother_number', 'Code_Model3',\n",
    "       'Code_Model1', 'Code_Kidney', 'Code_Heart', 'Code_Diabetes',\n",
    "       'Code_Depression', 'Code_COPD', 'Code_Cancer']\n",
    "'''\n",
    "# for refreshed model \n",
    "model_list=['Phrase_stroke', 'Phrase_emphysema', 'Phrase_hypertension',\n",
    "       'Phrase_dementia', 'Phrase_cholesterol', 'Phrase_cad',\n",
    "       'Phrase_aneurysm', 'Code_COPD', 'Code_Depression', 'Code_Diabetes',\n",
    "       'Code_Heart', 'Code_Kidney', 'Code_Model1', 'Code_Cancer',\n",
    "       'Code_Cholesterol', 'Code_Model2', 'Code_Model3', 'Phrase_asthma',\n",
    "       'Phrase_cancer', 'Phrase_ckd', 'Phrase_depression', 'Phrase_diabetes',\n",
    "       'DeletionReason_family_history', 'DeletionReason_negation',\n",
    "       'DeletionReason_not_doctors_note', 'DeletionReason_not_relevant',\n",
    "       'DeletionReason_phoneORaddressORother_number',\n",
    "       'DeletionReason_preventative_screening']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase_stroke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:177: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0\n",
      "TN: 139\n",
      "FN: 1\n",
      "FP: 0\n",
      "Phrase_emphysema\n",
      "TP: 40\n",
      "TN: 63\n",
      "FN: 13\n",
      "FP: 39\n",
      "Phrase_hypertension\n",
      "TP: 3556\n",
      "TN: 609\n",
      "FN: 27\n",
      "FP: 1734\n",
      "Phrase_dementia\n",
      "TP: 123\n",
      "TN: 150\n",
      "FN: 14\n",
      "FP: 91\n",
      "Phrase_cholesterol\n",
      "TP: 372\n",
      "TN: 1671\n",
      "FN: 38\n",
      "FP: 387\n",
      "Phrase_cad\n",
      "TP: 224\n",
      "TN: 614\n",
      "FN: 52\n",
      "FP: 177\n",
      "Phrase_aneurysm\n",
      "TP: 83\n",
      "TN: 310\n",
      "FN: 33\n",
      "FP: 33\n",
      "Code_COPD\n",
      "TP: 896\n",
      "TN: 323\n",
      "FN: 67\n",
      "FP: 368\n",
      "Code_Depression\n",
      "TP: 90\n",
      "TN: 749\n",
      "FN: 19\n",
      "FP: 98\n",
      "Code_Diabetes\n",
      "TP: 1071\n",
      "TN: 3033\n",
      "FN: 313\n",
      "FP: 806\n",
      "Code_Heart\n",
      "TP: 740\n",
      "TN: 1173\n",
      "FN: 200\n",
      "FP: 394\n",
      "Code_Kidney\n",
      "TP: 328\n",
      "TN: 207\n",
      "FN: 143\n",
      "FP: 196\n",
      "Code_Model1\n",
      "TP: 5954\n",
      "TN: 3383\n",
      "FN: 368\n",
      "FP: 3114\n",
      "Code_Cancer\n",
      "TP: 48\n",
      "TN: 978\n",
      "FN: 32\n",
      "FP: 58\n",
      "Code_Cholesterol\n",
      "TP: 3457\n",
      "TN: 1667\n",
      "FN: 89\n",
      "FP: 1744\n",
      "Code_Model2\n",
      "TP: 4659\n",
      "TN: 2131\n",
      "FN: 257\n",
      "FP: 2044\n",
      "Code_Model3\n",
      "TP: 1383\n",
      "TN: 2511\n",
      "FN: 149\n",
      "FP: 633\n",
      "Phrase_asthma\n",
      "TP: 247\n",
      "TN: 160\n",
      "FN: 16\n",
      "FP: 212\n",
      "Phrase_cancer\n",
      "TP: 30\n",
      "TN: 1449\n",
      "FN: 47\n",
      "FP: 66\n",
      "Phrase_ckd\n",
      "TP: 183\n",
      "TN: 57\n",
      "FN: 7\n",
      "FP: 160\n",
      "Phrase_depression\n",
      "TP: 143\n",
      "TN: 918\n",
      "FN: 46\n",
      "FP: 129\n",
      "Phrase_diabetes\n",
      "TP: 1374\n",
      "TN: 1583\n",
      "FN: 162\n",
      "FP: 840\n",
      "DeletionReason_family_history\n",
      "TP: 24638\n",
      "TN: 2728\n",
      "FN: 32\n",
      "FP: 32729\n",
      "DeletionReason_negation\n",
      "TP: 24550\n",
      "TN: 6137\n",
      "FN: 119\n",
      "FP: 29329\n",
      "DeletionReason_not_doctors_note\n",
      "TP: 24436\n",
      "TN: 8152\n",
      "FN: 229\n",
      "FP: 27332\n",
      "DeletionReason_not_relevant\n",
      "TP: 23901\n",
      "TN: 15310\n",
      "FN: 729\n",
      "FP: 20214\n",
      "DeletionReason_phoneORaddressORother_number\n",
      "TP: 24672\n",
      "TN: 2104\n",
      "FN: 10\n",
      "FP: 33352\n",
      "DeletionReason_preventative_screening\n",
      "TP: 24559\n",
      "TN: 3531\n",
      "FN: 108\n",
      "FP: 31927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "analysis_result_df=pd.DataFrame(columns=['model','TP','TN','FN','FP','precision','recall','accuracy'])\n",
    "\n",
    "for model_name in model_list:\n",
    "    df_pred['all_model_pred']=df_pred[model_name]\n",
    "    print(model_name)\n",
    "    TP,TN,FN,FP,precision,recall,accuracy = run_model_analysis(df_pred)\n",
    "    analysis_result_df=analysis_result_df.append({'model':model_name,'TP':TP, 'TN':TN,'FN':FN,'FP':FP,'precision':precision,'recall':recall,'accuracy':accuracy},ignore_index = True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phrase_stroke</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phrase_emphysema</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.664516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phrase_hypertension</td>\n",
       "      <td>3556</td>\n",
       "      <td>609</td>\n",
       "      <td>27</td>\n",
       "      <td>1734</td>\n",
       "      <td>0.672212</td>\n",
       "      <td>0.992464</td>\n",
       "      <td>0.702835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phrase_dementia</td>\n",
       "      <td>123</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>91</td>\n",
       "      <td>0.574766</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phrase_cholesterol</td>\n",
       "      <td>372</td>\n",
       "      <td>1671</td>\n",
       "      <td>38</td>\n",
       "      <td>387</td>\n",
       "      <td>0.490119</td>\n",
       "      <td>0.907317</td>\n",
       "      <td>0.827796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phrase_cad</td>\n",
       "      <td>224</td>\n",
       "      <td>614</td>\n",
       "      <td>52</td>\n",
       "      <td>177</td>\n",
       "      <td>0.558603</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.785380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phrase_aneurysm</td>\n",
       "      <td>83</td>\n",
       "      <td>310</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.856209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Code_COPD</td>\n",
       "      <td>896</td>\n",
       "      <td>323</td>\n",
       "      <td>67</td>\n",
       "      <td>368</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.930426</td>\n",
       "      <td>0.737001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Code_Depression</td>\n",
       "      <td>90</td>\n",
       "      <td>749</td>\n",
       "      <td>19</td>\n",
       "      <td>98</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.877615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Code_Diabetes</td>\n",
       "      <td>1071</td>\n",
       "      <td>3033</td>\n",
       "      <td>313</td>\n",
       "      <td>806</td>\n",
       "      <td>0.570591</td>\n",
       "      <td>0.773844</td>\n",
       "      <td>0.785755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Code_Heart</td>\n",
       "      <td>740</td>\n",
       "      <td>1173</td>\n",
       "      <td>200</td>\n",
       "      <td>394</td>\n",
       "      <td>0.652557</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.763063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Code_Kidney</td>\n",
       "      <td>328</td>\n",
       "      <td>207</td>\n",
       "      <td>143</td>\n",
       "      <td>196</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>0.696391</td>\n",
       "      <td>0.612128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Code_Model1</td>\n",
       "      <td>5954</td>\n",
       "      <td>3383</td>\n",
       "      <td>368</td>\n",
       "      <td>3114</td>\n",
       "      <td>0.656595</td>\n",
       "      <td>0.941791</td>\n",
       "      <td>0.728372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Code_Cancer</td>\n",
       "      <td>48</td>\n",
       "      <td>978</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.919355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Code_Cholesterol</td>\n",
       "      <td>3457</td>\n",
       "      <td>1667</td>\n",
       "      <td>89</td>\n",
       "      <td>1744</td>\n",
       "      <td>0.664680</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.736524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Code_Model2</td>\n",
       "      <td>4659</td>\n",
       "      <td>2131</td>\n",
       "      <td>257</td>\n",
       "      <td>2044</td>\n",
       "      <td>0.695062</td>\n",
       "      <td>0.947722</td>\n",
       "      <td>0.746893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Code_Model3</td>\n",
       "      <td>1383</td>\n",
       "      <td>2511</td>\n",
       "      <td>149</td>\n",
       "      <td>633</td>\n",
       "      <td>0.686012</td>\n",
       "      <td>0.902742</td>\n",
       "      <td>0.832763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Phrase_asthma</td>\n",
       "      <td>247</td>\n",
       "      <td>160</td>\n",
       "      <td>16</td>\n",
       "      <td>212</td>\n",
       "      <td>0.538126</td>\n",
       "      <td>0.939163</td>\n",
       "      <td>0.640945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Phrase_cancer</td>\n",
       "      <td>30</td>\n",
       "      <td>1449</td>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.929020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Phrase_ckd</td>\n",
       "      <td>183</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>160</td>\n",
       "      <td>0.533528</td>\n",
       "      <td>0.963158</td>\n",
       "      <td>0.589681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Phrase_depression</td>\n",
       "      <td>143</td>\n",
       "      <td>918</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.756614</td>\n",
       "      <td>0.858414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Phrase_diabetes</td>\n",
       "      <td>1374</td>\n",
       "      <td>1583</td>\n",
       "      <td>162</td>\n",
       "      <td>840</td>\n",
       "      <td>0.620596</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.746906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DeletionReason_family_history</td>\n",
       "      <td>24638</td>\n",
       "      <td>2728</td>\n",
       "      <td>32</td>\n",
       "      <td>32729</td>\n",
       "      <td>0.429480</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.455137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DeletionReason_negation</td>\n",
       "      <td>24550</td>\n",
       "      <td>6137</td>\n",
       "      <td>119</td>\n",
       "      <td>29329</td>\n",
       "      <td>0.455651</td>\n",
       "      <td>0.995176</td>\n",
       "      <td>0.510302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DeletionReason_not_doctors_note</td>\n",
       "      <td>24436</td>\n",
       "      <td>8152</td>\n",
       "      <td>229</td>\n",
       "      <td>27332</td>\n",
       "      <td>0.472029</td>\n",
       "      <td>0.990716</td>\n",
       "      <td>0.541788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DeletionReason_not_relevant</td>\n",
       "      <td>23901</td>\n",
       "      <td>15310</td>\n",
       "      <td>729</td>\n",
       "      <td>20214</td>\n",
       "      <td>0.541789</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>0.651844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DeletionReason_phoneORaddressORother_number</td>\n",
       "      <td>24672</td>\n",
       "      <td>2104</td>\n",
       "      <td>10</td>\n",
       "      <td>33352</td>\n",
       "      <td>0.425203</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>0.445243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DeletionReason_preventative_screening</td>\n",
       "      <td>24559</td>\n",
       "      <td>3531</td>\n",
       "      <td>108</td>\n",
       "      <td>31927</td>\n",
       "      <td>0.434780</td>\n",
       "      <td>0.995622</td>\n",
       "      <td>0.467193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model     TP     TN   FN     FP  \\\n",
       "0                                 Phrase_stroke      0    139    1      0   \n",
       "1                              Phrase_emphysema     40     63   13     39   \n",
       "2                           Phrase_hypertension   3556    609   27   1734   \n",
       "3                               Phrase_dementia    123    150   14     91   \n",
       "4                            Phrase_cholesterol    372   1671   38    387   \n",
       "5                                    Phrase_cad    224    614   52    177   \n",
       "6                               Phrase_aneurysm     83    310   33     33   \n",
       "7                                     Code_COPD    896    323   67    368   \n",
       "8                               Code_Depression     90    749   19     98   \n",
       "9                                 Code_Diabetes   1071   3033  313    806   \n",
       "10                                   Code_Heart    740   1173  200    394   \n",
       "11                                  Code_Kidney    328    207  143    196   \n",
       "12                                  Code_Model1   5954   3383  368   3114   \n",
       "13                                  Code_Cancer     48    978   32     58   \n",
       "14                             Code_Cholesterol   3457   1667   89   1744   \n",
       "15                                  Code_Model2   4659   2131  257   2044   \n",
       "16                                  Code_Model3   1383   2511  149    633   \n",
       "17                                Phrase_asthma    247    160   16    212   \n",
       "18                                Phrase_cancer     30   1449   47     66   \n",
       "19                                   Phrase_ckd    183     57    7    160   \n",
       "20                            Phrase_depression    143    918   46    129   \n",
       "21                              Phrase_diabetes   1374   1583  162    840   \n",
       "22                DeletionReason_family_history  24638   2728   32  32729   \n",
       "23                      DeletionReason_negation  24550   6137  119  29329   \n",
       "24              DeletionReason_not_doctors_note  24436   8152  229  27332   \n",
       "25                  DeletionReason_not_relevant  23901  15310  729  20214   \n",
       "26  DeletionReason_phoneORaddressORother_number  24672   2104   10  33352   \n",
       "27        DeletionReason_preventative_screening  24559   3531  108  31927   \n",
       "\n",
       "    precision    recall  accuracy  \n",
       "0    0.922520  0.000000  0.992857  \n",
       "1    0.506329  0.754717  0.664516  \n",
       "2    0.672212  0.992464  0.702835  \n",
       "3    0.574766  0.897810  0.722222  \n",
       "4    0.490119  0.907317  0.827796  \n",
       "5    0.558603  0.811594  0.785380  \n",
       "6    0.715517  0.715517  0.856209  \n",
       "7    0.708861  0.930426  0.737001  \n",
       "8    0.478723  0.825688  0.877615  \n",
       "9    0.570591  0.773844  0.785755  \n",
       "10   0.652557  0.787234  0.763063  \n",
       "11   0.625954  0.696391  0.612128  \n",
       "12   0.656595  0.941791  0.728372  \n",
       "13   0.452830  0.600000  0.919355  \n",
       "14   0.664680  0.974901  0.736524  \n",
       "15   0.695062  0.947722  0.746893  \n",
       "16   0.686012  0.902742  0.832763  \n",
       "17   0.538126  0.939163  0.640945  \n",
       "18   0.312500  0.389610  0.929020  \n",
       "19   0.533528  0.963158  0.589681  \n",
       "20   0.525735  0.756614  0.858414  \n",
       "21   0.620596  0.894531  0.746906  \n",
       "22   0.429480  0.998703  0.455137  \n",
       "23   0.455651  0.995176  0.510302  \n",
       "24   0.472029  0.990716  0.541788  \n",
       "25   0.541789  0.970402  0.651844  \n",
       "26   0.425203  0.999595  0.445243  \n",
       "27   0.434780  0.995622  0.467193  "
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_result_df.to_csv('pipeline_model_1000chart_numbers0624.csv')\n",
    "#analysis_result_df.to_csv('refreshed_model_1000chart_numbers0624.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3302</td>\n",
       "      <td>1959</td>\n",
       "      <td>201</td>\n",
       "      <td>1458</td>\n",
       "      <td>0.693697</td>\n",
       "      <td>0.942621</td>\n",
       "      <td>0.760260</td>\n",
       "      <td>Code_Cholesterol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24419</td>\n",
       "      <td>5559</td>\n",
       "      <td>221</td>\n",
       "      <td>29921</td>\n",
       "      <td>0.449374</td>\n",
       "      <td>0.991031</td>\n",
       "      <td>0.498636</td>\n",
       "      <td>DeletionReason_family_history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24169</td>\n",
       "      <td>11222</td>\n",
       "      <td>479</td>\n",
       "      <td>24303</td>\n",
       "      <td>0.498618</td>\n",
       "      <td>0.980566</td>\n",
       "      <td>0.588154</td>\n",
       "      <td>DeletionReason_negation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23798</td>\n",
       "      <td>13275</td>\n",
       "      <td>801</td>\n",
       "      <td>22256</td>\n",
       "      <td>0.516741</td>\n",
       "      <td>0.967438</td>\n",
       "      <td>0.616547</td>\n",
       "      <td>DeletionReason_not_doctors_note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4612</td>\n",
       "      <td>2175</td>\n",
       "      <td>294</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.697203</td>\n",
       "      <td>0.940073</td>\n",
       "      <td>0.747138</td>\n",
       "      <td>Code_Model2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>22377</td>\n",
       "      <td>20602</td>\n",
       "      <td>2065</td>\n",
       "      <td>15078</td>\n",
       "      <td>0.597437</td>\n",
       "      <td>0.915514</td>\n",
       "      <td>0.714863</td>\n",
       "      <td>DeletionReason_not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>Phrase_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3469</td>\n",
       "      <td>821</td>\n",
       "      <td>93</td>\n",
       "      <td>1518</td>\n",
       "      <td>0.695609</td>\n",
       "      <td>0.973891</td>\n",
       "      <td>0.726995</td>\n",
       "      <td>Phrase_hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>Phrase_emphysema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1296</td>\n",
       "      <td>1694</td>\n",
       "      <td>241</td>\n",
       "      <td>727</td>\n",
       "      <td>0.640633</td>\n",
       "      <td>0.843201</td>\n",
       "      <td>0.755432</td>\n",
       "      <td>Phrase_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>912</td>\n",
       "      <td>40</td>\n",
       "      <td>137</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.857027</td>\n",
       "      <td>Phrase_depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "      <td>172</td>\n",
       "      <td>18</td>\n",
       "      <td>68</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>Phrase_dementia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>155</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.643243</td>\n",
       "      <td>0.683292</td>\n",
       "      <td>Phrase_ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>288</td>\n",
       "      <td>1841</td>\n",
       "      <td>109</td>\n",
       "      <td>216</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.867563</td>\n",
       "      <td>Phrase_cholesterol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>1274</td>\n",
       "      <td>21</td>\n",
       "      <td>243</td>\n",
       "      <td>0.179054</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.834067</td>\n",
       "      <td>Phrase_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>255</td>\n",
       "      <td>570</td>\n",
       "      <td>31</td>\n",
       "      <td>223</td>\n",
       "      <td>0.533473</td>\n",
       "      <td>0.891608</td>\n",
       "      <td>0.764597</td>\n",
       "      <td>Phrase_cad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>194</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>108</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>Phrase_asthma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>76</td>\n",
       "      <td>306</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.649573</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>Phrase_aneurysm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>24397</td>\n",
       "      <td>4552</td>\n",
       "      <td>237</td>\n",
       "      <td>30918</td>\n",
       "      <td>0.441056</td>\n",
       "      <td>0.990379</td>\n",
       "      <td>0.481648</td>\n",
       "      <td>DeletionReason_preventative_screening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>13675</td>\n",
       "      <td>32128</td>\n",
       "      <td>8958</td>\n",
       "      <td>4536</td>\n",
       "      <td>0.750920</td>\n",
       "      <td>0.604206</td>\n",
       "      <td>0.772434</td>\n",
       "      <td>DeletionReason_phoneORaddressORother_number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1221</td>\n",
       "      <td>2818</td>\n",
       "      <td>274</td>\n",
       "      <td>365</td>\n",
       "      <td>0.769861</td>\n",
       "      <td>0.816722</td>\n",
       "      <td>0.863403</td>\n",
       "      <td>Code_Model3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5611</td>\n",
       "      <td>3862</td>\n",
       "      <td>667</td>\n",
       "      <td>2646</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>0.893756</td>\n",
       "      <td>0.740888</td>\n",
       "      <td>Code_Model1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>196</td>\n",
       "      <td>334</td>\n",
       "      <td>271</td>\n",
       "      <td>73</td>\n",
       "      <td>0.728625</td>\n",
       "      <td>0.419700</td>\n",
       "      <td>0.606407</td>\n",
       "      <td>Code_Kidney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>466</td>\n",
       "      <td>1408</td>\n",
       "      <td>429</td>\n",
       "      <td>178</td>\n",
       "      <td>0.723602</td>\n",
       "      <td>0.520670</td>\n",
       "      <td>0.755341</td>\n",
       "      <td>Code_Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>874</td>\n",
       "      <td>3269</td>\n",
       "      <td>491</td>\n",
       "      <td>573</td>\n",
       "      <td>0.604008</td>\n",
       "      <td>0.640293</td>\n",
       "      <td>0.795660</td>\n",
       "      <td>Code_Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>85</td>\n",
       "      <td>812</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.940252</td>\n",
       "      <td>Code_Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>855</td>\n",
       "      <td>399</td>\n",
       "      <td>100</td>\n",
       "      <td>301</td>\n",
       "      <td>0.739619</td>\n",
       "      <td>0.895288</td>\n",
       "      <td>0.757704</td>\n",
       "      <td>Code_COPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>1006</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.916071</td>\n",
       "      <td>Code_Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     TP     TN    FN     FP  precision    recall  accuracy  \\\n",
       "0            0   3302   1959   201   1458   0.693697  0.942621  0.760260   \n",
       "1            1  24419   5559   221  29921   0.449374  0.991031  0.498636   \n",
       "2            2  24169  11222   479  24303   0.498618  0.980566  0.588154   \n",
       "3            3  23798  13275   801  22256   0.516741  0.967438  0.616547   \n",
       "4            4   4612   2175   294   2003   0.697203  0.940073  0.747138   \n",
       "5            5  22377  20602  2065  15078   0.597437  0.915514  0.714863   \n",
       "6            6      0    124     1     15   0.000000  0.000000  0.885714   \n",
       "7            7   3469    821    93   1518   0.695609  0.973891  0.726995   \n",
       "8            8     46     72     8     32   0.589744  0.851852  0.746835   \n",
       "9            9   1296   1694   241    727   0.640633  0.843201  0.755432   \n",
       "10          10    149    912    40    137   0.520979  0.788360  0.857027   \n",
       "11          11    118    172    18     68   0.634409  0.867647  0.771277   \n",
       "12          12    119    155    66     61   0.661111  0.643243  0.683292   \n",
       "13          13    288   1841   109    216   0.571429  0.725441  0.867563   \n",
       "14          14     53   1274    21    243   0.179054  0.716216  0.834067   \n",
       "15          15    255    570    31    223   0.533473  0.891608  0.764597   \n",
       "16          16    194    270    60    108   0.642384  0.763780  0.734177   \n",
       "17          17     76    306    41     37   0.672566  0.649573  0.830435   \n",
       "18          18  24397   4552   237  30918   0.441056  0.990379  0.481648   \n",
       "19          19  13675  32128  8958   4536   0.750920  0.604206  0.772434   \n",
       "20          20   1221   2818   274    365   0.769861  0.816722  0.863403   \n",
       "21          21   5611   3862   667   2646   0.679545  0.893756  0.740888   \n",
       "22          22    196    334   271     73   0.728625  0.419700  0.606407   \n",
       "23          23    466   1408   429    178   0.723602  0.520670  0.755341   \n",
       "24          24    874   3269   491    573   0.604008  0.640293  0.795660   \n",
       "25          25     85    812    22     35   0.708333  0.794393  0.940252   \n",
       "26          26    855    399   100    301   0.739619  0.895288  0.757704   \n",
       "27          27     20   1006    60     34   0.370370  0.250000  0.916071   \n",
       "\n",
       "                                          model  \n",
       "0                              Code_Cholesterol  \n",
       "1                 DeletionReason_family_history  \n",
       "2                       DeletionReason_negation  \n",
       "3               DeletionReason_not_doctors_note  \n",
       "4                                   Code_Model2  \n",
       "5                   DeletionReason_not_relevant  \n",
       "6                                 Phrase_stroke  \n",
       "7                           Phrase_hypertension  \n",
       "8                              Phrase_emphysema  \n",
       "9                               Phrase_diabetes  \n",
       "10                            Phrase_depression  \n",
       "11                              Phrase_dementia  \n",
       "12                                   Phrase_ckd  \n",
       "13                           Phrase_cholesterol  \n",
       "14                                Phrase_cancer  \n",
       "15                                   Phrase_cad  \n",
       "16                                Phrase_asthma  \n",
       "17                              Phrase_aneurysm  \n",
       "18        DeletionReason_preventative_screening  \n",
       "19  DeletionReason_phoneORaddressORother_number  \n",
       "20                                  Code_Model3  \n",
       "21                                  Code_Model1  \n",
       "22                                  Code_Kidney  \n",
       "23                                   Code_Heart  \n",
       "24                                Code_Diabetes  \n",
       "25                              Code_Depression  \n",
       "26                                    Code_COPD  \n",
       "27                                  Code_Cancer  "
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_df=pd.read_csv('pipeline_model_1000chart_numbers0624.csv')\n",
    "pipeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Phrase_stroke', 'Phrase_emphysema', 'Phrase_hypertension',\n",
       "       'Phrase_dementia', 'Phrase_cholesterol', 'Phrase_cad',\n",
       "       'Phrase_aneurysm', 'Code_COPD', 'Code_Depression', 'Code_Diabetes',\n",
       "       'Code_Heart', 'Code_Kidney', 'Code_Model1', 'Code_Cancer',\n",
       "       'Code_Cholesterol', 'Code_Model2', 'Code_Model3', 'Phrase_asthma',\n",
       "       'Phrase_cancer', 'Phrase_ckd', 'Phrase_depression',\n",
       "       'Phrase_diabetes', 'DeletionReason_family_history',\n",
       "       'DeletionReason_negation', 'DeletionReason_not_doctors_note',\n",
       "       'DeletionReason_not_relevant',\n",
       "       'DeletionReason_phoneORaddressORother_number',\n",
       "       'DeletionReason_preventative_screening'], dtype=object)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_result_df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TP_x</th>\n",
       "      <th>TN_x</th>\n",
       "      <th>FN_x</th>\n",
       "      <th>FP_x</th>\n",
       "      <th>precision_x</th>\n",
       "      <th>recall_x</th>\n",
       "      <th>accuracy_x</th>\n",
       "      <th>model</th>\n",
       "      <th>TP_y</th>\n",
       "      <th>TN_y</th>\n",
       "      <th>FN_y</th>\n",
       "      <th>FP_y</th>\n",
       "      <th>precision_y</th>\n",
       "      <th>recall_y</th>\n",
       "      <th>accuracy_y</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3302</td>\n",
       "      <td>1959</td>\n",
       "      <td>201</td>\n",
       "      <td>1458</td>\n",
       "      <td>0.693697</td>\n",
       "      <td>0.942621</td>\n",
       "      <td>0.760260</td>\n",
       "      <td>Code_Cholesterol</td>\n",
       "      <td>3457</td>\n",
       "      <td>1667</td>\n",
       "      <td>89</td>\n",
       "      <td>1744</td>\n",
       "      <td>0.664680</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.736524</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24419</td>\n",
       "      <td>5559</td>\n",
       "      <td>221</td>\n",
       "      <td>29921</td>\n",
       "      <td>0.449374</td>\n",
       "      <td>0.991031</td>\n",
       "      <td>0.498636</td>\n",
       "      <td>DeletionReason_family_history</td>\n",
       "      <td>24638</td>\n",
       "      <td>2728</td>\n",
       "      <td>32</td>\n",
       "      <td>32729</td>\n",
       "      <td>0.429480</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.455137</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24169</td>\n",
       "      <td>11222</td>\n",
       "      <td>479</td>\n",
       "      <td>24303</td>\n",
       "      <td>0.498618</td>\n",
       "      <td>0.980566</td>\n",
       "      <td>0.588154</td>\n",
       "      <td>DeletionReason_negation</td>\n",
       "      <td>24550</td>\n",
       "      <td>6137</td>\n",
       "      <td>119</td>\n",
       "      <td>29329</td>\n",
       "      <td>0.455651</td>\n",
       "      <td>0.995176</td>\n",
       "      <td>0.510302</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23798</td>\n",
       "      <td>13275</td>\n",
       "      <td>801</td>\n",
       "      <td>22256</td>\n",
       "      <td>0.516741</td>\n",
       "      <td>0.967438</td>\n",
       "      <td>0.616547</td>\n",
       "      <td>DeletionReason_not_doctors_note</td>\n",
       "      <td>24436</td>\n",
       "      <td>8152</td>\n",
       "      <td>229</td>\n",
       "      <td>27332</td>\n",
       "      <td>0.472029</td>\n",
       "      <td>0.990716</td>\n",
       "      <td>0.541788</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4612</td>\n",
       "      <td>2175</td>\n",
       "      <td>294</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.697203</td>\n",
       "      <td>0.940073</td>\n",
       "      <td>0.747138</td>\n",
       "      <td>Code_Model2</td>\n",
       "      <td>4659</td>\n",
       "      <td>2131</td>\n",
       "      <td>257</td>\n",
       "      <td>2044</td>\n",
       "      <td>0.695062</td>\n",
       "      <td>0.947722</td>\n",
       "      <td>0.746893</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>22377</td>\n",
       "      <td>20602</td>\n",
       "      <td>2065</td>\n",
       "      <td>15078</td>\n",
       "      <td>0.597437</td>\n",
       "      <td>0.915514</td>\n",
       "      <td>0.714863</td>\n",
       "      <td>DeletionReason_not_relevant</td>\n",
       "      <td>23901</td>\n",
       "      <td>15310</td>\n",
       "      <td>729</td>\n",
       "      <td>20214</td>\n",
       "      <td>0.541789</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>0.651844</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>Phrase_stroke</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3469</td>\n",
       "      <td>821</td>\n",
       "      <td>93</td>\n",
       "      <td>1518</td>\n",
       "      <td>0.695609</td>\n",
       "      <td>0.973891</td>\n",
       "      <td>0.726995</td>\n",
       "      <td>Phrase_hypertension</td>\n",
       "      <td>3556</td>\n",
       "      <td>609</td>\n",
       "      <td>27</td>\n",
       "      <td>1734</td>\n",
       "      <td>0.672212</td>\n",
       "      <td>0.992464</td>\n",
       "      <td>0.702835</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>Phrase_emphysema</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1296</td>\n",
       "      <td>1694</td>\n",
       "      <td>241</td>\n",
       "      <td>727</td>\n",
       "      <td>0.640633</td>\n",
       "      <td>0.843201</td>\n",
       "      <td>0.755432</td>\n",
       "      <td>Phrase_diabetes</td>\n",
       "      <td>1374</td>\n",
       "      <td>1583</td>\n",
       "      <td>162</td>\n",
       "      <td>840</td>\n",
       "      <td>0.620596</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.746906</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>912</td>\n",
       "      <td>40</td>\n",
       "      <td>137</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.857027</td>\n",
       "      <td>Phrase_depression</td>\n",
       "      <td>143</td>\n",
       "      <td>918</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.756614</td>\n",
       "      <td>0.858414</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "      <td>172</td>\n",
       "      <td>18</td>\n",
       "      <td>68</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>Phrase_dementia</td>\n",
       "      <td>123</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>91</td>\n",
       "      <td>0.574766</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>155</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.643243</td>\n",
       "      <td>0.683292</td>\n",
       "      <td>Phrase_ckd</td>\n",
       "      <td>183</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>160</td>\n",
       "      <td>0.533528</td>\n",
       "      <td>0.963158</td>\n",
       "      <td>0.589681</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>288</td>\n",
       "      <td>1841</td>\n",
       "      <td>109</td>\n",
       "      <td>216</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.867563</td>\n",
       "      <td>Phrase_cholesterol</td>\n",
       "      <td>372</td>\n",
       "      <td>1671</td>\n",
       "      <td>38</td>\n",
       "      <td>387</td>\n",
       "      <td>0.490119</td>\n",
       "      <td>0.907317</td>\n",
       "      <td>0.827796</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>1274</td>\n",
       "      <td>21</td>\n",
       "      <td>243</td>\n",
       "      <td>0.179054</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.834067</td>\n",
       "      <td>Phrase_cancer</td>\n",
       "      <td>30</td>\n",
       "      <td>1449</td>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.929020</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>255</td>\n",
       "      <td>570</td>\n",
       "      <td>31</td>\n",
       "      <td>223</td>\n",
       "      <td>0.533473</td>\n",
       "      <td>0.891608</td>\n",
       "      <td>0.764597</td>\n",
       "      <td>Phrase_cad</td>\n",
       "      <td>224</td>\n",
       "      <td>614</td>\n",
       "      <td>52</td>\n",
       "      <td>177</td>\n",
       "      <td>0.558603</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.785380</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>194</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>108</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>Phrase_asthma</td>\n",
       "      <td>247</td>\n",
       "      <td>160</td>\n",
       "      <td>16</td>\n",
       "      <td>212</td>\n",
       "      <td>0.538126</td>\n",
       "      <td>0.939163</td>\n",
       "      <td>0.640945</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>76</td>\n",
       "      <td>306</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.649573</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>Phrase_aneurysm</td>\n",
       "      <td>83</td>\n",
       "      <td>310</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.856209</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>24397</td>\n",
       "      <td>4552</td>\n",
       "      <td>237</td>\n",
       "      <td>30918</td>\n",
       "      <td>0.441056</td>\n",
       "      <td>0.990379</td>\n",
       "      <td>0.481648</td>\n",
       "      <td>DeletionReason_preventative_screening</td>\n",
       "      <td>24559</td>\n",
       "      <td>3531</td>\n",
       "      <td>108</td>\n",
       "      <td>31927</td>\n",
       "      <td>0.434780</td>\n",
       "      <td>0.995622</td>\n",
       "      <td>0.467193</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>13675</td>\n",
       "      <td>32128</td>\n",
       "      <td>8958</td>\n",
       "      <td>4536</td>\n",
       "      <td>0.750920</td>\n",
       "      <td>0.604206</td>\n",
       "      <td>0.772434</td>\n",
       "      <td>DeletionReason_phoneORaddressORother_number</td>\n",
       "      <td>24672</td>\n",
       "      <td>2104</td>\n",
       "      <td>10</td>\n",
       "      <td>33352</td>\n",
       "      <td>0.425203</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>0.445243</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1221</td>\n",
       "      <td>2818</td>\n",
       "      <td>274</td>\n",
       "      <td>365</td>\n",
       "      <td>0.769861</td>\n",
       "      <td>0.816722</td>\n",
       "      <td>0.863403</td>\n",
       "      <td>Code_Model3</td>\n",
       "      <td>1383</td>\n",
       "      <td>2511</td>\n",
       "      <td>149</td>\n",
       "      <td>633</td>\n",
       "      <td>0.686012</td>\n",
       "      <td>0.902742</td>\n",
       "      <td>0.832763</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5611</td>\n",
       "      <td>3862</td>\n",
       "      <td>667</td>\n",
       "      <td>2646</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>0.893756</td>\n",
       "      <td>0.740888</td>\n",
       "      <td>Code_Model1</td>\n",
       "      <td>5954</td>\n",
       "      <td>3383</td>\n",
       "      <td>368</td>\n",
       "      <td>3114</td>\n",
       "      <td>0.656595</td>\n",
       "      <td>0.941791</td>\n",
       "      <td>0.728372</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>196</td>\n",
       "      <td>334</td>\n",
       "      <td>271</td>\n",
       "      <td>73</td>\n",
       "      <td>0.728625</td>\n",
       "      <td>0.419700</td>\n",
       "      <td>0.606407</td>\n",
       "      <td>Code_Kidney</td>\n",
       "      <td>328</td>\n",
       "      <td>207</td>\n",
       "      <td>143</td>\n",
       "      <td>196</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>0.696391</td>\n",
       "      <td>0.612128</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>466</td>\n",
       "      <td>1408</td>\n",
       "      <td>429</td>\n",
       "      <td>178</td>\n",
       "      <td>0.723602</td>\n",
       "      <td>0.520670</td>\n",
       "      <td>0.755341</td>\n",
       "      <td>Code_Heart</td>\n",
       "      <td>740</td>\n",
       "      <td>1173</td>\n",
       "      <td>200</td>\n",
       "      <td>394</td>\n",
       "      <td>0.652557</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.763063</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>874</td>\n",
       "      <td>3269</td>\n",
       "      <td>491</td>\n",
       "      <td>573</td>\n",
       "      <td>0.604008</td>\n",
       "      <td>0.640293</td>\n",
       "      <td>0.795660</td>\n",
       "      <td>Code_Diabetes</td>\n",
       "      <td>1071</td>\n",
       "      <td>3033</td>\n",
       "      <td>313</td>\n",
       "      <td>806</td>\n",
       "      <td>0.570591</td>\n",
       "      <td>0.773844</td>\n",
       "      <td>0.785755</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>85</td>\n",
       "      <td>812</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.940252</td>\n",
       "      <td>Code_Depression</td>\n",
       "      <td>90</td>\n",
       "      <td>749</td>\n",
       "      <td>19</td>\n",
       "      <td>98</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.877615</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>855</td>\n",
       "      <td>399</td>\n",
       "      <td>100</td>\n",
       "      <td>301</td>\n",
       "      <td>0.739619</td>\n",
       "      <td>0.895288</td>\n",
       "      <td>0.757704</td>\n",
       "      <td>Code_COPD</td>\n",
       "      <td>896</td>\n",
       "      <td>323</td>\n",
       "      <td>67</td>\n",
       "      <td>368</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.930426</td>\n",
       "      <td>0.737001</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>1006</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.916071</td>\n",
       "      <td>Code_Cancer</td>\n",
       "      <td>48</td>\n",
       "      <td>978</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   TP_x   TN_x  FN_x   FP_x  precision_x  recall_x  accuracy_x  \\\n",
       "0            0   3302   1959   201   1458     0.693697  0.942621    0.760260   \n",
       "1            1  24419   5559   221  29921     0.449374  0.991031    0.498636   \n",
       "2            2  24169  11222   479  24303     0.498618  0.980566    0.588154   \n",
       "3            3  23798  13275   801  22256     0.516741  0.967438    0.616547   \n",
       "4            4   4612   2175   294   2003     0.697203  0.940073    0.747138   \n",
       "5            5  22377  20602  2065  15078     0.597437  0.915514    0.714863   \n",
       "6            6      0    124     1     15     0.000000  0.000000    0.885714   \n",
       "7            7   3469    821    93   1518     0.695609  0.973891    0.726995   \n",
       "8            8     46     72     8     32     0.589744  0.851852    0.746835   \n",
       "9            9   1296   1694   241    727     0.640633  0.843201    0.755432   \n",
       "10          10    149    912    40    137     0.520979  0.788360    0.857027   \n",
       "11          11    118    172    18     68     0.634409  0.867647    0.771277   \n",
       "12          12    119    155    66     61     0.661111  0.643243    0.683292   \n",
       "13          13    288   1841   109    216     0.571429  0.725441    0.867563   \n",
       "14          14     53   1274    21    243     0.179054  0.716216    0.834067   \n",
       "15          15    255    570    31    223     0.533473  0.891608    0.764597   \n",
       "16          16    194    270    60    108     0.642384  0.763780    0.734177   \n",
       "17          17     76    306    41     37     0.672566  0.649573    0.830435   \n",
       "18          18  24397   4552   237  30918     0.441056  0.990379    0.481648   \n",
       "19          19  13675  32128  8958   4536     0.750920  0.604206    0.772434   \n",
       "20          20   1221   2818   274    365     0.769861  0.816722    0.863403   \n",
       "21          21   5611   3862   667   2646     0.679545  0.893756    0.740888   \n",
       "22          22    196    334   271     73     0.728625  0.419700    0.606407   \n",
       "23          23    466   1408   429    178     0.723602  0.520670    0.755341   \n",
       "24          24    874   3269   491    573     0.604008  0.640293    0.795660   \n",
       "25          25     85    812    22     35     0.708333  0.794393    0.940252   \n",
       "26          26    855    399   100    301     0.739619  0.895288    0.757704   \n",
       "27          27     20   1006    60     34     0.370370  0.250000    0.916071   \n",
       "\n",
       "                                          model   TP_y   TN_y FN_y   FP_y  \\\n",
       "0                              Code_Cholesterol   3457   1667   89   1744   \n",
       "1                 DeletionReason_family_history  24638   2728   32  32729   \n",
       "2                       DeletionReason_negation  24550   6137  119  29329   \n",
       "3               DeletionReason_not_doctors_note  24436   8152  229  27332   \n",
       "4                                   Code_Model2   4659   2131  257   2044   \n",
       "5                   DeletionReason_not_relevant  23901  15310  729  20214   \n",
       "6                                 Phrase_stroke      0    139    1      0   \n",
       "7                           Phrase_hypertension   3556    609   27   1734   \n",
       "8                              Phrase_emphysema     40     63   13     39   \n",
       "9                               Phrase_diabetes   1374   1583  162    840   \n",
       "10                            Phrase_depression    143    918   46    129   \n",
       "11                              Phrase_dementia    123    150   14     91   \n",
       "12                                   Phrase_ckd    183     57    7    160   \n",
       "13                           Phrase_cholesterol    372   1671   38    387   \n",
       "14                                Phrase_cancer     30   1449   47     66   \n",
       "15                                   Phrase_cad    224    614   52    177   \n",
       "16                                Phrase_asthma    247    160   16    212   \n",
       "17                              Phrase_aneurysm     83    310   33     33   \n",
       "18        DeletionReason_preventative_screening  24559   3531  108  31927   \n",
       "19  DeletionReason_phoneORaddressORother_number  24672   2104   10  33352   \n",
       "20                                  Code_Model3   1383   2511  149    633   \n",
       "21                                  Code_Model1   5954   3383  368   3114   \n",
       "22                                  Code_Kidney    328    207  143    196   \n",
       "23                                   Code_Heart    740   1173  200    394   \n",
       "24                                Code_Diabetes   1071   3033  313    806   \n",
       "25                              Code_Depression     90    749   19     98   \n",
       "26                                    Code_COPD    896    323   67    368   \n",
       "27                                  Code_Cancer     48    978   32     58   \n",
       "\n",
       "    precision_y  recall_y  accuracy_y _merge  \n",
       "0      0.664680  0.974901    0.736524   both  \n",
       "1      0.429480  0.998703    0.455137   both  \n",
       "2      0.455651  0.995176    0.510302   both  \n",
       "3      0.472029  0.990716    0.541788   both  \n",
       "4      0.695062  0.947722    0.746893   both  \n",
       "5      0.541789  0.970402    0.651844   both  \n",
       "6      0.922520  0.000000    0.992857   both  \n",
       "7      0.672212  0.992464    0.702835   both  \n",
       "8      0.506329  0.754717    0.664516   both  \n",
       "9      0.620596  0.894531    0.746906   both  \n",
       "10     0.525735  0.756614    0.858414   both  \n",
       "11     0.574766  0.897810    0.722222   both  \n",
       "12     0.533528  0.963158    0.589681   both  \n",
       "13     0.490119  0.907317    0.827796   both  \n",
       "14     0.312500  0.389610    0.929020   both  \n",
       "15     0.558603  0.811594    0.785380   both  \n",
       "16     0.538126  0.939163    0.640945   both  \n",
       "17     0.715517  0.715517    0.856209   both  \n",
       "18     0.434780  0.995622    0.467193   both  \n",
       "19     0.425203  0.999595    0.445243   both  \n",
       "20     0.686012  0.902742    0.832763   both  \n",
       "21     0.656595  0.941791    0.728372   both  \n",
       "22     0.625954  0.696391    0.612128   both  \n",
       "23     0.652557  0.787234    0.763063   both  \n",
       "24     0.570591  0.773844    0.785755   both  \n",
       "25     0.478723  0.825688    0.877615   both  \n",
       "26     0.708861  0.930426    0.737001   both  \n",
       "27     0.452830  0.600000    0.919355   both  "
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge these two\n",
    "new_df = pd.merge(pipeline_df, analysis_result_df,how = 'inner', on = ['model'], indicator = True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('pipeline_vs_refreshed_model_1000charts_numbers_0624.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_pred['all_model_pred']=df_pred['Phrase_stroke']\\n#model_name='Code_Cholesterol'\\n#df_pred['all_model_pred']=df_pred['DeletionReason_family_history']\\nTP,TN,FN,FP,precision,recall,accuracy = run_model_analysis(df_pred)\\nprint('TP:',TP)\\nprint('TN:',TN)\\nprint('FN:',FN)\\nprint('FP:',FP)\\nprint('precision:',precision)\\nprint('recall:',recall)\\nprint('accuracy:',accuracy)\\n\""
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "'''\n",
    "df_pred['all_model_pred']=df_pred['Phrase_stroke']\n",
    "#model_name='Code_Cholesterol'\n",
    "#df_pred['all_model_pred']=df_pred['DeletionReason_family_history']\n",
    "TP,TN,FN,FP,precision,recall,accuracy = run_model_analysis(df_pred)\n",
    "print('TP:',TP)\n",
    "print('TN:',TN)\n",
    "print('FN:',FN)\n",
    "print('FP:',FP)\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)\n",
    "print('accuracy:',accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model computation\n",
    "def run_model_analysis(df_pred):\n",
    "    df_pred1=df_pred[['chart_id', 'code', 'text', 'start_offset', 'end_offset', 'text75','all_model_pred']]\n",
    "    #print(len(df_pred1))\n",
    "    df_pred1 = df_pred1.drop_duplicates()\n",
    "    #print(len(df_pred1))\n",
    "    # read in all charts with coder feedback\n",
    "    df_codeall = pd.read_csv('/home/jovyan/work/Analytics_Data_training/conditions_with_chartids_29042019.csv') # 1000 charts\n",
    "    #df_codeall = pd.read_csv('/home/jovyan/work/Analytics_Data_training/conditions_output_withchart_id_100619.csv') #7500 chart\n",
    "    #print(len(df_codeall))\n",
    "    #print(\"unique chart is in 1000 charts run model output:\",df_pred1['chart_id'].nunique())\n",
    "    #print(\"unique chart is in 6000 charts with coder feedback:\",df_codeall['chart_id'].nunique())\n",
    "    # now find overlap chart ids\n",
    "    overlapped_charts = pd.merge(df_codeall[['chart_id']].drop_duplicates(),df_pred1[['chart_id']].drop_duplicates(), how = 'inner')\n",
    "    overlapped_charts = list(overlapped_charts['chart_id'].unique())\n",
    "    #print(len(overlapped_charts))  \n",
    "    # select the model output\n",
    "    fd_prod = df_pred1[['chart_id','code','start_offset','end_offset','text75','all_model_pred']][df_pred1['chart_id'].isin(overlapped_charts)].drop_duplicates()\n",
    "    #len(fd_prod)\n",
    "    # select the model output, if it's individual model, need to select those not NaN instances only\n",
    "    fd_prod.dropna(inplace=True)\n",
    "    #print(len(fd_prod))\n",
    "    #fd_prod.isnull().sum()\n",
    "\n",
    "    # select those in the code output\n",
    "    data = df_codeall[df_codeall['chart_id'].isin(overlapped_charts)]\n",
    "    #print(len(data))\n",
    "    #print(len(data[data['label'] == 'added']))\n",
    "    #print(len(data[data['label'] == 'deleted']))\n",
    "   # print(len(data[data['label'] == 'agreed']))\n",
    "\n",
    "    #The accurary number for the pipeline models\n",
    "    # Use fuzzy logic to compute the deleted, added, agreed\n",
    "    data = data[data['start'] != 0]\n",
    "    data = data[data['end'] != 0]\n",
    "    #data = data[data['created_at'] == date ] ##Change date to filter for datewise data\n",
    "    #label_counts = data.groupby(['label']).size().reset_index(name='counts')\n",
    "    instmatches = data[data['label'] == 'agreed']\n",
    "    instfuzzymatches = data[data['label'] == 'deleted']\n",
    "    instfuzzymatches = instfuzzymatches[instfuzzymatches['deleted_reason'].isin(['Incorrect Specification - Non-Risk Adjusted','repeated_instance','incorrect_year_of_service']) ]\n",
    "    instmatches = pd.concat([instmatches, instfuzzymatches])\n",
    "    instmatches = instmatches[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "    instdeleted = data[data['label'] == 'deleted']\n",
    "    instdeleted = instdeleted[instdeleted['deleted_reason'] != 'other']\n",
    "    instdeleted = pd.merge(instdeleted, instmatches,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "    instdeleted = instdeleted[instdeleted['_merge'] == 'left_only']\n",
    "    instdeleted = instdeleted[['chart_id','submission_id','code_id','start','end','deleted_reason']].drop_duplicates()\n",
    "    deleted_reason = instdeleted.groupby(['deleted_reason']).size().reset_index(name = 'counts')\n",
    "    instdeleted = instdeleted[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "\n",
    "    instadded = data[data['label'] == 'added']\n",
    "    instadded = pd.merge(instadded, instmatches,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "    instadded = instadded[instadded['_merge'] == 'left_only']\n",
    "    instadded = instadded[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "    instadded = pd.merge(instadded, instdeleted,how = 'outer', on = ['chart_id','submission_id','code_id','start','end'], indicator = True)\n",
    "    instadded = instadded[instadded['_merge'] == 'left_only']\n",
    "    instadded = instadded[['chart_id','submission_id','code_id','start','end']].drop_duplicates()\n",
    "\n",
    "    added = len(instadded)\n",
    "    deleted = len(instdeleted)\n",
    "    agreed = len(instmatches)\n",
    "   # print(added)\n",
    "    #print(deleted)\n",
    "  #  print(agreed)\n",
    "\n",
    "\n",
    "  #  print(instmatches.columns)\n",
    "    # my added small part\n",
    "    instmatchessub=instmatches[['chart_id', 'code_id', 'submission_id','start','end']]\n",
    "    instmatchessub.columns = ['chart_id', 'code_id','submission_id', 'start_offset', 'end_offset']\n",
    "\n",
    "    instadded.columns = ['chart_id', 'submission_id', 'code_id', 'start_offset', 'end_offset']\n",
    "    prod_additions_models = pd.merge(instadded, fd_prod,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "    prod_additions_models['abs_diff_start'] = abs(prod_additions_models['start_offset_x'] - prod_additions_models['start_offset_y'])\n",
    "    prod_additions_models['abs_diff_end'] = abs(prod_additions_models['end_offset_x'] - prod_additions_models['end_offset_y'])\n",
    "    prod_additions_models1 = prod_additions_models[ (\n",
    "                        (prod_additions_models['code_id'] == prod_additions_models['code']) \n",
    "                        & (prod_additions_models['abs_diff_start'] <= 75))\n",
    "              | (prod_additions_models['start_offset_x'] == prod_additions_models['start_offset_y'])\n",
    "              | (prod_additions_models['end_offset_x'] == prod_additions_models['end_offset_y'])\n",
    "              |((prod_additions_models['code_id'] == prod_additions_models['code']) \n",
    "                        & (prod_additions_models['abs_diff_end'] <= 75))\n",
    "              ]\n",
    "    instadded_modeldeleted = prod_additions_models1[['chart_id','submission_id','code','start_offset_y','end_offset_y']].drop_duplicates()\n",
    "\n",
    "  #  print(len(instadded_modeldeleted))\n",
    "\n",
    "    # initial numbers considering model deleted additions data for recall\n",
    "\n",
    "    total = len(instmatches) + len(instdeleted) + len(instadded_modeldeleted)\n",
    "    added = len(instadded_modeldeleted)\n",
    "    deleted = len(instdeleted)\n",
    "    agreed = len(instmatches)\n",
    "\n",
    "    TP = agreed\n",
    "    FN = added\n",
    "    FP = deleted\n",
    "    TN= len(fd_prod)-(len(data)-len(data[data['label'] == 'added']))\n",
    "\n",
    "    precision=TP/(FP+TP)\n",
    "    recall=TP/(FN+TP)\n",
    "    accuracy=(TP+TN)/(TP+TN1+FN+FP)\n",
    "\n",
    "   \n",
    "    # Evaluated Model accuracy numbers\n",
    "    # select those 708 charts and only passed the filtering not deleted, 0 is keep here\n",
    "\n",
    "    dev_df_sub_1 = fd_prod[fd_prod['all_model_pred']==0]  # select the 798 chart\n",
    "    #print(len(dev_df_sub_1[['chart_id','start_offset']].drop_duplicates()))  # 37085 pass through\n",
    "\n",
    "    dev_df_sub_1.rename(columns={'start_offset':'start','end_offset':'end'},inplace=True)\n",
    "    dev_df_sub_1.rename(columns={'code':'code_id'},inplace=True)\n",
    "\n",
    "    new_matches = pd.merge(dev_df_sub_1[['chart_id','start']], instmatches,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "    new_deleted = pd.merge(dev_df_sub_1[['chart_id','start']], instdeleted,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "\n",
    "    instadded.columns = ['chart_id', 'submission_id', 'code_id', 'start', 'end']\n",
    "    new_added = pd.merge(dev_df_sub_1, instadded,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "    new_added['abs_diff_start'] = abs(new_added['start_x'] - new_added['start_y'])\n",
    "    new_added['abs_diff_end'] = abs(new_added['end_x'] - new_added['end_y'])\n",
    "\n",
    "    new_added1 = new_added[ (\n",
    "                        (new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                        & (new_added['abs_diff_start'] <= 5))\n",
    "              | (new_added['start_x'] == new_added['start_y'])\n",
    "              ]\n",
    "\n",
    "    #1. if the start offset matches exactly\n",
    "    #2. If the end offset matches exactly\n",
    "    #3. If the overlap of start offset is between 75 characters and the code id matches\n",
    "    #4. If the overlap of end offset is between 75 characters and the code id matches\n",
    "    new_added2 = new_added[ (\n",
    "                        (new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                        & (new_added['abs_diff_start'] <= 75))\n",
    "              | (new_added['start_x'] == new_added['start_y'])\n",
    "              | (new_added['end_x'] == new_added['end_y'])\n",
    "              |((new_added['code_id_x'] == new_added['code_id_y']) \n",
    "                        & (new_added['abs_diff_end'] <= 75))\n",
    "              ]\n",
    "\n",
    "    #just validating the additions with a different method of calculation\n",
    "    instadded_modeldeleted.columns = ['chart_id', 'submission_id', 'code_id', 'start', 'end']\n",
    "    x = pd.merge(dev_df_sub_1[['chart_id','start']].drop_duplicates()\n",
    "                 , instadded_modeldeleted[['chart_id','start']].drop_duplicates()\n",
    "                 ,how = 'inner', on = ['chart_id','start'], indicator = True)\n",
    "\n",
    "    #type 1 - older number of additions considering only start offset\n",
    "    refreshed_agreements1 = int(len(new_matches)) + int(len(new_added1[['chart_id','start_x']].drop_duplicates()))\n",
    "    refreshed_deletions1 = int(len(dev_df_sub_1[['chart_id','start']].drop_duplicates())) - (int(len(new_matches)) + int(len(new_added1[['chart_id','start_x']].drop_duplicates()))) \n",
    "    refreshed_additions1 = added - int(len(new_added1[['chart_id','start_x']].drop_duplicates()))\n",
    "\n",
    "    #type 2 - new number of additions considering start offset and end offset\n",
    "    refreshed_agreements2 = int(len(new_matches)) + int(len(new_added2[['chart_id','start_x']].drop_duplicates()))\n",
    "    refreshed_deletions2 = int(len(dev_df_sub_1[['chart_id','start']].drop_duplicates())) - (int(len(new_matches)) + int(len(new_added2[['chart_id','start_x']].drop_duplicates()))) \n",
    "    refreshed_additions2 = added - int(len(new_added2[['chart_id','start_x']].drop_duplicates()))\n",
    "\n",
    "    refreshed_total1 = refreshed_agreements1 + refreshed_deletions1 + refreshed_additions1\n",
    "    refreshed_total2 = refreshed_agreements2 + refreshed_deletions2 + refreshed_additions2\n",
    "\n",
    "    # my added part of calculating TN\n",
    "    fd_prodsub=fd_prod[fd_prod['all_model_pred']==1]\n",
    "    fd_prodsub2=fd_prod[fd_prod['all_model_pred']==0]\n",
    "   # print(len(fd_prodsub))   # predicted as delete\n",
    "  #  print(len(fd_prodsub2))  # not deleted, presented to coder\n",
    "    fd_prodsub.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "           'all_model_pred']   # model predicted as deleted\n",
    "    fd_prodsub2.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "           'all_model_pred']   # model predicted as passing through or agree\n",
    "\n",
    "    instaddedsub=instadded[['chart_id', 'submission_id','code_id', 'start','end']]\n",
    "    instaddedsub.columns = ['chart_id', 'submission_id', 'code_id', 'start_offset', 'end_offset']\n",
    "\n",
    "    fd_prodsub.columns=['chart_id', 'code_id', 'start_offset', 'end_offset', 'text75',\n",
    "           'all_model_pred']\n",
    "    instmatchedaddedsub = pd.concat([instaddedsub,instmatchessub])\n",
    "    #instmatchedaddedsub=instmatchedaddedsub[['chart_id', 'code_id', 'submission_id','start','end']]\n",
    "    #instmatchedaddedsub.columns = ['chart_id', 'code_id','submission_id', 'start_offset', 'end_offset']\n",
    "    #print(len(instmatchedaddedsub))  # 25273\n",
    "    prod_agree_models = pd.merge(instmatchedaddedsub, fd_prodsub,how = 'inner', on = ['chart_id'], indicator = True)\n",
    "   # len(prod_agree_models)\n",
    "\n",
    "    prod_agree_models['abs_diff_start'] = abs(prod_agree_models['start_offset_x'] - prod_agree_models['start_offset_y'])\n",
    "    prod_agree_models['abs_diff_end'] = abs(prod_agree_models['end_offset_x'] - prod_agree_models['end_offset_y'])\n",
    "\n",
    "    prod_agree_models1 = prod_agree_models[ (\n",
    "                        (prod_agree_models['code_id_x'] == prod_agree_models['code_id_y']) \n",
    "                        & (prod_agree_models['abs_diff_start'] <= 5))\n",
    "              | (prod_agree_models['start_offset_x'] == prod_agree_models['start_offset_y'])\n",
    "              | (prod_agree_models['end_offset_x'] == prod_agree_models['end_offset_y'])\n",
    "              |((prod_agree_models['code_id_x'] == prod_agree_models['code_id_y']) \n",
    "                        & (prod_agree_models['abs_diff_end'] <= 5))\n",
    "              ]\n",
    "\n",
    "    instaddagreed_modeldeleted = prod_agree_models1[['chart_id','submission_id','code_id_x','code_id_y','start_offset_x','end_offset_x']].drop_duplicates()\n",
    " #   len(instaddagreed_modeldeleted)\n",
    "\n",
    "    #type 2 calculation\n",
    "\n",
    " #   print('Instance level New Models:')\n",
    "  #  print('Agreements = ', refreshed_agreements2*100/refreshed_total2,'%')\n",
    "  #  print('Deletions = ', refreshed_deletions2*100/refreshed_total2,'%')\n",
    "  #  print('Additions = ', refreshed_additions2*100/refreshed_total2,'%')\n",
    "   # print('Precision = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_deletions2),'%')\n",
    "    #print('Recall = ', refreshed_agreements2*100/(refreshed_agreements2+refreshed_additions2),'%')\n",
    " #   print('-------------------')\n",
    " #   print('Agreements = ', refreshed_agreements2)\n",
    " #   print('Deletions = ', refreshed_deletions2)\n",
    " #   print('Additions = ', refreshed_additions2)\n",
    "\n",
    "\n",
    "\n",
    "    TP = refreshed_agreements2\n",
    "    FP = refreshed_deletions2\n",
    "    FN = refreshed_additions2\n",
    "\n",
    "    TN=len(fd_prod[fd_prod['all_model_pred']==1])-len(instaddagreed_modeldeleted)  # deleted instances\n",
    "    \n",
    "    print('TP:',TP)\n",
    "    print('TN:',TN)\n",
    "    print('FN:',FN)\n",
    "    print('FP:',FP)\n",
    "\n",
    "    if (FP+TP)>0:\n",
    "        precision=TP/(FP+TP)\n",
    "    else:\n",
    "        percision = 'NA'\n",
    "    if (FN+TP)>0:\n",
    "        recall=TP/(FN+TP)\n",
    "    else:\n",
    "        recall ='NA' \n",
    "        \n",
    "    if (TP+TN+FN+FP)>0:\n",
    "        accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "    else:\n",
    "        accuracy ='NA'\n",
    "\n",
    "    \n",
    "   # print('precision:',precision)\n",
    "   # print('recall:',recall)\n",
    "   # print('accuracy:',accuracy)\n",
    "\n",
    "    return TP,TN,FN,FP,precision,recall,accuracy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a html copy\n",
    "#!jupyter nbconvert --to html all28refreshedmodels_comptoAMresult_050819-deleteinstances.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
